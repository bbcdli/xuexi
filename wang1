# python -m tensorflow.tensorboard --logdir=./
import tensorflow as tf
import sys
from keras.backend import set_image_dim_ordering
# tf.python.control_flow_ops = tf #hy:for remote

# KERAS_BACKEND=tensorflow python -c "from keras import backend"
# Using TensorFlow backend.
from PIL import ImageFilter
from functools import wraps
from random import randint
import time
import os
import cv2
import numpy as np
import PIL

import tflearn as tflearn
from sklearn import datasets
from scipy import ndimage
import math
import operator
import imutils
from PIL import Image  # hy: create video with images
import tools_classifier_seg as tools

# https://handong1587.github.io/deep_learning/2015/10/09/segmentation.html

# https://keras.io/getting-started/functional-api-guide/

MAX_ITERATION = 20000  # int(1e5 + 1)
NUM_OF_CLASSESS = 255  # 255#151
IMAGE_SIZE = 320
PROJ_DIR = '/home/'
Mul_Class = True
INPUT_CH = 3
do_reduce_mean = True

FLAGS = tf.flags.FLAGS
tf.flags.DEFINE_bool('DEBUG', 'False', 'Debug mode: True/ False')
tf.flags.DEFINE_integer("batch_size", "1", "batch size for training")
tf.flags.DEFINE_integer("view_size", "4", "batch size for view")
tf.flags.DEFINE_string("logs_dir", PROJ_DIR + "logs/", "path to logs directory")
tf.flags.DEFINE_string("data_dir", PROJ_DIR + "Data/data_3_segnet/mul_class/", "path to dataset")
tf.flags.DEFINE_string("val_dir", PROJ_DIR + "Test_Images/MA_video/representations/", "path to val dataset")
tf.flags.DEFINE_string("tb_dir", PROJ_DIR + 'Tensorboard_data/sum107/' + '08-08' + '/', "path to val dataset")
# tf.flags.DEFINE_float("learning_rate", "1e-4", "Learning rate for Adam Optimizer")
tf.flags.DEFINE_bool('log_on', "False", "Log mode: True/ False")

tf.flags.DEFINE_string('mode', "new_train", "Mode new_train/con_train/ visualize / only_validate_data")
tf.flags.DEFINE_integer('current_step', "1751", "current step for training")  # in fact 17050


#################################################################
# use tensorflow
# http://warmspringwinds.github.io/tensorflow/tf-slim/2016/11/22/upsampling-and-image-segmentation-with-tensorflow-and-tf-slim/

def load_and_preprocess_data(h, w):
    data_path = PROJ_DIR + '/Data/MA_cad/training/'  # main_path
    # data_path = '../Data/data_3_segnet/mul_class/MA_real/validation/'  # main_path

    print 'train_path:', data_path

    #####################################################################################
    im_path = data_path + 'others/2images_6cl/'  # for both masks_mul and masks_mul_1extra
    m_path = data_path + 'others/2masks_ex_ring/'

    # im_path = data_path + '6images/'  # total 714 + 155(green,yellow)
    # m_path = data_path + '6masks/'
    data_1s = sorted([s for s in os.listdir(im_path)])
    m_1s = sorted([s for s in os.listdir(m_path)])

    # data_1s = data_1s[0:100] + data_1s[600:700]
    # m_1s = m_1s[0:100] +  m_1s[600:700]
    #data_1s = data_1s[0:33] + data_1s[98:109]
    data_1s = data_1s[0:33]


    # data_1s = data_1s[10:28]
    # m_1s = m_1s[10:28]
    images, masks = tools.import_data_seg_tf_rgb_rnd(im_path, m_path, data_1s, m_1s, h, w, len(data_1s), MUL=True,
                                                     do_Flipping=True, do_gblur=True, do_darken=True)
    # images, masks = tools.import_data_seg_mul_tf_rgb(im_path, m_path, data_1s, m_1s, h, w, len(data_1s),
    #												 do_Flipping=True, do_gblur=True)
    if do_reduce_mean:
        images = tools.reduce_mean_stdev(images)
    # print masks[0]
    if FLAGS.DEBUG:
        import scipy.misc as misc
        for i, im, m in zip(xrange(len(images)), images, masks):
            print im.shape, m.shape
            misc.imsave(data_path + '1masks_3cl_o_val/' + str(i) + '.jpg', im)
            misc.imsave(data_path + '1masks_3cl_o_val/' + str(i) + '.png', m.reshape(h, w))
        # misc.imshow(m.reshape(h,w))

    #####################################################################################
    add_data_2 = False
    if add_data_2:
        im_path2 = data_path + '/6images_g_y/'  #
        m_path2 = data_path + '/6masks_g_y/'  #
        data_2s = sorted([s for s in os.listdir(im_path2)])
        m_2s = sorted([s for s in os.listdir(m_path2)])

        # data_2s = data_2s[100:280]
        # m_2s = m_2s[100:280]

        images2, mask2 = tools.import_data_seg_tf_rgb_rnd(im_path2, m_path2, data_2s, m_2s, h, w, len(data_2s),
                                                          MUL=False,
                                                          do_Flipping=True, do_gblur=True, do_darken=True)
        print 'train_path:', im_path2, ', images2 shape:', images2.shape, ', mask2 shape:', mask2.shape

        if do_reduce_mean:
            images2 = tools.reduce_mean_stdev(images2)

        images = np.concatenate((images, images2), axis=0)
        masks = np.concatenate((masks, mask2), axis=0)

    #####################################################################################
    add_data_3 = False
    if add_data_3:
        im_path3 = data_path + '/4images_exp/'  # main_path
        m_path3 = data_path + '/4masks_exp/'  # main_path
        data_3s = sorted([s for s in os.listdir(im_path3)])
        m_3s = sorted([s for s in os.listdir(m_path3)])

        # data_3s = data_3s[10:15]
        # m_3s = m_3s[10:15]

        images3, mask3 = tools.import_data_seg_tf_rgb_rnd(im_path3, m_path3, data_3s, m_3s, h, w,
                                                          len(data_3s), MUL=False,
                                                          do_Flipping=True, do_gblur=True, do_darken=True)
        print 'train_path:', im_path3, ', images3 shape:', images3.shape, ', mask3 shape:', mask3.shape

        if do_reduce_mean:
            images3 = tools.reduce_mean_stdev(images3)
        images = np.concatenate((images, images3), axis=0)
        masks = np.concatenate((masks, mask3), axis=0)

    add_data_4 = False
    if add_data_4:
        im_path4 = data_path + '/images_blank2/'  # main_path
        m_path4 = data_path + '/masks_blank2/'  # main_path
        data_4s = sorted([s for s in os.listdir(im_path4)])
        m_4s = sorted([s for s in os.listdir(m_path4)])

        # data_4s = data_4s[7:9] + data_4s[15:17] + data_4s[21:22] + data_4s[23:24]
        # m_4s =    m_4s[7:9]      + m_4s[15:17]     + m_4s[21:22] + m_4s[23:24]
        # data_4s = data_4s[22:47]
        # m_4s = m_4s[22:47]

        images4, mask4 = tools.import_data_seg_tf_rgb_rnd(im_path4, m_path4, data_4s, m_4s, h, w,
                                                          len(data_4s), MUL=False,
                                                          do_Flipping=True, do_gblur=True, do_darken=True)
        print 'train_path:', im_path4, ', images4 shape:', images4.shape, ', mask4 shape:', mask4.shape

        if do_reduce_mean:
            images4 = tools.reduce_mean_stdev(images4)
        images = np.concatenate((images, images4), axis=0)
        masks = np.concatenate((masks, mask4), axis=0)

    add_data_5 = False
    if add_data_5:
        im_path5 = data_path + '/4images_exp/'  # main_path  #4images_exp
        m_path5 = data_path + '/4masks_exp/'  # main_path
        data_5s = sorted([s for s in os.listdir(im_path5)])
        m_5s = sorted([s for s in os.listdir(m_path5)])

        # data_5s = data_5s[150:280]
        # m_5s = m_5s[150:280]

        images5, mask5 = tools.import_data_seg_2c_tf_rgb(im_path5, m_path5, data_5s, m_5s, h, w,
                                                         len(data_5s), do_Flipping=True, do_gblur=True)
        print 'train_path:', im_path5, ', images5 shape:', images5.shape, ', mask5 shape:', mask5.shape

        images5 = tools.reduce_mean_stdev(images5)
        images = np.concatenate((images, images5), axis=0)
        masks = np.concatenate((masks, mask5), axis=0)

    ####################################################################################
    ####################################################################################
    return images, masks


def get_online_test_batch(h, w):
    data_path = '../Test_Images/MA/test_represent/'  # main_path

    print 'train_path:', data_path
    #####################################################################################
    im_path = data_path + 'images/'
    m_path = data_path + 'masks/'
    data_1s = sorted([s for s in os.listdir(im_path)])
    m_1s = sorted([s for s in os.listdir(m_path)])

    max_num = len(data_1s)  # 3
    images, masks, images_view = tools.import_data_segnet_2c_tf_misc_cv2_gray(im_path, m_path, data_1s, m_1s, h, w,
                                                                              max_num, MUL=False,
                                                                              do_Flipping=False)
    #####################################################################################

    dummy_mask = np.ones((1, h * w))
    return images, masks, dummy_mask, data_1s, m_1s, images_view


def count_diff_pixel_values(picture, h, w):
    ds = []
    for row in xrange(h):
        for col in xrange(w):
            if picture[row][col] not in ds:
                ds.append(picture[row][col])
    return len(ds), ds


def save_str_to_file(file, lines):
    lines = '\n'.join(lines)
    with open(file, 'w') as f:
        f.writelines(lines)


def test_seg_tf_model_online(dice_results, dice_cad_results, save_name, classifier_model, h, w, dropout_1s, step):
    images, masks, dummy_mask, data_1s, label_1s, images_view = get_online_test_batch(h, w)
    if do_reduce_mean:
        images = tools.reduce_mean_stdev(images)
    # print 'images shape after mean reduction:', images.shape  # images shape: (849, 33856, 1) example 6c
    # images, masks, data_1s = images[0:5], masks[0:5], data_1s[0:5]
    print 'len of images, masks loaded:', len(images), ', ', len(masks)
    new_graph = tf.Graph()

    with tf.Session(graph=new_graph) as sess2:
        # load classifier model
        # sess, saver = tools.load_classifier_model(sess, '../testbench/6classes/', classifier_model=classifier_model)
        ckpt = tf.train.get_checkpoint_state(checkpoint_dir=FLAGS.logs_dir)
        tf.train.import_meta_graph(classifier_model)  # (v)

        ckpt.model_checkpoint_path = classifier_model[:-5]

        if ckpt and ckpt.model_checkpoint_path:
            saver = tf.train.Saver()
            saver.restore(sess2, ckpt.model_checkpoint_path)
            print "Evaluation with model", ckpt.model_checkpoint_path
        else:
            print 'not found model'

        batch_ys = dummy_mask
        batch_ys = batch_ys.reshape(-1, h, w, 1)
        dices = 0
        for im, im_o, ref_mask, imn, mn, idx in zip(images, images_view, masks, data_1s, label_1s, xrange(len(images))):
            imn, mn = imn[:-4], mn[:-4]
            test_im = np.uint8(im_o.reshape((h, w, 3)))
            batch_xs = im.reshape(-1, h, w, INPUT_CH)  # cat

            DEBUG = False
            if DEBUG:
                print 'batch_x, batch_y shape:', batch_xs.shape, ', ', batch_ys.shape
                print 'batch_xs (test_im):'
                cv2.imshow('im', test_im)

            feed_dict_view = {"x:0": batch_xs, "y:0": batch_ys, "keep_prob:0": dropout_1s}
            # conv19_view = sess2.run("conv19:0", feed_dict=feed_dict_view)
            pred = sess2.run("prediction:0", feed_dict=feed_dict_view)
            pred = np.squeeze(pred, axis=3)
            pred = pred[0].astype(np.uint8) * 255.0
            pred_thresh = pred.copy()

            conv19_view = sess2.run("conv19:0", feed_dict=feed_dict_view)

            conv19_view = conv19_view[0].astype(np.uint8) * 255.0
            conv19_r, conv19_c, conv19_ch = conv19_view.shape
            # print '====== conv19 shape:', conv19_view.shape

            conv19_values0 = conv19_view[:, :, 0]
            conv19_values1 = conv19_view[:, :, 1]
            if conv19_ch == 2:
                conv19_values2 = conv19_view[:, :, 1]
            elif conv19_ch == 3:
                conv19_values2 = conv19_view[:, :, 2]

            # print 'pred *255', pred #tasks direct value without *255: [0,2], so what we see with *255: 0,255,510
            # print 'conv19 *255', conv19_view  #tasks value 0,1, => 0, 255

            ref_mask = np.squeeze(ref_mask, axis=2)
            ref_mask_thresh = ref_mask * 255.0

            print '\n'

            def print_count(img, h, w, str):
                n, diff_v = count_diff_pixel_values(img, h, w)
                min_n = min(n, 5)
                print 'num of diff values in ', str, ':', n, ',    ', diff_v[:min_n]

            print_count(pred, h, w, 'pred')
            # print_count(ref_mask_thresh,h,w,'r255')
            print_count(conv19_values0, h, w, 'con0')
            print_count(conv19_values1, h, w, 'con1')
            print_count(conv19_values2, h, w, 'con2')

            ##############################################################
            # calc dice
            ##############################################################
            threshold_ref = True
            if threshold_ref:
                """
				all values larger than thresh_at value will be replaced with a new value
				this is only for the case when only one annotation in foreground and the background are interested
				"""
                thresh_at = 1  # or 1
                ceiling_to_pixel_value = 255
                idx = ref_mask_thresh[:, :] > thresh_at
                ref_mask_thresh[idx] = ceiling_to_pixel_value

            threshold_pred = True
            if threshold_pred:
                thresh_at = 0
                pred_key_value = 255
                idx = pred_thresh[:, :] > thresh_at
                pred_thresh[idx] = pred_key_value

            if 'cad' not in imn:
                dice = tools.calc_dice_simi(pred_thresh, ref_mask_thresh, imn, k=pred_key_value)
                dice_str = imn + ', \t\tdice\t:' + str(dice)
                dice_results.append(dice_str)
                dices += dice
                # dice_2 = tools.calc_dice_simi(pred_thresh, ref_mask_thresh, imn, k=2)
                print imn, ',dice_1', dice
            # print imn,'dice_2:', dice_2
            # dice_results.append(str(avg_dice))


            if 'cad' in imn:
                dice_cad = tools.calc_dice_simi(pred_thresh, ref_mask_thresh, imn, k=pred_key_value)
                dice_cad_str = imn + ', \t\tdice\t:' + str(dice_cad)
                dice_cad_results.append(dice_cad_str)
                print imn, ', dice score: {}'.format(dice_cad)



            ##############################################################
            # save images
            ##############################################################
            display = False
            save_im = True
            if display:
                cv2.imshow('test_pred', pred)
                cv2.imshow('ref', ref_mask)
                cv2.waitKey(5)
            if save_im:
                # cv2.imwrite(save_name + 'pred_' + imn +'.png', pred)
                # cv2.imwrite(save_name + 'ori_' + imn +'.png', test_im)

                # stack view
                #
                def save_stacked_ims(im1, im2, im3):
                    test_im, pred, conv19_view = im1, im2, im3
                    r_rgb, c_rgb, ch = test_im.shape
                    r_gray, c_gray = pred.shape
                    r_rgb2, c_rgb2, conv19_ch = conv19_view.shape

                    r_comb = max(r_rgb, r_gray, r_rgb2)
                    c_comb = c_rgb + c_gray + c_rgb2
                    comb_im = np.zeros(shape=(r_comb, c_comb, ch), dtype=np.uint8)

                    comb_im[:r_rgb, :c_rgb] = test_im
                    comb_im[:r_gray, c_rgb:c_rgb + c_gray] = pred[:, :, None]
                    if conv19_ch < 3:
                        comb_im[:r_rgb2, c_rgb + c_gray:] = np.expand_dims(conv19_view[:, :, 1], 3)
                    else:
                        comb_im[:r_rgb2, c_rgb + c_gray:] = conv19_view
                    cv2.imwrite(save_name + 'com_' + imn + '.png', comb_im)

                save_stacked_ims(test_im, pred, conv19_view)

            # print 'mask path name',save_name + mn + '_ref.png'
            # cv2.imwrite(save_name + 'ref_' + mn + '.png', ref_mask*255)

        avg_dice = float(dices / (len(images) - 6))  # 6 cad
        avg_str = '\t\t\t\t================> step ' + str(step) + ' avg:' + str(avg_dice) + '\n'
        dice_results.append(avg_str)
    return avg_dice, dice_results, dice_cad_results


def train_2c_tensorflow(h, w):  # input 320x320
    # tf" assumes (rows, cols, channels), "th" assumes (channels, rows, cols)
    dice_results, dice_cad_results = [], []
    set_image_dim_ordering(dim_ordering='tf')
    # print 'train binary classes, load data'
    print 'load data'
    bg_LABEL = 'sigmch3conv19_2'
    images, masks = load_and_preprocess_data(h, w)

    Graph_seg = 1

    if Graph_seg == 1:
        # import Graph_seg_convout3 as g_seg
        import Graph_seg_tf1 as g_seg

        print 'import graph seg'
        # arch_str = 'seg'


        learning_rate, dropout_def, dropout_1s, optimizer_type, classifier_tpye, loss_type, \
        x, y, y_int, keep_prob, optimizer, cost, summary_op, optimize_op, \
        conv19_out, conv19, annotation_pred = g_seg.define_model()

    str_log = optimizer_type

    if FLAGS.log_on and ('train' in FLAGS.mode):
        sys.stdout = tools.Logger(FLAGS.log_path, str_log)

    print 'Network parameters etc:\n' \
          'learning_rate:', str(learning_rate), ', dropout_def:', dropout_def,
    ', optimizer_type', optimizer_type, ', classifier_tpye', classifier_tpye, \
    ', loss_type', loss_type  # , ' conv19_out:', conv19_out

    # hy:customized tensor model name
    model_log_name = 'model_' + bg_LABEL

    ## hy include specs of model
    from datetime import datetime
    t = datetime.now()
    date = t.strftime('%m-%d')  # t.strftime('%y-%m-%d')
    # tensorboard_path = '../Tensorboard_data/sum107/' + '06-16' + '/'
    tensorboard_path = FLAGS.tb_dir

    tensor_model_sum_path = '../tensor_model_sum/'

    # Keep training until max iterations is reached or by any other defined conditions
    set_STOP = False
    TrainingProp = 1
    train_size = int(len(images) * TrainingProp)
    print 'train_size', train_size

    # Launch the graph
    with tf.Session() as sess:
        saver = tf.train.Saver()  # hy:

        ckpt = tf.train.get_checkpoint_state(checkpoint_dir=FLAGS.logs_dir)
        if FLAGS.mode == 'new_train':
            # Initializing the variables
            init = tf.global_variables_initializer()
            sess.run(init)
            current_step = 0
        if FLAGS.mode == 'con_train' or FLAGS.mode == 'visualize':
            current_step = FLAGS.current_step
            # or manually
            #ckpt.model_checkpoint_path = PROJ_DIR + '/logs/' + 'model_sigmch3conv19_3_0_I_loss0.36-1000.meta'
            # ckpt.model_checkpoint_path = '../logs/'+'model_seg_adam_h184_w184_b3_II_los-2.23-407'

            # print 'ckpt path', ckpt.model_checkpoint_path

            if ckpt and ckpt.model_checkpoint_path:
                saver.restore(sess, ckpt.model_checkpoint_path)
                print "Continue to train with ", ckpt.model_checkpoint_path
                classifier_model = ckpt.model_checkpoint_path + '.meta'
            else:
                print 'not found model'

        if 'train' in FLAGS.mode:
            ###############################################################
            # hy: can display all results in one graph
            train_writer = tf.train.SummaryWriter(tensorboard_path + '/train', sess.graph)
            # validation_writer = tf.train.SummaryWriter(tensorboard_path + '/vali', sess.graph)
            # test_writer = tf.train.SummaryWriter(tensorboard_path + '/test', sess.graph)

            # hy register finished class learning
            pred_y_diff = 0
            e = 0

            print 'batch size:', FLAGS.batch_size
            total_batches = int(train_size / FLAGS.batch_size)
            im_to = 0
            # f_e = float(MAX_ITERATION * FLAGS.batch_size / train_size)
            # i_e = int(MAX_ITERATION * FLAGS.batch_size / train_size)

            train_ith_batch = 0
            for i in xrange(current_step, current_step + MAX_ITERATION + MAX_ITERATION):
                start_time = time.time()
                ## Set batch data  #############################################################
                # im_from = im_to if im_to < train_size-1 else 0
                # im_to = min(train_size - 1, im_from + FLAGS.batch_size)

                train_index = randint(0, train_size - FLAGS.batch_size)
                im_from, im_to = train_index, train_index + FLAGS.batch_size

                # print 'from',im_from,'to',im_to

                for batch_step in xrange(FLAGS.batch_size):
                    batch_xs, batch_ys = images[im_from:im_to], masks[im_from:im_to]
                # cv2.imshow('tmp_ys',batch_ys[-1,:,:])

                batch_xs = batch_xs.reshape(-1, h, w, INPUT_CH)  # cat
                batch_ys = batch_ys.reshape(-1, h, w, 1)

                ## Feed batch data   ############################################################
                feed_dict = {"x:0": batch_xs, "y:0": batch_ys, "keep_prob:0": dropout_def}
                feed_dict_view = {"x:0": batch_xs, "y:0": batch_ys, "keep_prob:0": dropout_1s}

                ## Start Training  ##############################################################
                loss = sess.run(cost, feed_dict=feed_dict)
                y_sess_value = sess.run(y, feed_dict=feed_dict_view)
                y_sess_value = np.squeeze(y_sess_value, axis=3)
                # print '========== y_sess shape:', y_sess_value.shape

                sess.run(optimize_op, feed_dict=feed_dict)

                view_interval = 500
                if i < 1000:
                    view_interval = 50
                if i > 1000 and i < 5000:
                    view_interval = 250

                if i > 5000:
                    view_interval = 1000

                if i > 50000:
                    view_interval = 2000

                glb_step = i
                if i % view_interval == 0:
                    # summary_str = sess.run(summary, feed_dict={x: batch_xs, y: batch_ys, keep_prob: dropout})
                    # summary_writer.add_summary(summary_str, step)
                    train_ith_batch = 0 if train_ith_batch >= total_batches - view_interval else train_ith_batch + view_interval

                    # print 'Elapsed time:', "{:.2f}".format(elapsed_time / 60), 'min'
                    ## Validation  ####################################################################
                    # val1_acc = sess.run(accuracy, feed_dict={x: val1_batch_xs, y: val1_batch_ys, keep_prob: dropout_1s})
                    train_res = sess.run(summary_op, feed_dict=feed_dict_view)
                    train_writer.add_summary(train_res, i)

                    elapsed_time = int(time.time() - start_time)
                    t_str = datetime.now().strftime('%H-%M-%S')
                    print " %2d-%2d/%2d %s ---> -ETA: %ds -\tloss: %g" % (
                        i, train_ith_batch, total_batches, t_str, elapsed_time, loss)

                # if  i % total_batches == 0:
                if i % view_interval == 0:  # and i > current_step + 500:
                    save_all_models = 1
                    if save_all_models == 1:
                        mn = model_log_name + '_' + str(batch_step) + '_I_loss' + str(round(loss, 2))
                        model_save = FLAGS.logs_dir + mn
                        saver.save(sess, save_path=model_save,
                                   global_step=glb_step)  # saver.save(sess, FLAGS.logs_dir + "model.ckpt", itr)
                        classifier_model = model_save + '-' + str(i) + '.meta'
                        print '--- ---> Iter %5d: saving model to %s' % (glb_step, classifier_model)
                        e += 1

                    # print 'download images'
                    # tools.save_tb_imgs(tensorboard_path + str(i)) #visualization
                    # online test
                    do_online_test = True
                    if do_online_test:
                        n, diff_v = count_diff_pixel_values(y_sess_value[0], h, w)
                        print 'num of diff values in y_sess:', n, ', diff:', diff_v
                        # print 'y_int:', y_int_sess   #(?, 320, 320, 1), dtype=int32)

                        avg, dice_results, dice_cad_results = \
                            test_seg_tf_model_online(dice_results, dice_cad_results, tensorboard_path + str(i),
                                                     classifier_model, h, w, dropout_1s, i)
                        print '================================> step ', glb_step, ' test average dice:', avg

                    control_save = True
                    if control_save:
                        if avg > 0.12 and avg < 1 and i < int(1e7 + 1):
                            # save the model
                            model_save2 = FLAGS.logs_dir + model_log_name + '_II_avg' + str(round(avg, 2))
                            saver.save(sess, save_path=model_save2, global_step=glb_step)
                            print 'model save', model_save2
                            cmd = 'mv ' + FLAGS.logs_dir + 'model*II* ' + tensor_model_sum_path
                            os.system(cmd)

                            cmd = 'rm ' + FLAGS.logs_dir + 'model*I*'
                            os.system(cmd)
                        elif avg > 0.4 and avg < 1:
                            model_save2 = FLAGS.logs_dir + model_log_name + '_II_avg' + str(round(avg, 2))
                            saver.save(sess, save_path=model_save2, global_step=glb_step)
                            print 'model save', model_save2
                            cmd = 'mv ' + FLAGS.logs_dir + 'model*II* ' + tensor_model_sum_path
                            os.system(cmd)

                            cmd = 'rm ' + FLAGS.logs_dir + 'model*I*'
                            os.system(cmd)

                    save_online_eva_to_file = True
                    if save_online_eva_to_file:
                        # keyword = os.path.basename(os.path.normpath(FLAGS.log_dir))
                        keyword = 'dice_results'
                        dice_txt = dice_results + dice_cad_results
                        save_str_to_file(FLAGS.logs_dir + keyword + '.txt', dice_txt)

                    if set_STOP:
                        print 'STOP is set'
                        break

                if i % (view_interval * 2) == 0:
                    REMOVE_IMAGES = True
                    if REMOVE_IMAGES and glb_step > 1:
                        if avg < 0.01:
                            # remove saved images
                            cmd = 'rm ' + FLAGS.tb_dir + str(glb_step) + 'com*'
                            os.system(cmd)

                if cv2.waitKey(1) & 0xFF == ord('q'):
                    print 'key interrupt'
                    break

        #################
        if FLAGS.mode == 'visualize':
            for view_i in xrange(len(images) - 1):
                im_from, im_to = view_i, view_i + 1
                # train_index = randint(0, train_size - FLAGS.batch_size)
                # im_from, im_to = train_index, train_index + FLAGS.batch_size

                batch_xs, batch_ys = images[im_from:im_to], masks[im_from:im_to]

                batch_xs = batch_xs.reshape(-1, h, w, 3)  # cat
                batch_ys = batch_ys.reshape(-1, h, w, 1)

                ## Feed batch data   ############################################################
                feed_dict_view = {x: batch_xs, y: batch_ys, keep_prob: dropout_1s}

                ################################################################
                pred = sess.run(annotation_pred, feed_dict=feed_dict_view)
                pred = np.squeeze(pred, axis=3)
                print 'pred shape', pred.shape

                conv19_view = sess.run('conv19:0', feed_dict=feed_dict_view)

                show_value = False
                if show_value:
                    counter = 0
                    for i in xrange(320):
                        for j in xrange(100, 320):
                            counter += 1
                            if counter % 100 == 0:
                                print '\n'
                            print pred[0][i][j],

                cv2.imshow('pred', pred[0].astype(np.uint8) * 255)
                cv2.imshow('conv19', conv19_view[0].astype(np.uint8))
                cv2.waitKey()

        print "\nOptimization Finished!"


#######################################

#######################################
if 'only_validate_data' in FLAGS.mode:
    load_and_preprocess_data(320, 320)

if 'train' in FLAGS.mode or 'visualize' in FLAGS.mode:
    train_2c_tensorflow(320, 320)

    print("Training done!")


# if __name__ == "__main__":#
#	tf.app.run()

#wang
import tensorflow as tf
import numpy as np
import tflearn

import settings  # hy: collection of global variables

settings.set_global()
PRINT_ARCHI = True

#when using concat at axis 0 got logits shape [512000,3] and labels shape [102400]
####################################################### Header begin ###################p#############################
###############################
# 0    1      2      3        4        5      6     7      8
# dropout = [1,  1,  1,  1,      1,      1,  1,  1,  1] #1st
dropout = [0.15, 0.25, 0.4, 0.45, 1, 0.4, 0.25, 0.15, 0.15]  # 1st
#dropout = [0.5, 0.5, 0.4, 0.5, 1, 0.4, 0.5, 0.5, 0.5]  # 1st
dropout_1s = [1] * len(dropout)

# output size is now n_classes
n_classes = 2
IMAGE_SIZE = 320  # 320
input_size = IMAGE_SIZE * IMAGE_SIZE  # hy
optimizer_type = 'adam'# 'adam'  # 'adam' #GD-'gradient.descent',#'ProximalGradientDescent', #'SGD', #'RMSprop'
#learning_rate = 0.0005
learning_rate = 0.000498
#learning_rate = 0.00001

classifier_tpye = 3  # 1.category  2.binary  3 ch=3
loss_type = 5  # 1'IoU',  2'sparse_softmax',  3 'loss_dice'   4.sigmoid  5.loss_l2

input_ch = 3
conv19_out = 3  # 2 can set 255, different from fcn, where can only use 256
pad='SAME'  #'VALID'
u = 8
# Tensor must be 4-D with last dim 1, 3, or 4, not [1,320,320,2]

# IoU: conv19_out can be any num
# sparse_softmax: conv19_out can only be 2

######################
# GD
if optimizer_type == 'GD':
	learning_rate = learning_rate  # 0.00405 good #0.09 bad 3549 #0.04049 #0.03049 #0.015 #0.07297 #0.09568# TODO 0.05  0.005 better, 0.001 good \0.02, 0.13799 to 0.14 good for 6 classes,

######################
# RMSprop
if optimizer_type == 'RMSprop':
	decay = 0.00009
	momentum = 0.99
	epsilon_R = 0.009
######################
# SGD
if optimizer_type == 'SGD':
	learning_rate = learning_rate
	momentum_SGD = 0.99  # 0.99
# lr_decay = 0.01
# decay_step = 100
######################
######################
# adam
# Adam with these parameters beta1=0.9,beta2=0.999, epsilon=1e-08 etc the training accuracy is not stable, epsilon = 0.01
if optimizer_type == 'adam':
	learning_rate = learning_rate
	beta1 = 0.9
	beta2 = 0.999
	epsilon = 0.1


####################################################### Header End#### ################################################

def IoU(logits=None, labels=None, pixel_num=input_size):
	with tf.name_scope('cost'):
		# dimension of logits and labels must be equal
		logits = tf.to_float(tf.reshape(logits, (-1, pixel_num)))
		labels = tf.to_float(tf.reshape(labels, (-1, pixel_num)))
		
		# intersection = sum([logits] .* [labels])
		# since only 1s in labels will produce non-zero values, this produce is then the intersection
		intersec = tf.reduce_sum(tf.mul(logits, labels))
		#
		union = tf.reduce_sum(tf.sub(tf.add(logits, labels), tf.mul(logits, labels)))
		loss = tf.sub(tf.constant(1.0, dtype=tf.float32), tf.div(intersec, union))
	return loss


def loss_sigmoid(logits=None, labels=None, pixel_num=input_size):
	with tf.name_scope('cost'):
		logits = tf.to_float(tf.reshape(logits, [-1, pixel_num]))
		labels = tf.to_float(tf.reshape(labels, [-1, pixel_num]))
		cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits, labels)  # no args keyword
		# cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, labels) #no args keyword, all values
		# go to 1 or 0 quickly
		loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')
	return loss


def loss_dice_coeff(logits=None, labels=None, pixel_num=input_size):
	# input labels and logits must be of type float (use tf.to_float)
	# output: loss value, which is the negative dice coefficient
	# accuracy is the dice coefficient
	pixel_num = input_size
	with tf.name_scope('cost'):
		# num_equals_net_output = conv19_out
		# the dimension of labels and logits should be equal
		print 'logits flat shape:', logits.get_shape(), ',  labels flat shape:', labels.get_shape()
		logits = tf.to_float(tf.reshape(logits, (-1, pixel_num)))
		labels = tf.to_float(tf.reshape(labels, (-1, pixel_num)))
		
		print 'logits flat shape:', logits.get_shape(), ',  labels flat shape:', labels.get_shape()
		
		# using * and axis=1
		# intersection = tf.reduce_sum(labels * logits,axis=1,keep_dims=True,name='intersection')
		# Info: intersection size: (?, 1, 102400)
		# ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,102400,102400]
		
		# using mul
		intersection = tf.reduce_sum(tf.mul(labels, logits))
		# Info: intersection size: ()
		# ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,102400,102400]
		
		smooth = 1  # avoid 0 as output
		loss_inter = tf.add(2. * intersection, smooth, name='loss_inter')
		# loss_inter = tf.add(tf.mul(tf.constant(2), intersection,axis=1,keep_dims=True), smooth)
		loss_u1 = tf.add(tf.reduce_sum(labels), tf.reduce_sum(logits), name='loss_u1')
		loss_u = tf.add(loss_u1, smooth, name='loss_u')
		loss_div = tf.div(loss_inter, loss_u, name='loss_div')  # expected value very close to or equal 1
		loss = tf.sub(1.0, loss_div, name='cost')
		'''
	intersection = tf.reduce_sum(flat_logits * flat_labels, axis=1, keep_dims=True)
		union = tf.reduce_sum(tf.mul(flat_logits, flat_logits), axis=1, keep_dims=True) \
						+ tf.reduce_sum(tf.mul(flat_labels, flat_labels), axis=1, keep_dims=True)
		loss = 1 - tf.reduce_mean(2 * intersection / (union))
	'''
	return loss


# return (2. * intersection + smooth) / (K.sum(labels) + K.sum(logits) + smooth)
def loss_l2(logits=None, labels=None, pixel_num=input_size):
	import keras
	with tf.name_scope('cost'):
		logits = tf.to_float(tf.reshape(logits, [-1, pixel_num]))
		labels = tf.to_float(tf.reshape(labels, [-1, pixel_num]))
		
		predictions = logits
		# **************************************************************************************
		# - weighted cross entropy
		# logits, targets, pos_weight, name=None
		# loss_all = tf.nn.weighted_cross_entropy_with_logits(logits, labels, -0.0008, name=None)
		# loss = tf.reduce_mean(loss_all)
		#################################################
		# - binary crossentropy
		# epsilon = 1e-8
		# loss = tf.reduce_mean(-(labels * tf.log(logits + epsilon) +
		#                      (1. - labels) * tf.log(1. - logits + epsilon)))
		# **************************************************************************************
		
		################################################
		times_diff = tf.mul(1.0, (logits - labels))
		loss = tf.reduce_sum(tf.pow(times_diff, 2)) / (1.0 * pixel_num)
	return loss


def loss2(logits=None, labels=None, n_classes=0, cost_name=''):  # cross_entropy, dice_coefficient
	"""
	Constructs the cost function, either cross_entropy, weighted cross_entropy or dice_coefficient.
	Optional arguments are:
	class_weights: weights for the different classes in case of multi-class imbalance
	regularizer: power of the L2 regularizers added to the loss function
	"""
	
	flat_logits = tf.reshape(logits, [-1, n_classes])
	flat_labels = tf.reshape(labels, [-1, n_classes])
	if cost_name == "cross_entropy":
		# class_weights = cost_kwargs.pop("class_weights", None)
		class_weights = None
		
		if class_weights is not None:
			class_weights = tf.constant(np.array(class_weights, dtype=np.float32))
			
			weight_map = tf.mul(flat_labels, class_weights)
			weight_map = tf.reduce_sum(weight_map, axis=1)
			
			loss_map = tf.nn.softmax_cross_entropy_with_logits(flat_logits, flat_labels)
			weighted_loss = tf.mul(loss_map, weight_map)
			
			loss = tf.reduce_mean(weighted_loss)
		
		else:
			loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(flat_logits,
			                                                              flat_labels))
	else:
		raise ValueError("Unknown cost function: " % cost_name)
	
	# regularizer = cost_kwargs.pop("regularizer", None)
	# regularizer = None
	# if regularizer is not None:
	#    regularizers = sum([tf.nn.l2_loss(variable) for variable in variables])
	#    loss += (regularizer * regularizers)

	return loss

def pool(img, k, pool_type='max',pad='SAME', name=None):
	if pool_type == 'max':
		return tf.nn.max_pool(img, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding=pad, name=name)
	if pool_type == 'avg':
		return tf.nn.avg_pool(img, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding=pad, name=name)

def p_relu0(x):
  alphas = tf.get_variable('alpha', x.get_shape()[-1],
                       initializer=tf.constant_initializer(0.0),
                        dtype=tf.float32)
  pos = tf.nn.relu(x)
  neg = alphas * (x - abs(x)) * 0.5
  return pos + neg

def p_relu(_x, name="prelu"):
  _alpha = tf.get_variable(name, shape=_x.get_shape()[-1],
                           dtype=_x.dtype, initializer=tf.constant_initializer(0.1))
  return tf.maximum(0.0, _x) + _alpha * tf.minimum(0.0, _x)

def conv2d(img, w, b, k, pad='SAME', name=None):
	#x = tf.nn.bias_add(tf.nn.conv2d(img, w, strides=[1, k, k, 1], padding=pad), b)
	return p_relu(tf.nn.bias_add(tf.nn.conv2d(img, w, strides=[1, k, k, 1], padding=pad), b),name=name)
	#return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(img, w, strides=[1, k, k, 1], padding=pad), b), name=name)



def conv2d_leaky(img, w, b, k, pad='SAME', name=None):
	alpha = 0.0001
	x = tf.nn.bias_add(tf.nn.conv2d(img, w, strides=[1, k, k, 1], padding=pad), b)
	return tf.maximum(alpha*x,x,name=name)


def conv2d_1(img, w, b, k, pad='SAME', name=None):
	return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(img, w, strides=[1, k, k, 1], padding=pad), b), name=name)


def max_pool(img, k, pad='SAME', name=None):  # 'SAME', 'VALID'
	return tf.nn.max_pool(img, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding=pad, name=name)


def avg_pool(img, k, pad='SAME', name=None):  # 'SAME', 'VALID'
	return tf.nn.avg_pool(img, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding=pad, name=name)


def train(loss_val, var_list, learning_rate):
	optimizer = tf.train.AdamOptimizer(learning_rate)
	grads = optimizer.compute_gradients(loss_val, var_list=var_list)
	return optimizer.apply_gradients(grads)


def conv_net(_X, _weights, _biases, _dropout, filter_size, filter_size_out, k_conv, k_pool, k_out, SEED):
	# - INPUT Layer
	# Reshape input picture
	
	# _X = tf.reshape(_X, shape=[-1, IMAGE_SIZE, IMAGE_SIZE, 3])
	
	################################
	# - Convolution Layer 1,2
	# - Convolution Layer 1,2
	conv1 = conv2d(_X, _weights['wc1'], _biases['bc1'], k_conv, name='conv1')  # 4
	conv2 = conv2d(conv1, _weights['wc2'], _biases['bc2'], k_conv, pad=pad,name='conv2')
	pool1 = pool(conv2, k_pool, name='pool1')
	pool1d = tf.nn.dropout(pool1, _dropout[0])  # TODO comment it later!
	
	################################
	# - Convolution Layer 3,4
	conv3 = conv2d(pool1d, _weights['wc3'], _biases['bc3'], k_conv, name='conv3')
	conv4 = conv2d(conv3, _weights['wc4'], _biases['bc4'], k_conv, pad=pad,name='conv4')
	pool2 = pool(conv4, k_pool, name='pool2')
	pool2d = tf.nn.dropout(pool2, _dropout[1])
	
	# - Convolution Layer 5,6
	conv5 = conv2d(pool2d, _weights['wc5'], _biases['bc5'], k_conv, name='conv5')
	conv6 = conv2d(conv5, _weights['wc6'], _biases['bc6'], k_conv, pad=pad,name='conv6')
	pool3 = pool(conv6, k_pool, name='pool3')
	pool3d = tf.nn.dropout(pool3, _dropout[2])
	
	# - Convolution Layer 7,8
	conv7 = conv2d(pool3d, _weights['wc7'], _biases['bc7'], k_conv, name='conv7')
	conv8 = conv2d(conv7, _weights['wc8'], _biases['bc8'], k_conv, pad=pad,name='conv8')
	pool4 = pool(conv8, k_pool, name='pool4')
	pool4d = tf.nn.dropout(pool4, _dropout[3])
	################################
	
	################################
	# - Convolution Layer 9,10
	conv9 = conv2d(pool4d, _weights['wc9'], _biases['bc9'], k_conv, name='conv9')
	conv10 = conv2d(conv9, _weights['wc10'], _biases['bc10'], k_conv,pad=pad, name='conv10')
	conv10 = tf.nn.dropout(conv10, _dropout[4])
	
	
	def conv2d_transpose(name_or_scope, input_tensor, out_ch, ksize=3, stride=2, re_shape=None, padding=pad):
		strides = [1, stride, stride, 1]
		debug = False
		with tf.variable_scope(name_or_scope):
			in_ch = input_tensor.get_shape()[3].value
			
			if re_shape is None:
				# get shape out of input_tensor
				in_shape = tf.shape(input_tensor)
				if debug:
					print 'input shape:', in_shape.get_shape()
				
				if (padding is 'SAME'):
					out_h = in_shape[1] * stride  # 20*2 = 40
					out_w = in_shape[2] * stride  # 20*2 = 40
				elif padding is 'VALID':
					out_h = ((in_shape[1] - 1) * stride) - 1  # (20-1)*2 -1 = 38
					out_w = ((in_shape[2] - 1) * stride) - 1  # (20-1)*2 -1 = 38
				# out_h = ((in_shape[1] - 1) * stride) + 1 #
				# out_w = ((in_shape[2] - 1) * stride) + 1
				new_shape = [in_shape[0], out_h, out_w,
				             out_ch]  # batch size, h,w,ch: ?,20,20,32, ch is num of classes
			else:
				# or from defined re_shape
				new_shape = [re_shape[0], re_shape[1], re_shape[2], out_ch]
			output_shape = tf.pack(new_shape)  # ?,40,40,32
			
			print '\nup Layer: %s, ch-in: %d, ch-out: %d' % (name_or_scope, in_ch, out_ch)
			weights_tensor_shape = [ksize, ksize, out_ch, in_ch]  # 3,3,32,32
			
			# create weights tensor for transpose
			num_input = ksize * ksize * in_ch / stride  # 3x3x32/2 = 9x16
			stddev = (2 / num_input) ** 0.5  # 2/(9x16) ** 0.5 = 1/72 ** 0.5 #'**' uppacking args list
			# using stddev = 0.1 the same value as for other nodes produces better learning speed
			# 1_0_diff increases quicker, once pred_train for one of labels becomes 0, the training must be
			# terminated, otherwise, the other values will also be trained to be 0.
			weights = tf.get_variable('w_transp', weights_tensor_shape,
			                          initializer=tf.truncated_normal_initializer(stddev=0.1, seed=SEED))
			
			# weights = self.get_deconv_filter(weight_tensor_shape)
			deconv = tf.nn.conv2d_transpose(input_tensor, weights, output_shape,
			                                strides=strides, padding=pad)
			# conv=tf.nn.conv2d(img,w,strides=[1,k,k,1],padding)
			# add=tf.nn.bias_add(conv,bias_)
			# activation=tf.nn.relu(add,name=name)
			# tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(img, w, strides=[1, k, k, 1], padding=pad), b),name=name)
			
			# initialize bias
			bias = tf.get_variable('b', [out_ch], initializer=tf.truncated_normal_initializer(0.1, seed=SEED))
			# bias = tf.get_variable('b', [output_ch], initializer=tf.truncated_normal_initializer(0.1, seed=SEED))
			
			deconv_add = tf.nn.bias_add(deconv, bias)
			activation = tf.nn.relu(deconv_add)
			
			if debug:
				deconv = tf.Print(deconv, [tf.shape(deconv)],
				                  message='Shape of %s' % name_or_scope,
				                  summarize=4, first_n=1)
		
		return activation
	
	# UP_1
	# re_shape:[?,h,w,ch]
	up1 = conv2d_transpose('up1', conv10, 4*u, ksize=3, stride=2, re_shape=None, padding=pad) #(?, 40, 40, 32)
	
	concat_axis = 3
	up1_concat = tf.concat(concat_axis, [conv8, up1])  # conv8: 40,40,32, merged: (?, 40, 40, 64)
	
	up1_concatd = tf.nn.dropout(up1_concat, _dropout[5])
	# - Convolution Layer 11,12
	conv11 = conv2d(up1_concatd, _weights['wc11'], _biases['bc11'], k_conv, name='conv11')  # conv11_out = 32
	conv12 = conv2d(conv11, _weights['wc12'], _biases['bc12'], k_conv, name='conv12')
	
	##########################################################
	# UP_2
	up2 = conv2d_transpose('up2', conv12, 4*u, ksize=3, stride=2, re_shape=None, padding=pad)
	
	up2s = tf.slice(up2, [0, 0, 0, 0], [0, 80, 80,     2*u])
	conv6s = tf.slice(conv6, [0, 0, 0, 0], [0, 80, 80, 2*u])
	concat_axis = 3
	up2_concat1 = tf.concat(concat_axis, [conv6s, up2s], name='up2conv6')  # conv6: 80,80,32
	# the input ch for conv13 is 32, so the output ch for up2_concat must be reduced to 32
	#tf.random_crop(value, size, seed=None, name=None)
	#up2_concats = tf.slice(up2_concat, [1:-1, 0, 0, 0], [1:-1, 80, 80, 4*u]) #[1:-1, :, :, :]
	#up2_concats = tf.slice(up2_concat, [0, 0, 0, 0], [0, 80, 80, 4*u]) #[1:-1, :, :, :] #(up2conv6, Slice/begin, Slice/size)
	
	#up2_concat = conv2d(up2_concat1, _weights['concat2'], _biases['bc_concat2'], k_conv, name='concat2')
	
	up2_concatd = tf.nn.dropout(up2_concat1, _dropout[6])
	
	# - Convolution Layer 13,14
	conv13 = conv2d(up2_concatd, _weights['wc13'], _biases['bc13'], k_conv, name='conv13') #32
	conv14 = conv2d(conv13, _weights['wc14'], _biases['bc14'], k_conv, name='conv14')
	
	##########################################################
	# UP_3
	up3 = conv2d_transpose('up3', conv14, 2*u, ksize=3, stride=2, re_shape=None, padding=pad)  # ?, 160, 160, 32  16

	conv4s = tf.slice(conv4, [0, 0, 0, 0], [0, 160, 160, 2*u])  #  cov4  # ?, 160, 160,16
	up3s   = tf.slice(up3, [0, 0, 0, 0], [0, 160, 160,   2*u])
	concat_axis = 3
	up3_concat1 = tf.concat(concat_axis, [conv4s, up3s])

	up3_concatd = tf.nn.dropout(up3_concat1, _dropout[7])
	
	
	# - Convolution Layer 15,16
	conv15 = conv2d(up3_concatd, _weights['wc15'], _biases['bc15'], k_conv, name='conv15')  #16, 16
	conv16 = conv2d(conv15, _weights['wc16'], _biases['bc16'], k_conv, name='conv16')
	# conv16 can be 8
	
	##########################################################
	# UP_4 (16-in, 8-out)
	
	if PRINT_ARCHI:
		print 'input tensor', _X.get_shape()
		print 'conv1 ( f=', filter_size, 'k=', k_conv, ')', conv1.get_shape()
		print 'conv2 ( f=', filter_size, 'k=', k_conv, ')', conv2.get_shape(), '<===4'
		print 'conv2 - max pooling (k=', k_pool, ')', pool1.get_shape()
		print '- dropout ( keep rate', dropout[0], ')', pool1d.get_shape()
		print '\nconv3 ( f=', filter_size, 'k=', k_conv, ')', conv3.get_shape()
		print 'conv4 ( f=', filter_size, 'k=', k_conv, ')', conv4.get_shape(), '<===3'
		print 'conv4 max pooling ( k=', k_pool, ')', pool2.get_shape()
		print '- dropout ( keep rate', dropout[1], ')', pool2d.get_shape()
		print '\nconv5 ( f=', filter_size, 'k=', k_conv, ')', conv5.get_shape()
		print 'conv6 ( f=', filter_size, 'k=', k_conv, ')', conv6.get_shape(), '<===2'
		print 'conv6 max pooling ( k=', k_pool, ')', pool3.get_shape()
		print '- dropout ( keep rate', dropout[2], ')', pool3d.get_shape()
		print '\nconv7 ( f=', filter_size, 'k=', k_conv, ')', conv7.get_shape()
		print 'conv8 ( f=', filter_size, 'k=', k_conv, ')', conv8.get_shape(), '<===1'
		print 'conv8 max pooling ( k=', k_pool, ')', pool4.get_shape()
		print '- dropout ( keep rate', dropout[3], ')', pool4d.get_shape()
		print '\nconv9 ( f=', filter_size, 'k=', k_conv, ')', conv9.get_shape()
		print 'conv10 ( f=', filter_size, 'k=', k_conv, ')', conv10.get_shape()
		print '- dropout ( keep rate', dropout[4], ')', conv10.get_shape()
		print 'conv8 shape:', conv8.get_shape(), ',  up1 transpose shape:', up1.get_shape(), '<=== 1'  # [?,40,40,32]
		print 'up1,conv8 concat(a=', concat_axis, ') shape:', up1_concat.get_shape()
		print 'up1 concat - dropout ( keep rate', dropout[5], ')', up1_concatd.get_shape()
		print '\nconv11 ( f=', filter_size, 'k=', k_conv, ')', conv11.get_shape()
		print 'conv12 ( f=', filter_size, 'k=', k_conv, ')', conv12.get_shape()
		print 'conv6 shape:', conv6.get_shape(), ',  up2 transpose shape:', up2.get_shape(), '<=== 2'
		#print 'up2,conv6 concat (a=', concat_axis, ') shape:', up2_concat.get_shape()
		#print 'up2_concat slice shape:', up2_concats.get_shape()
		print '- merge conv6, dropout ( keep rate', dropout[6], ')', up2_concatd.get_shape()  # ?, 80, 80, 64
		print '\nconv13 ( f=', filter_size, 'k=', k_conv, ')', conv13.get_shape()  # ?, 80, 80, 32
		print 'conv14 ( f=', filter_size, 'k=', k_conv, ')', conv14.get_shape()  # ?, 80, 80, 32
		print '\nup3 transposed shape:', up3.get_shape()
		print 'conv4:', conv4.get_shape(), ',  up3:', up3.get_shape()
		#print 'conv4 slice:', conv4s.get_shape(), ',  up3 slice:', up3s.get_shape(), '<=== 3'
		#print 'up3,conv4s concat(a=', concat_axis, ') shape:', up3_concat.get_shape()  # (?, 160, 160, 48)    #use slice (1, 160, 160, 32)
		print '- up3 concat, dropout ( keep rate', dropout[7], ')', up3_concatd.get_shape()  # ?, 160, 160, 48
		print '\nconv15 ( f=', filter_size, 'k=', k_conv, ')', conv15.get_shape()  # ?, 160, 160, 16
		print 'conv16 ( f=', filter_size, 'k=', k_conv, ')', conv16.get_shape()  # ?, 160, 160, 8
	
	up4 = conv2d_transpose('up4', conv16, u, ksize=3, stride=2, re_shape=None, padding=pad) #tmp u to 2u
	print '\nup4 transposed shape:', up4.get_shape()  # (?, 320, 320, 8)
	
	#up4s = tf.slice(up4,[0,0,0,0], [0,320,320,8])
	#print 'conv2:', conv2.get_shape(), ',  up4:', up4s.get_shape(), '<=== 4'  # conv2: (?, 320, 320, 8)
	
	concat_axis = 0
	up4_concat1 = tf.concat(concat_axis, [conv2, up4]) #-1,320,320,8
	print 'up4_concat1:', up4_concat1.get_shape()
	
	#up4_concat = conv2d(up4_concat1, _weights['concat4'], _biases['bc_concat4'], k_conv, name='concat4')
	
	#concat_axis = 3
	#up4_concat = tf.concat(concat_axis, [up4_concat, up4s]) #-1,320,320,16
	#print 'up4_concat:', up4_concat.get_shape()
	
	#print 'up4,conv2 concat (a=', concat_axis, ') shape:', up4_concat.get_shape()
	# conv4 first output size (?, 160, 160, 16)
	up4_concat = tf.nn.dropout(up4_concat1, _dropout[8])
	print '- dropout ( keep rate', dropout[8], ')', up4_concat.get_shape()
	
	# - Convolution Layer 17,18
	conv17 = conv2d(up4_concat, _weights['wc17'], _biases['bc17'], k_conv, name='conv17')
	#                                 8, 8
	print '\nconv17 ( f=', filter_size, 'k=', k_conv, ')', conv17.get_shape()  # ?, 320, 320, 8
	
	conv18 = conv2d(conv17, _weights['wc18'], _biases['bc18'], k_conv, name='conv18')
	print 'conv18 ( f=', filter_size, 'k=', k_conv, ')', conv18.get_shape()  # ?, 320, 320, 8

	# without activation, many outputs are negative, so should not use
	# or use relu, when it combined with softmax logits, all values go to 1 quickly
	# conv19 = conv2d(conv18, _weights['wc19'], _biases['bc19'], k_out, name='conv19')
	#
	# or use sigmoid activation for final conv layer, when it combined with softmax logits, all values go to 0 quickly
	# tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(img, w, strides=[1, k, k, 1], padding='SAME'), b))
	#
	
	
	conv19 = tf.nn.sigmoid(tf.nn.bias_add(tf.nn.conv2d(conv18, _weights['wc19'],
	              strides=[1, k_out, k_out, 1], padding=pad), _biases['bc19']),name='conv19')  # 1, 1
	print '\nconv19 ( f=', filter_size, 'k=', k_out, ')', conv19.get_shape()  # ?, 320, 320, 1
	
	
	
	# Output, class prediction
	#annotation_pred_max = tf.argmax(conv19, dimension=3)
	annotation_pred_max = tf.argmax(conv19, axis=3) #use tf.abs not work
	#annotation_pred_max = tf.argmax(conv19, axis=3)
	annotation_pred = tf.expand_dims(annotation_pred_max, dim=3, name='prediction')
	
	return [_X, conv1, conv2, conv3, conv4, conv5, conv6, conv7, \
	        conv8, conv9, conv10, up1, conv11, conv12, up2, conv13, conv14, up3, conv15,
	        conv16, up4, conv17, conv18, conv19, annotation_pred]


###################################################################
def define_model():
	# General input for tensorflow
	# hy: Graph input, same placeholders for various architectures
	x = tf.placeholder(tf.float32, [None, IMAGE_SIZE, IMAGE_SIZE, input_ch], name="x")
	
	################################################ Graph 4conv begin
	keep_prob = tf.placeholder(tf.float32, len(dropout), name="keep_prob")
	# hy: define receptive field size
	filter_size, filter_size_out = 3, 1
	k_conv, k_out, k_pool = 1, 1, 2
	
	
	SEED = 8  # hy: number of filters in conv1  8, 16, 64
	conv1_out, conv2_out, conv3_out, conv4_out = u, u, 2*u, 2*u
	conv5_out, conv6_out, conv7_out, conv8_out, conv9_out, conv10_out = 4*u, 4*u, 4*u, 4*u, 4*u, 4*u
	
	# must use the same name for up1 here and in net
	#up1, concat1, conv11_out, conv12_out, up2, concat2, conv13_out, conv14_out = 4*u, 8*u, 4*u, 4*u, 4*u, 4*u, 4*u, 4*u  # concat2:64 or 32
	up1,   concat1, conv11_out, conv12_out, up2,   concat21, concat2, conv13_out, conv14_out \
    = 4*u, 8*u,     4*u,        4*u,        4*u,    4*u,     4*u,     4*u,        4*u  # concat2:64 or 32
	
	## upsampling using fcn deconv
	# up3, concat3, conv15_out, conv16_out,  up4,concat4, conv17_out, conv18_out = 32, 16, 16, 8,         16, 8,  8,  8  # conv16_out:16 or 8
	
	# upsampling using version 1
	#up3, concat3, conv15_out, conv16_out,    up4, concat4, conv17_out, conv18_out = 4*u, 4*u, 2*u, u,       2*u, u, u, u  # conv16_out:16 or 8
	#                                                                                  ^
	
	up3,   concat31, concat3,   conv15_out, conv16_out,     up4, concat41,concat4, conv17_out, conv18_out \
	= 2*u, 4*u,      4*u,       2*u,        2*u,            u,   u,        u,       u,          u  # conv16_out:16 or 8
	# stddev = sqrt(2 / fan_in)  #np.random.randn(n) / sqrt(n)
	
	weights = {
		'wc1': tf.Variable(
			tf.truncated_normal([filter_size, filter_size, input_ch, conv1_out], stddev=np.sqrt(2.0 / SEED).astype(np.float32),
			                    seed=SEED),
			name="wc1"),
		
		'wc2': tf.Variable(
			tf.truncated_normal([filter_size, filter_size, SEED, conv2_out], stddev=np.sqrt(2.0 / SEED).astype(np.float32),
			                    seed=SEED),
			name="wc2"),
		'wc3': tf.Variable(tf.truncated_normal([filter_size, filter_size, conv2_out, conv3_out],
		                                       stddev=np.sqrt(2.0 / conv2_out).astype(np.float32), seed=SEED),
		                   name="wc3"),
		'wc4': tf.Variable(tf.truncated_normal([filter_size, filter_size, conv3_out, conv4_out],
		                                       stddev=np.sqrt(2.0 / conv3_out).astype(np.float32), seed=SEED),
		                   name="wc4"),
		'wc5': tf.Variable(tf.truncated_normal([filter_size, filter_size, conv4_out, conv5_out],
		                                       stddev=np.sqrt(2.0 / conv4_out).astype(np.float32), seed=SEED),
		                   name="wc5"),
		'wc6': tf.Variable(tf.truncated_normal([filter_size, filter_size, conv5_out, conv6_out],
		                                       stddev=np.sqrt(2.0 / conv5_out).astype(np.float32), seed=SEED),
		                   name="wc6"),
		'wc7': tf.Variable(tf.truncated_normal([filter_size, filter_size, conv6_out, conv7_out],
		                                       stddev=np.sqrt(2.0 / conv6_out).astype(np.float32), seed=SEED),
		                   name="wc7"),
		'wc8': tf.Variable(tf.truncated_normal([filter_size, filter_size, conv7_out, conv8_out],
		                                       stddev=np.sqrt(2.0 / conv7_out).astype(np.float32), seed=SEED),
		                   name="wc8"),
		'wc9': tf.Variable(tf.truncated_normal([filter_size, filter_size, conv8_out, conv9_out],
		                                       stddev=np.sqrt(2.0 / conv8_out).astype(np.float32), seed=SEED),
		                   name="wc9"),
		'wc10': tf.Variable(tf.truncated_normal([filter_size, filter_size, conv9_out, conv10_out],
		                                        stddev=np.sqrt(2.0 / conv9_out).astype(np.float32), seed=SEED),
		                    name="wc10"),
		
		'up1': tf.Variable(tf.truncated_normal([filter_size, filter_size, conv10_out, up1],
		                                       stddev=np.sqrt(2.0 / conv10_out).astype(np.float32), seed=SEED)),
		'concat1': tf.Variable(
			tf.truncated_normal([filter_size, filter_size, up1, concat1], stddev=np.sqrt(2.0 / up1).astype(np.float32),
			                    seed=SEED)),
		
		'wc11': tf.Variable(tf.truncated_normal([filter_size, filter_size, concat1, conv11_out],
		                                        stddev=np.sqrt(2.0 / concat1).astype(np.float32), seed=SEED),
		                    name="wc11"),
		'wc12': tf.Variable(tf.truncated_normal([filter_size, filter_size, conv11_out, conv12_out],
		                                        stddev=np.sqrt(2.0 / conv11_out).astype(np.float32), seed=SEED),
		                    name="wc12"),
		
		'up2': tf.Variable(tf.truncated_normal([filter_size, filter_size, conv12_out, up2],
		                                       stddev=np.sqrt(2.0 / conv12_out).astype(np.float32), seed=SEED)),
		
		'concat21': tf.Variable(
			tf.truncated_normal([filter_size, filter_size, up2, concat21], stddev=np.sqrt(2.0 / up2).astype(np.float32),
			                    seed=SEED)),
		
		'concat2': tf.Variable(
			tf.truncated_normal([filter_size, filter_size, concat21, concat2], stddev=np.sqrt(2.0 / concat21).astype(np.float32),
			                    seed=SEED)),
		
		'wc13': tf.Variable(tf.truncated_normal([filter_size, filter_size, concat2, conv13_out],
		                                        stddev=np.sqrt(2.0 / concat2).astype(np.float32), seed=SEED),
		                    name="wc13"),
		'wc14': tf.Variable(tf.truncated_normal([filter_size, filter_size, conv13_out, conv14_out],
		                                        stddev=np.sqrt(2.0 / conv13_out).astype(np.float32), seed=SEED),
		                    name="wc14"),
		
		'up3': tf.Variable(tf.truncated_normal([filter_size, filter_size, conv14_out, up3],
		                                       stddev=np.sqrt(2.0 / conv14_out).astype(np.float32), seed=SEED)),
		'concat31': tf.Variable(
			tf.truncated_normal([filter_size, filter_size, up3, concat31], stddev=np.sqrt(2.0 / up3).astype(np.float32),
			                    seed=SEED)),
		
		'concat3': tf.Variable(
			tf.truncated_normal([filter_size, filter_size, concat31, concat3], stddev=np.sqrt(2.0 / concat31).astype(np.float32),
			                    seed=SEED)),
		
		'wc15': tf.Variable(tf.truncated_normal([filter_size, filter_size, concat3, conv15_out],
		                                        stddev=np.sqrt(2.0 / concat3).astype(np.float32), seed=SEED),
		                    name="wc15"),
		'wc16': tf.Variable(tf.truncated_normal([filter_size, filter_size, conv15_out, conv16_out],
		                                        stddev=np.sqrt(2.0 / conv15_out).astype(np.float32), seed=SEED),
		                    name="wc16"),
		
		'up4': tf.Variable(tf.truncated_normal([filter_size, filter_size, conv16_out, up4],
		                                       stddev=np.sqrt(2.0 / conv16_out).astype(np.float32), seed=SEED)),
		'concat41': tf.Variable(
			tf.truncated_normal([filter_size, filter_size, up4, concat41], stddev=np.sqrt(2.0 / up4).astype(np.float32),
			                    seed=SEED)),
		
		'concat4': tf.Variable(
			tf.truncated_normal([filter_size, filter_size, concat41, concat4], stddev=np.sqrt(2.0 / concat41).astype(np.float32),
			                    seed=SEED)),
		
		'wc17': tf.Variable(tf.truncated_normal([filter_size, filter_size, concat4, conv17_out],
		                                        stddev=np.sqrt(2.0 / concat4).astype(np.float32), seed=SEED),
		                    name="wc17"),
		'wc18': tf.Variable(tf.truncated_normal([filter_size, filter_size, conv17_out, conv18_out],
		                                        stddev=np.sqrt(2.0 / conv17_out).astype(np.float32), seed=SEED),
		                    name="wc18"),
		'wc19': tf.Variable(tf.truncated_normal([filter_size_out, filter_size_out, conv18_out, conv19_out],
		                                        stddev=np.sqrt(2.0 / conv18_out).astype(np.float32), seed=SEED),
		                    name="wc19"),
	}
	
	biases = {
		'bc1': tf.Variable(tf.truncated_normal([conv1_out]), name="bc1"),
		'bc2': tf.Variable(tf.truncated_normal([conv2_out]), name="bc2"),  # hy: use variable, instead fixed number
		'bc3': tf.Variable(tf.truncated_normal([conv3_out]), name="bc3"),
		'bc4': tf.Variable(tf.truncated_normal([conv4_out]), name="bc4"),
		'bc5': tf.Variable(tf.truncated_normal([conv5_out]), name="bc5"),
		'bc6': tf.Variable(tf.truncated_normal([conv6_out]), name="bc6"),
		'bc7': tf.Variable(tf.truncated_normal([conv7_out]), name="bc7"),
		'bc8': tf.Variable(tf.truncated_normal([conv8_out]), name="bc8"),
		'bc9': tf.Variable(tf.truncated_normal([conv9_out]), name="bc9"),
		'bc10': tf.Variable(tf.truncated_normal([conv10_out]), name="bc10"),
		
		'bc_up1': tf.Variable(tf.truncated_normal([up1])),
		'bc_concat1': tf.Variable(tf.truncated_normal([concat1])),
		
		'bc11': tf.Variable(tf.truncated_normal([conv11_out]), name="bc11"),
		'bc12': tf.Variable(tf.truncated_normal([conv12_out]), name="bc12"),
		
		'bc_up2': tf.Variable(tf.truncated_normal([up2])),
		'bc_concat21': tf.Variable(tf.truncated_normal([concat21])),
		'bc_concat2': tf.Variable(tf.truncated_normal([concat2])),
		
		'bc13': tf.Variable(tf.truncated_normal([conv13_out]), name="bc13"),
		'bc14': tf.Variable(tf.truncated_normal([conv14_out]), name="bc14"),
		
		'bc_up3': tf.Variable(tf.truncated_normal([up3])),
		'bc_concat31': tf.Variable(tf.truncated_normal([concat31])),
		'bc_concat3': tf.Variable(tf.truncated_normal([concat3])),
		
		'bc15': tf.Variable(tf.truncated_normal([conv15_out]), name="bc15"),
		'bc16': tf.Variable(tf.truncated_normal([conv16_out]), name="bc16"),
		
		'bc_up4': tf.Variable(tf.truncated_normal([up4])),
		'bc_concat41': tf.Variable(tf.truncated_normal([concat41])),
		'bc_concat4': tf.Variable(tf.truncated_normal([concat4])),
		
		'bc17': tf.Variable(tf.truncated_normal([conv17_out]), name="bc17"),
		'bc18': tf.Variable(tf.truncated_normal([conv18_out]), name="bc18"),
		'bc19': tf.Variable(tf.truncated_normal([conv19_out]), name="bc19"),
	}
	
	# hy: try with zero mean
	# tf.image.per_image_whitening(x)
	# this operation computes (x-mean)/adjusted_stddev
	
	#################################
	# tmp: test
	[_X, conv1, conv2, conv3, conv4, conv5, conv6, conv7, \
	 conv8, conv9, conv10, up1, conv11, conv12, up2, conv13, conv14, up3, conv15, \
	 conv16, up4, conv17, conv18, conv19, annotation_pred] \
		= conv_net(x, weights, biases, keep_prob, filter_size, filter_size_out, k_conv, k_pool, k_out, SEED)
	
	#################################
	y = tf.placeholder(tf.float32, shape=[None, IMAGE_SIZE, IMAGE_SIZE, 1], name="y")
	# logits = conv19,  labels: y
	y_int = tf.cast(y, tf.int32)
	#sparse_softmax can only take [0,3) for y and logits
	cost = tf.reduce_mean((tf.nn.sparse_softmax_cross_entropy_with_logits(logits=conv19,
	                                                                      labels=tf.squeeze(y_int, squeeze_dims=[3]),
	                                                                      name="loss")))
	#conv19 = tf.reshape(conv19, shape=[None,IMAGE_SIZE,IMAGE_SIZE,3])
	
	#cost = tf.reduce_mean((tf.nn.softmax_cross_entropy_with_logits(logits=conv19,
	#																	  labels=y_int,
	#																	  name="loss")))

	#############################################################################
	# Define loss function and optimizer
	# ****************************************************************************
	# ****************************************************************************
	trainable_var = tf.all_variables()
	if optimizer_type == 'adam':
		# hy: Adam with these parameters beta1=0.9,beta2=0.999, epsilon=1e-08 etc the training
		# accuracy is not stable, epsilon = 0.01 better for these data
		print '\noptimizer:', optimizer_type, 'learning_rate:', learning_rate, '\nbeta11:', beta1, \
			'\tbeta2:', beta2, '\tepsilon:', epsilon
		# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1, beta2=beta2, epsilon=epsilon,
		#                                  use_locking=False, name='Adam').minimize(cost)
		# trainable_var = tf.all_variables()
		optimizer = tf.train.AdamOptimizer(learning_rate)
		grads = optimizer.compute_gradients(cost, var_list=trainable_var)
		optimize_op = optimizer.apply_gradients(grads)  # must feed optimizer... to a variable to be as tensor run in sess
	
	# hy: Adam with only learning rate as parameter can also be used to continue a training that was done previously with beta,epsilon setup
	# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # TODO change to ADAM
	if optimizer_type == 'GD':
		# hy: GradientDescentOptimizer
		print '\noptimizer:', optimizer_type, '\tlearning_rate:', learning_rate
		optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate, name="GD").minimize(cost)
	# for learning_rate_i in xrange(5):
	# optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate_i*(1+learning_rate_i*0.000001),name="GD").minimize(cost)
	
	if optimizer_type == 'SGD':
		print '\noptimizer:', optimizer_type, '\tlearning_rate:', learning_rate, '\tmomentum:', momentum_SGD
		optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=momentum_SGD, name='SGD').minimize(
			cost)
	# = tf.train.MomentumOptimizer(LEARNING_RATE, MOMENTUM).minimize(cost)
	
	#################################################################
	# Build the summary operation based on the TF collection of Summaries.
	# Adding variables to be visualized
	tf.summary.scalar('Loss', cost)
	# tf.summary.image("a_ground_truth", tf.cast(y*255, tf.uint8), max_outputs=2)    #tf.cast(annotation, tf.uint8)
	tf.summary.image("a_ground_truth", tf.reshape(tf.to_float(y), shape=[-1, IMAGE_SIZE, IMAGE_SIZE, 1]), max_outputs=2)
	tf.summary.image("b_pred", tf.reshape(tf.to_float(annotation_pred * 255), shape=[-1, IMAGE_SIZE, IMAGE_SIZE, 1]),
	                 max_outputs=4)
	
	#tf.summary.image('c_conv19', tf.reshape(conv19*255, shape=[-1, IMAGE_SIZE, IMAGE_SIZE, conv19_out]), max_outputs=4)
	#c_conv19_s1 = tf.slice(conv19, [0, 0, 0, 0], [0, IMAGE_SIZE, IMAGE_SIZE, 1])
	#c_conv19_s2 = tf.slice(conv19, [0, 0, 0, 0], [0, IMAGE_SIZE, IMAGE_SIZE, 2])
	tf.summary.image('c_conv19', tf.reshape(conv19*255, shape=[-1, IMAGE_SIZE, IMAGE_SIZE, 1]), max_outputs=4)
	#tf.summary.image('c_conv19s2', tf.reshape(c_conv19_s2*255, shape=[-1, IMAGE_SIZE, IMAGE_SIZE, 1]), max_outputs=4)
	tf.summary.image('c_ori_rgb', tf.reshape(x * 255, shape=[-1, IMAGE_SIZE, IMAGE_SIZE, input_ch]), max_outputs=4)
	
	def view_conv_(layers, layer_names):
		for layer, layer_name in zip(layers, layer_names):
			conv_view_size = layer.get_shape().as_list()[1]
			tf.summary.image(layer_name, tf.reshape(layer, shape=[-1, conv_view_size, conv_view_size, 1]), max_outputs=4)
	
	view_conv_([conv1, conv3, conv5, conv7, conv10],
	           ['conv1', 'conv3', 'conv5', 'conv7', 'conv10'])

	
	##############
	tf.summary.histogram('histogram_conv1w', weights['wc1'])
	tf.summary.histogram('histogram_conv10w', weights['wc10'])
	tf.summary.histogram('histogram_conv19w', weights['wc19'])
	
	summary_op = tf.summary.merge_all()
	
	return (learning_rate, dropout, dropout_1s, optimizer_type, classifier_tpye, loss_type,
	        x,y, y_int, keep_prob, optimizer, cost, summary_op, optimize_op,
	        conv19_out, conv19, annotation_pred)


import keras
import seg_net_arch as u_a
import tensorflow as tf
import numpy as np


def init_tf_var():
	x = tf.placeholder(tf.float32, shape=(None, IMAGE_SIZE, IMAGE_SIZE, 3), name='x')
	y = tf.placeholder(tf.float32, shape=(None, IMAGE_SIZE, IMAGE_SIZE, 1), name='y')
	
	test_result = tf.placeholder(tf.float32, shape=(None, IMAGE_SIZE, IMAGE_SIZE, 1), name='test_result')
	conv19view = tf.placeholder(tf.float32, shape=(None, IMAGE_SIZE, IMAGE_SIZE, 1), name='conv19view')
	dropout = [0.15, 0.25, 0.4, 0.45, 1, 0.4, 0.25, 0.15, 0.15]
	keep_prob = tf.placeholder(tf.float32, len(dropout), name="keep_prob")
	dropout_1s = [1] * len(dropout)
	######
	tf.summary.image('original_rgb', tf.reshape(x, shape=[-1, IMAGE_SIZE, IMAGE_SIZE, 3]), max_outputs=4)
	tf.summary.image('ground_truth', tf.reshape(y, shape=[-1, IMAGE_SIZE, IMAGE_SIZE, 1]), max_outputs=4)
	tf.summary.image('test_result', tf.reshape(test_result, shape=[-1, IMAGE_SIZE, IMAGE_SIZE, 1]), max_outputs=4)
	##############
	summary_op = tf.summary.merge_all()
	##############
	return x, y, conv19view, test_result, keep_prob, dropout, dropout_1s, summary_op


def run_model_k(images, masks):
	keras.callbacks.History()
	epochs = 3000  # 1200
	learning_rate = 0.0002
	decay_rate = learning_rate / epochs
	momentum = 0.99
	sgd = u_a.SGD(lr=learning_rate, momentum=momentum)  # hy:decay_rate
	model, conv19 = u_a.get_model(IMAGE_SIZE, IMAGE_SIZE)  # (?, 1, 320, 320)
	
	##############
	'''
	conv19view = tf.transpose(conv19, perm=[0,2,3,1])
	print 'conv19 shape:', conv19.get_shape()
	tf.summary.image('conv19', tf.reshape(conv19, shape=[-1, 320, 320, 1]), max_outputs=4)
	batch_xs = np.transpose(images, (0, 3, 1, 2))  # -1,3, 320,320
	batch_ys = np.transpose(masks, (0, 3, 1, 2))  # -1,3, 320,320
	######
	tf.summary.image('original_color', tf.reshape(input_img, shape=[-1, 320, 320, 1]), max_outputs=4)
	#tf.summary.image("ground_truth", tf.reshape(tf.to_float(y), shape=[-1, tensor_h, tensor_w, 1]), max_outputs=2)
	#tf.summary.image('conv19_255', tf.reshape(conv19_255, shape=[-1, tensor_h, tensor_w, 1]), max_outputs=4)

	##############
	tf.summary.histogram('histogram_conv19', conv19view)
	summary_op = tf.summary.merge_all()
	##############
	train_res = sess.run(summary_op, feed_dict={'x:0': batch_xs[0], 'y:0': batch_ys[0], 'keep_prob:0': dropout_1s})
	train_writer.add_summary(train_res, train_step)
	##############
	'''
	loss_type, optimizer_type = 'binary_crossentropy', 'sgd'
	model.compile(loss='binary_crossentropy', optimizer=sgd)
	
	# images.reshape((None,1,h,w))
	# fit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=[], validation_split=0.0, validation_data=None,
	#    shuffle=True, class_weight=None, sample_weight=None)
	# docu example
	# weights.{epoch:02d}-{val_loss:.2f}.hdf5 # val_loss, must first define validation set
	# '/Users/Alex/checkpoint-{epoch:02d}-{val_loss:.2f}.hdf5')
	
	model_path = '../testbench/seg_mul/kintf_seg/'
	save_model_name = model_path + 'weights.{epoch:02d}'  # model_path + 'test_' + '{epoch:02d}.hdf5'
	save_params = keras.callbacks.ModelCheckpoint(filepath=model_path + 'weights.{epoch:02d}.hdf5',
	                                              monitor='val_loss', verbose=2,
	                                              save_best_only=False, save_weights_only=False, mode='auto')
	
	# keras.callbacks.TensorBoard(log_dir='../Tensorboard_data/sum108/', histogram_freq=1, write_graph=True, write_images=True)
	
	class LossHistory(keras.callbacks.Callback):
		def on_train_begin(self, logs={}):
			self.losses = []
		
		def on_batch_end(self, batch, logs={}):
			self.losses.append(logs.get('loss'))
	
	# train
	history_train = model.fit(images, masks, batch_size=1, nb_epoch=epochs, callbacks=[save_params], shuffle=True)
	
	history = LossHistory()
	print history.losses
	print 'val keys', history_train.history.keys()
	
	model.save(model_path + 'model_' + '.h5')
