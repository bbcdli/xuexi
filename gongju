
#####################################################################################################
from PIL import ImageDraw
from PIL import ImageFilter
from PIL import ImageOps
import time
import random
import glob
from functools import wraps
from random import randint
import os
import sys
import datetime
import settings  # hy: collection of global variables
import cv2
import numpy as np
import tensorflow as tf
from sklearn import datasets
import math
import imutils
from PIL import Image  # hy: create video with images

# activate global var
settings.set_global()
start_time = time.time()
# http://lvdmaaten.github.io/tsne/ visualization
## Train or Evaluation
############################################################
# act_min = 0.80
# act_max = 0.93
# add_data = 0 #initial
# area_step_size_webcam = 20 #479 #200
optimizer_type = 'GD'  # 'adam' #GD-'gradient.descent'
# n_hidden = 2000

# SAVE_Misclassified     = 0
# SAVE_CorrectClassified = 0

# GENERATE_FILELIST = 0
# log_on = False
DEBUG = 0
ImageType = '.jpg'
# Network Parameters
# n_input = settings.h_resize * settings.w_resize  #hy
n_classes = len(settings.LABELS)  # hy: adapt to lego composed of 6 classes. Cifar10 total classes (0-9 digits)
dropout = 0.8  # Dropout, probability to keep units

# Data
LABEL_LIST = settings.data_label_file
LABEL_PATH = settings.data_label_path

LABEL_LIST_TEST = settings.test_label_file
LABEL_PATH_TEST = settings.test_label_path5

LABELS = settings.LABELS  # hy
LABEL_names = settings.LABEL_names  # hy

# auto-switches  #########################
# result_for_table = 0

# hy:add timestamp to tensor log files
from datetime import datetime

tensorboard_path = '/tmp/Tensorboard_data/sum107/' + str(datetime.now()) + '/'


class Logger0(object):
	def __init__(self):
		self.terminal = sys.stdout
		from datetime import datetime
		str_log = optimizer_type
		self.log = open(datetime.now().strftime('log_%Y_%m_%d_%H_%M' + str_log + '.log'), "a")
	
	def write(self, message):
		self.terminal.write(message)
		self.log.write(message)
	
	def flush(self):
		# this flush method is needed for python 3 compatibility.
		# this handles the flush command by doing nothing.
		# you might want to specify some extra behavior here.
		pass
	
class Logger(object):
	log_path = ''
	str_log = ''
	def __init__(self,log_path,str_log):
		self.terminal = sys.stdout
		from datetime import datetime
		self.str_log = str_log
		self.log_path = log_path
		self.log = open(datetime.now().strftime(log_path + '%Y_%m_%d_%H_%M' + str_log + '.log'), "a")
	
	def write(self, message):
		self.terminal.write(message)
		self.log.write(message)
	
	def flush(self):
		# this flush method is needed for python 3 compatibility.
		# this handles the flush command by doing nothing.
		# you might want to specify some extra behavior here.
		pass

# if log_on and (RETRAIN or CONTINUE_TRAIN or TEST_with_Video):
#  sys.stdout = Logger()


def prepare_list(image_list_file, image_label_path):
	filelist = sorted(glob.glob(image_label_path))  # hy: sorted is used for doing active fields analysis
	Output_file = image_list_file
	
	if DEBUG:
		print filelist
	
	file_name_label = []
	
	# method 1
	# label_list = os.listdir(class_PATH)
	# print "class list:", label_list
	
	# method 2 same result as 1
	# class_label = next(os.walk(class_PATH))[1]
	# print "class_label:", class_label
	if not os.path.isdir(image_label_path):
		os.makedirs(image_label_path)
	
	if not os.path.isfile(Output_file):
		open(Output_file, 'w')
	
	for filename in filelist:
		class_index = 0
		for label in LABELS:  # hy search files under this path
			# label = class_PATH + label  #hy ../Data/2
			if str.find(filename, label) != -1:  # hy find all lines containing /Data/class_index
				file_name_label.append(filename + " " + str(class_index))
			# print file_name_label
			# else:
			#    print 'no folder found'
			class_index = class_index + 1
	
	lines = "\n".join(file_name_label)
	
	# write lines into the file
	with open(Output_file, 'w') as f:
		f.writelines(lines)
	
	# print "first line:"
	# with open(Output_file, 'r') as f:
	#    plines = [next(f) for x in xrange(1)]
	#    print plines
	
	if DEBUG:
		# method 1
		print "method 1: file length:", sum(1 for line in open(Output_file))
		
		# method 2
		with open(Output_file) as f:  # use "with sth as" to define a file
			print "method 2: file length:", sum(1 for line in f)
		
		# method 3
		with open(Output_file) as f:
			file_length = len(f.readlines())
			print "method 3: file length:", file_length
	
	print 'file list is created.', image_list_file, ', path', image_label_path


def read_images(filelist, random_read=True):
	# read file generated in .txt with prepare.py
	# print 'file list',filelist
	# filelist = '../FeatureMapList.txt'
	
	lable_file = open(filelist, 'r')
	lines = lable_file.readlines()
	
	if random_read == True:
		# make the file order in random way, this makes training more efficiently
		random.shuffle(lines)
		print 'loading images in random order'
	else:
		print 'loading sorted images'
	
	images = []
	labels = []
	files = []
	label_sum = 0
	
	for item in lines:
		filename, label = item.split()
		
		# print 'filename',filename
		
		im = cv2.imread(filename)
		im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
		im = transform_to_one_size(im)
		
		'''
		# im = imutils.resize(im, width = 72, height = 72) # w=146, h=121
		im_gray = imutils.resize(im, width=settings.w_resize, height=settings.h_resize)  # w=146, h=121
		# im=imutils.resize(cv2.cvtColor(cv2.imread(filename),cv2.COLOR_BGR2GRAY),width=42,height=24)
		# add ###################################################################################
		# resize to fit classifier model
		im_resize_gray = cv2.resize(im_gray, (settings.h_resize, settings.w_resize))
		im = np.float32(im_resize_gray.reshape(settings.h_resize, settings.w_resize))

		im = np.asarray(im, np.float32)
		'''
		
		# im = im.reshape((-1, im.size))
		# im = np.expand_dims(np.array(im), 2).astype(np.float32)
		########################################################################################
		
		# im=np.asarray(im, np.float32) #old
		
		images.append(im)
		labels.append(label)
		files.append(filename)
		label_sum = int(label) + label_sum
	
	images_np = np.asarray(images)
	labels_np = np.asarray(labels)
	#  #print "sum of labels:",label_sum #debug #hy need to correct
	#  tmp = Image.fromarray(images_np[2],'L')
	#  tmp.show()
	
	# print "h_resize = ", settings.h_resize
	# print "images_np array shape:",images_np.shape
	
	# print "im shape:", im.shape
	# print "total files:", len(files)
	return (images_np, labels_np, files)


def load_base_images_test_online(LABEL_LIST_TEST, LABEL_PATH_TEST, feed_train_data=False, feed_test_images=False,
                                 CREATE_FILELIST=False,
                                 CREATE_TESTLIST=False):
	images = []
	targets = []
	f = []
	
	if CREATE_TESTLIST:
		prepare_list(LABEL_LIST_TEST, LABEL_PATH_TEST)
	
	if feed_train_data:
		images, targets, f = read_images(LABEL_LIST, random_read=True)  ## hy: require read in random
	
	if feed_test_images:  ## hy: require read in order
		images, targets, f = read_images(LABEL_LIST_TEST, random_read=False)
	# tools.read_image_output_slices(LABEL_LIST_TEST) #hy: get slices for activation analysis
	return images, targets, f


def load_base_images(file, file_path, CREATE_FILELIST=False, random_read=False):
	if CREATE_FILELIST:
		prepare_list(file, file_path)
	
	images, targets, f = read_images(file, random_read=random_read)
	
	return images, targets, f


def load_base_imagesORI(feed_train_data=False, feed_test_images=False, CREATE_FILELIST=False, CREATE_TESTLIST=False):
	images = []
	targets = []
	f = []
	
	if CREATE_FILELIST:
		prepare_list(LABEL_LIST, LABEL_PATH)
	
	if CREATE_TESTLIST:
		prepare_list(LABEL_LIST_TEST, LABEL_PATH_TEST)
	
	if feed_train_data:
		images, targets, f = read_images(LABEL_LIST, random_read=True)  ## hy: require read in random
	
	if feed_test_images:  ## hy: require read in order
		images, targets, f = read_images(LABEL_LIST_TEST, random_read=False)
	# tools.read_image_output_slices(LABEL_LIST_TEST) #hy: get slices for activation analysis
	return images, targets, f


def rotateflipImg(patch_size=0, Rotation_Angle=0, Flip_X=0, noise_level=0, do_perspectiveTransform_in=0, step=0):  #
	# def rotateflipImg(Rotation_Angle,Flip_X,noise_level,step):
	INPUT_PATCHES_PATH = '../tmp/tmp2/'
	DATA_PATH = settings.data
	Clockwise = 0
	Anti_clockwise = 1
	Aspect_Factor = 0.2
	random_add = 4
	print 'doing rotation or flipping', Rotation_Angle, ',', Flip_X, ',st', step, \
		',noise=', noise_level, ',do_perspectiveTransform_in=', do_perspectiveTransform_in
	
	print 'removing tmp data'
	for i in xrange(len(settings.LABELS)):
		dir = settings.tmp + settings.LABELS[i]
		for f in os.listdir(dir):
			if re.search('/*.jpg', f) is not None:
				os.remove(os.path.join(dir, f))
	
	filelist = glob.glob(INPUT_PATCHES_PATH + '/*')
	
	# print 'filelist,', filelist
	for filename in filelist:
		for label in settings.LABELS:
			import string
			if string.find(filename + '/', label) != -1:  # hy:return index if found, or -1 if not found
				
				OUTPUT_PATH = DATA_PATH + label
				
				# If error occurs, possibly because some old file name errors, e.g. contain _ in the end'
				
				filelist_tmp = glob.glob(INPUT_PATCHES_PATH + label + '*')
				random.shuffle(filelist_tmp)
				
				# hy:use fixed additional amount of data
				# random_add = 1
				# random_add = 7*len(settings.LABELS)
				
				# hy: use proportional setting
				# random_add = int(len(filelist_tmp) * 0.70)
				
				filelist_add = filelist_tmp[0:random_add]
				
				# print len(filelist_tmp)
				# for file in filelist_tmp: #hy if all data should be used
				for file in filelist_add:  # hy if only part data should be used
					file.split('/')[-1]
					# print file.split('/')[-1]
					original = cv2.imread(file)
					Height, Width, Channel = original.shape
					# print original.shape
					
					### Rotation start ##############################################################
					if Anti_clockwise == 1 and Rotation_Angle <> 0:
						# Counter-Clockwise: Zooming in, rotating, cropping
						# rotated_tmp = cv2.resize(original, (Width + 40, Height + 20), interpolation=cv2.INTER_LINEAR)
						# rotated_tmp = imutils.rotate(rotated_tmp, angle=Rotation_Angle)
						# rotated = rotated_tmp[10:Height + 10, 20:Width + 20]
						# print rotated.shape
						# rotated = imutils.resize(rotated, width=Width,
						#        height=Height)
						rotated = imutils.rotate(original, angle=Rotation_Angle)
						new_file = OUTPUT_PATH + os.path.basename(os.path.normpath(file))[:-4] + '_st' + str(
							step) + '_rotatedCC_' + str(
							Rotation_Angle) + ImageType  # hy: split by .jpg, with '.' to avoid extra '.' in file name
						cv2.imwrite(new_file, rotated)
					
					if Clockwise == 1 and Rotation_Angle <> 0:
						# Clockwise
						rotated_tmp = cv2.resize(original, (Width + 40, Height + 20), interpolation=cv2.INTER_LINEAR)
						rotated_tmp = imutils.rotate(rotated_tmp, angle=Rotation_Angle * -1)
						rotated = rotated_tmp[10:Height + 10, 20:Width + 20]
						# print rotated.shape
						rotated = imutils.resize(rotated, width=Width, height=Height)
						new_file = OUTPUT_PATH + os.path.basename(os.path.normpath(file))[:-4] + '_st' + str(
							step) + '_rotatedC_' + str(Rotation_Angle) + ImageType
						cv2.imwrite(new_file, rotated)
					
					### Perspective Transform begin  #################################################
					f_outs = []
					if do_perspectiveTransform_in == 1:
						# print 'file',file
						# h, w, ch = original.shape
						# print 'h,w,ch', h, w, ch
						# rand1 = randint(2,30)
						# rand2 = randint(2,30)
						aspect_w = int(Aspect_Factor * Width)
						for i in xrange(aspect_w, aspect_w + 2):
							for j in xrange(14, 16):
								pts1 = np.float32([[i, 0], [Width - i, 0], [j, Height - j], [Width - i, Height - j]])
								# pts1 = np.float32([[rand1, 0], [patch_size+rand1, 0], [rand2, patch_size], [patch_size, patch_size]])
								pts2 = np.float32([[0, 0], [Width, 0], [0, Height], [Width, Height]])  # leftT,rT,leftB,rB
								# pts2 = np.float32([[0, 0], [patch_size, 0], [0, patch_size], [patch_size, patch_size]])  # leftT,rT,leftB,rB
								
								M = cv2.getPerspectiveTransform(pts1, pts2)
								
								dst = cv2.warpPerspective(original, M, (Width, Height))  # (w,h)
								# dst = cv2.warpPerspective(img,M,(patch_size,patch_size)) #(w,h)
								f_out = OUTPUT_PATH + os.path.basename(os.path.normpath(file))[:-4] + '_persp_' + str(i) + '_' + str(
									j) + ImageType
								# f_out = '../Data/data_1_mix/save/prep/' + os.path.basename(file) + '_persp_' + str(i) + '_' + str(j) + ImageType
								print f_out
								f_outs.append(f_out)
								cv2.imwrite(f_out, dst)
						print 'can generate num of new files with perspective transformation', len(f_outs)
					
					### Perspective Transform end    #################################################
					
					
					### add noise begin ##############################################################
					if noise_level <> 0:
						img_gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
						
						# img = img.astype(np.float32)
						img_noised = img_gray + np.random.rand(Width, Height) * noise_level
						img_noised = (img_noised / np.max(img_noised)) * 255
						new_file = OUTPUT_PATH + os.path.basename(os.path.normpath(file))[:-4] + '_st' + str(
							step) + '_NOI' + ImageType
						cv2.imwrite(new_file, img_noised)
					### add noise end    ##############################################################


def read_test_images(filelist):
	# read file generated in .txt with prepare.py
	
	lable_file = open(filelist, 'r')
	lines = lable_file.readlines()
	# make the file order in random way, this makes training more efficiently
	random.shuffle(lines)
	
	images = []
	labels = []
	files = []
	label_sum = 0
	
	for item in lines:
		filename, label = item.split()
		files.append(filename)
		labels.append(label)
	
	labels_np = np.asarray(labels)
	return (labels_np, files)


def read_image_output_slices(filelist):
	lable_file = open(filelist, 'r')
	lines = lable_file.readlines()
	# make the file order in random way, this makes training more efficiently
	random.shuffle(lines)
	
	images = []
	labels = []
	files = []
	label_sum = 0
	
	for item in lines:
		filename, label = item.split()
		
		# print filename
		_im = cv2.imread(filename)
		_im = cv2.cvtColor(_im, cv2.COLOR_BGR2GRAY)
		# im = imutils.resize(im, width = 72, height = 72) # w=146, h=121
		(w, h) = _im.shape  # hy:get suitable value for width
		num_of_parts_per_row = 4
		for row in xrange(0, num_of_parts_per_row):
			for col in xrange(0, num_of_parts_per_row):
				im = _im[72 / num_of_parts_per_row * col:72 / num_of_parts_per_row * (col + 1),
				     72 / num_of_parts_per_row * row:72 / num_of_parts_per_row * (row + 1)]  # x1:x2,y1:y2
				im = np.asarray(im, np.float32)
				
				images.append(im)
				labels.append(label)
				files.append(filename)
				label_sum = int(label) + label_sum
	
	images_np = np.asarray(images)
	labels_np = np.asarray(labels)
	print 'read_test_image() done'
	return (images_np, labels_np, files)


def read_images_online_FIRST(filelist='', random_read=True, Anti_clockwise=0, Clockwise=0, Rotation_Angle=0, Flip_X=0,
                             Flip_Y=0, noise_level=0, step=0):
	print filelist, random_read, Anti_clockwise, Clockwise, 'angle', Rotation_Angle, 'flip', Flip_X, Flip_Y, noise_level, step
	save_path = settings.data
	show = False
	lable_file = open(filelist, 'r')
	lines = lable_file.readlines()
	
	if random_read == True:
		# make the file order in random way, this makes training more efficiently
		random.shuffle(lines)
		print 'loading images in random order'
	else:
		print 'loading sorted images'
	
	images = []
	labels = []
	files = []
	
	for item, index in zip(lines, xrange(len(lines))):
		filename, label = item.split()
		name = os.path.basename(filename)[:-len(ImageType)]
		im = cv2.imread(filename)
		im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
		
		im_base = transform_to_one_size(im_gray)
		
		images, labels, files = add_to_images_list(im_base, label, filename, images, labels, files)
		cv2.imshow('im_base', im_base)
		
		############ add online data begin
		# Rotation_Angle = randint(15, 170)
		# noise_level = 0.01 * randint(1, 2)
		### Rotation start ##############################################################
		def add_rotation(im, Rotation_Angle, label, filename, images, labels, files, i=0, save_path='', name='', show=False,
		                 save_file=False):
			if Anti_clockwise == 1 and Rotation_Angle <> 0:
				# im = cv2.resize(im,(settings.w_resize,settings.h_resize), interpolation=cv2.INTER_LINEAR)
				# print 'received im for rotation h,w', im.shape[0], im.shape[1]
				rotated = imutils.rotate(im, angle=Rotation_Angle)
				images, labels, files = add_to_images_list(rotated, label, filename, images, labels, files)
				if show:
					cv2.imshow('ori' + str(i) + '_' + filename[:-8], rotated)
					cv2.waitKey(10)
					
					cv2.imshow('rota' + str(i) + '_' + str(Rotation_Angle) + filename[:-8], rotated)
					cv2.waitKey()
				if save_file:
					filename = save_path + name + '_' + str(i) + '_rota1_' + str(Rotation_Angle) + ImageType
					print 'filename', filename
					cv2.imwrite(filename, im)
				
				# im = cv2.resize(im,(settings.w_resize,settings.h_resize), interpolation=cv2.INTER_LINEAR)
				# print 'received im for rotation h,w', im.shape[0], im.shape[1]
				rotated = imutils.rotate(im, angle=Rotation_Angle + 5)
				images, labels, files = add_to_images_list(rotated, label, filename, images, labels, files)
				if show:
					cv2.imshow('ori2' + str(i) + '_' + filename[:-8], rotated)
					cv2.waitKey(10)
					
					cv2.imshow('rota2' + str(i) + '_' + str(Rotation_Angle) + filename[:-8], rotated)
					cv2.waitKey()
				if save_file:
					filename = save_path + name + '_' + str(i) + '_rota2_' + str(Rotation_Angle) + ImageType
					print 'filename', filename
					cv2.imwrite(filename, im)
			
			if Clockwise == 1 and Rotation_Angle <> 0:
				# Clockwise
				rotated_tmp = cv2.resize(im, (settings.w_resize + 40, settings.h_resize + 20), interpolation=cv2.INTER_LINEAR)
				rotated_tmp = imutils.rotate(rotated_tmp, angle=Rotation_Angle * -1)
				rotated = rotated_tmp[10:settings.h_resize + 10, 20:settings.w_resize + 20]
				images, labels, files = add_to_images_list(rotated, label, filename, images, labels, files)
				# rotated = imutils.resize(rotated, width=settings.w_resize, height=settings.h_resize)
				images, labels, files = add_to_images_list(rotated, label, filename, images, labels, files)
				if show:
					cv2.imshow('c_ori1' + str(i) + '_' + filename[:-8], rotated)
					cv2.waitKey(10)
					
					cv2.imshow('c_rota1' + str(i) + '_' + str(Rotation_Angle) + filename[:-8], rotated)
					cv2.waitKey()
				if save_file:
					filename = save_path + name + '_' + str(i) + '_c_rota1_' + str(Rotation_Angle) + ImageType
					print 'filename', filename
					cv2.imwrite(filename, im)
			
			return images, labels, files
		
		images, labels, files = add_rotation(im_base, Rotation_Angle, label, filename, images, labels, files, index,
		                                     save_path,
		                                     name, show=show, save_file=False)
		
		def add_flip(im, label, filename, images, labels, files, i=0, save_path='', name='', show=False, save_file=False):
			### Flipping begin ##############################################################
			for flipType in xrange(-1, 2):
				flipped = cv2.flip(im, flipType)
				images, labels, files = add_to_images_list(flipped, label, filename, images, labels, files)
				if show:
					cv2.imshow('flip' + str(i) + str(flipType + 1), flipped)
					cv2.waitKey()
				if save_file:
					filename = save_path + name + '_' + str(i) + '_flip' + str(flipType + 1) + ImageType
					print 'filename', filename
					cv2.imwrite(filename, im)
			return images, labels, files
		
		images, labels, files = add_flip(im_base, label, filename, images, labels, files, index, save_path, name, show=show,
		                                 save_file=False)
		### add noise begin ##############################################################
		if noise_level <> 0:
			img_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
			
			# img = img.astype(np.float32)
			img_noised = img_gray + np.random.rand(settings.w_resize, settings.h_resize) * noise_level
			img_noised = (img_noised / np.max(img_noised)) * 255
		
		### add noise end    ##############################################################
		
		def do_augment_data(im, label, filename, images, labels, files, h, w, show=False, save_file=False):
			name = os.path.basename(filename)[:-len(ImageType)]
			save_path = settings.data
			# im = cv2.imread(filename)
			im_proportions = []
			ims_resize = []
			
			# first cut different proportion from whole image
			def cutCVimg(im, ori_h, ori_w, ratio):
				w_new = int(ori_w * ratio * 0.78)  # simulate different detection area sizes
				h_new = int(ori_h * ratio)
				im = im[0:h_new, ori_w - w_new:w_new]  # y1:y2,x1:x2
				# im = im[ori_h - h_new:h_new, ori_w - w_new:w_new]  # y1:y2,x1:x2
				# resize them to seg output size hxw (simulate)
				im = cv2.resize(np.uint8(im), (h, w))
				return im
			
			# create patches
			for r in xrange(7, 9):
				im_proportion = cutCVimg(im, im.shape[0], im.shape[1], r * 0.125)  # [0]h,[1]w for rectangular use 0.12
				im_proportions.append(im_proportion)
				for im in im_proportions:
					if show:
						cv2.imshow('proportion' + str(r), im)
						cv2.waitKey(10)
			
			# second, add to transform_to_one_size
			for im, i in zip(im_proportions, xrange(len(im_proportions))):
				# im = cv2.resize(np.uint8(im), (h, w))
				# im = imutils.resize(im, width=settings.w_resize)
				im_base = transform_to_one_size(im)
				ims_resize.append(im)
				if show:
					cv2.imshow('resize_' + str(i), im)
					cv2.waitKey()
				if save_file:
					cv2.imwrite(save_path + name + '_' + str(i) + ImageType, im)
				# third, add rotation and add to images list
				# for im_base, i in zip(ims_resize, xrange(len(ims_resize))):
				images, labels, files = add_rotation(im_base, Rotation_Angle, label, filename, images, labels, files, i,
				                                     save_path, name, show=show, save_file=False)
				
				# next, add all flipping and add to images list
				# for im_base, i in zip(ims_resize, xrange(len(ims_resize))):
				images, labels, files = add_flip(im_base, label, filename, images, labels, files, index, save_path, name,
				                                 show=show,
				                                 save_file=False)
				'''
				if show:
					cv2.imshow('flip' + str(i) + str(flipType + 1), flipped)
					cv2.waitKey()
				if save_file:
					filename = save_path + name + '_' + str(i) + '_flip' + str(flipType + 1) + ImageType
					print 'filename', filename
					cv2.imwrite(filename, im)
				'''
			return images, labels, files
		
		if 'full' in filename:  # hinten/', 'links/', 'oben/', 'rechts/', 'unten/', 'vorn/
			images, labels, files = do_augment_data(im_gray, label, filename, images, labels, files, 320, 320, show=False,
			                                        save_file=False)
		
		'''
		if index > int(0.3*len(lines)) and index < int(0.4 * len(lines)):
			############ add online data begin
			# Rotation_Angle = randint(15, 170)
			# noise_level = 0.01 * randint(1, 2)
			### Rotation start ##############################################################
			if Anti_clockwise == 1 and Rotation_Angle <> 0:
				rotated = imutils.rotate(im, angle=Rotation_Angle+3)
				images.append(rotated)
				labels.append(label)
				files.append(filename)

		if index > int(0.5*len(lines)) and index < int(0.6 * len(lines)):
			############ add online data begin
			# Rotation_Angle = randint(15, 170)
			# noise_level = 0.01 * randint(1, 2)
			### Rotation start ##############################################################
			if Anti_clockwise == 1 and Rotation_Angle <> 0:
				rotated = imutils.rotate(im, angle=Rotation_Angle+23)
				images.append(rotated)
				labels.append(label)
				files.append(filename)

		'''
	
	images_np = np.asarray(images)
	labels_np = np.asarray(labels)
	# print len(images),len(labels),len(files)
	
	return (images_np, labels_np, files)


###########
def transform_to_one_size(im):
	# resize to fit classifier model
	im = cv2.resize(im, (settings.h_resize, settings.w_resize))
	im = imutils.resize(im, width=settings.w_resize, height=settings.h_resize)
	# im = imutils.resize(im_resize_gray, width=settings.w_resize, height=settings.h_resize)
	# im_resize_gray = cv2.resize(im, (settings.h_resize, settings.w_resize))
	
	return im


def add_to_images_list(im, label, filename, images, labels, files):
	im = np.asarray(im, np.float32)
	im = np.float32(im.reshape(settings.h_resize, settings.w_resize))
	
	images.append(im)
	labels.append(label)
	files.append(filename)
	return images, labels, files


############
def create_test_slices(img, patch_size, label):
	im = img
	# h_b, w_b = im.shape
	h_b, w_b = im.size
	print 'read test image ok', h_b, ', ', w_b
	bboxes = []
	slices = ['../tmp00.png', '../tmp01.png', '../tmp10.png',
	          '../tmp11.png', '../tmp_c.png']
	
	# corner (0,0)
	# bbox1 = im[1:1 + patch_size, 1:1 + patch_size] #crop method for numpy array object, cv2 image, which has attribute shape
	bbox1 = (1, 1, 1 + patch_size, 1 + patch_size)  # crop method for Image object which has attribute size
	
	# corner (0,1)   1 + patch_size
	# bbox2 = im[1:1 + patch_size, w_b - patch_size: w_b]
	bbox2 = (1, w_b - patch_size, 1 + patch_size, w_b)
	
	# corner (1,0)
	# bbox3 = im[h_b - patch_size:h_b, 1: patch_size +1]
	bbox3 = (h_b - patch_size, 1, h_b, patch_size + 1)
	
	# corner (1,1)
	# bbox4 = im[h_b - patch_size:h_b,  w_b - patch_size: w_b]
	bbox4 = (h_b - patch_size, w_b - patch_size, h_b, w_b)
	
	# center (c,c)
	# bbox5 = im[int(h_b/2 - patch_size/2)-1: int(h_b/2 + patch_size/2), int(w_b/2 - patch_size/2)-1: int(w_b/2 + patch_size/2)]
	bbox5 = (int(h_b / 2 - patch_size / 2) - 1, int(w_b / 2 - patch_size / 2) - 1, int(h_b / 2 + patch_size / 2),
	         int(w_b / 2 + patch_size / 2))
	
	bboxes.append(bbox1)
	bboxes.append(bbox2)
	bboxes.append(bbox3)
	bboxes.append(bbox4)
	bboxes.append(bbox5)
	bboxes_len = len(bboxes)
	
	slices_files = []
	folderstr = settings.LABELS[int(label)] + '/'
	for boxindex in range(0, bboxes_len, 1):
		slice = im.crop(bboxes[boxindex]).save(slices[boxindex], optimize=True, bits=6)
		# slice = bboxes[boxindex] #for numpy.ndarray object
		
		cmd = 'mv ' + slices[boxindex] + ' ' + settings.tmp + folderstr  # hy: move
		os.system(cmd)
		slice_pathname = settings.tmp + folderstr + slices[boxindex].split('/')[1]
		slices_files.append(slice_pathname)
	# print 'slice file path', slices_files[boxindex]
	print 'slices created ok'
	return slices_files


############
def get_tensor(im_i, pre_tensor, n_classes, cvtcolor, screen_out):
	# tensorImgIn = cv2.imread('../testbench/frame_color_tmp.jpg')
	# transform color and size to fit trained classifier model
	if screen_out:
		cv2.namedWindow('pre_tensor', cv2.WINDOW_NORMAL)
		cv2.putText(pre_tensor, 'frame ' + str(im_i), org=(320 / 10, 320 / 8),
		            fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1,
		            color=(0, 255, 0), thickness=2)
		cv2.imshow('pre_tensor', pre_tensor)
	
	if cvtcolor:
		pre_tensor = cv2.cvtColor(pre_tensor, cv2.COLOR_BGR2GRAY)
	
	# in case gray image as test image, no need to cvt
	# test_image = cv2.resize(pre_tensor, (settings.h_resize, settings.w_resize))
	# test_image = imutils.resize(test_image, width=settings.w_resize, height=settings.h_resize)
	# test_image = np.asarray(test_image, np.float32)
	
	test_image = transform_to_one_size(pre_tensor)
	
	test_image = np.asarray(test_image, np.float32)
	test_image = np.float32(test_image.reshape(settings.h_resize, settings.w_resize))
	
	tensorImgIn = test_image.reshape((-1, test_image.size))  # can be other size
	tensorImgIn = np.expand_dims(np.array(tensorImgIn), 2).astype(np.float32)
	tensorImgIn = tensorImgIn / 255 - 0.5  # TODO here is tricky, double check wit respect to the formats
	
	test_labels = np.zeros((1, n_classes))  # Making a dummy label tp avoid errors as initial predict
	return tensorImgIn, test_labels


def do_statistics(confMat1, confMat2, data_length):
	# for i in range(0, len(settings.LABELS)):
	#	confMat1[i, :] = confMat1[i, :] / np.sum(confMat1[i, :])
	print_label_title()
	print confMat1
	tp = confMat2[0, 0]
	tn = confMat2[1, 1]
	overall_acc = round(tp / data_length, 2)
	print 'TEST overall acc:', overall_acc
	
	return overall_acc


def process_res(confMat1_TEST, confMat2_TEST, RES, frame_crop, SAVE_CorrectClassified=False, SAVE_Misclassified=False,
                im_i=1,
                target=1):
	# print '\ntarget,RES', target, RES
	if RES == target:
		label2_TEST = 0
		pred2_TEST = 0
		name_str = settings.CorrectClassified + "/frame_crop%d.jpg" % im_i
		SAVE_CorrectClassified_frame(name_str, frame_crop, SAVE_CorrectClassified)  # (v)
	
	else:
		label2_TEST = 1
		pred2_TEST = 1
		name_str = settings.Misclassified + "/frame_crop%d.jpg" % im_i
		SAVE_Misclassified_frame(name_str, frame_crop, SAVE_Misclassified)
	
	confMat1_TEST[target, RES] = confMat1_TEST[target, RES] + 1.0
	confMat2_TEST[label2_TEST, pred2_TEST] = confMat2_TEST[label2_TEST, pred2_TEST] + 1
	return confMat1_TEST, confMat2_TEST


def read_images_online(filelist='', random_read=True, Anti_clockwise=0, Clockwise=0, Rotation_Angle=0, Flip=False,
                       noise_level=0, step=0, augment_crop=False):
	print filelist, random_read, Anti_clockwise, Clockwise, 'angle', Rotation_Angle, 'flip', Flip, noise_level, step
	save_path = settings.data
	show = False
	lable_file = open(filelist, 'r')
	lines = lable_file.readlines()
	rnd_flip, rnd_gblur, rnd_darken = [], [], []
	do_flip, do_rotat, do_gblur, do_darken = Flip, True, False, False
	
	if random_read == True:
		# make the file order in random way, this makes training more efficiently
		random.shuffle(lines)
		print 'loading images in random order'
	else:
		print 'loading sorted images'
	
	images, labels, files = [], [], []
	files_num = len(lines)
	
	if Flip:
		rnd_flip0 = random.sample(xrange(files_num - 1), int(files_num*0.3))
	if Flip:
		rnd_flip1 = random.sample(xrange(files_num - 1), int(files_num * 0.3))
	
	if Flip:
		rnd_flip2 = random.sample(xrange(files_num - 1), int(files_num*0.3))
		
	if do_gblur:
		rnd_gblur = random.sample(xrange(files_num - 1), files_num - 2)
	if do_rotat:
		rnd_rotat = random.sample(xrange(files_num - 1), int(files_num*0.05))  # 80
	if do_darken:
		rnd_darken = random.sample(xrange(files_num - 1), int(files_num*0.05))  # 80
	
	for item, index in zip(lines, xrange(files_num)):
		filename, label = item.split()
		name = os.path.basename(filename)[:-len(ImageType)]
		im = cv2.imread(filename)
		im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
		
		im_base = transform_to_one_size(im_gray)
		
		# if 'full' not in filename:
		images, labels, files = add_to_images_list(im_base, label, filename, images, labels, files)
		
		############ add online data begin
		# Rotation_Angle = randint(15, 170)
		# noise_level = 0.01 * randint(1, 2)
		### Rotation start ##############################################################
		def add_rotation(im, Rotation_Angle, label, filename, images, labels, files, i=0, save_path='', name='', show=False,
		                 save_file=False):
			if Anti_clockwise == 1 and Rotation_Angle <> 0:
				# im = cv2.resize(im,(settings.w_resize,settings.h_resize), interpolation=cv2.INTER_LINEAR)
				# print 'received im for rotation h,w', im.shape[0], im.shape[1]
				rotated = imutils.rotate(im, angle=Rotation_Angle)
				images, labels, files = add_to_images_list(rotated, label, filename, images, labels, files)
				if show:
					cv2.imshow('ori' + str(i) + '_' + filename[:-8], rotated)
					cv2.waitKey(10)
					
					cv2.imshow('rota' + str(i) + '_' + str(Rotation_Angle) + filename[:-8], rotated)
					cv2.waitKey()
				if save_file:
					filename = save_path + name + '_' + str(i) + '_rota1_' + str(Rotation_Angle) + ImageType
					print 'filename', filename
					cv2.imwrite(filename, im)
				
				# im = cv2.resize(im,(settings.w_resize,settings.h_resize), interpolation=cv2.INTER_LINEAR)
				# print 'received im for rotation h,w', im.shape[0], im.shape[1]
				rotated = imutils.rotate(im, angle=Rotation_Angle + 5)
				images, labels, files = add_to_images_list(rotated, label, filename, images, labels, files)
				if show:
					cv2.imshow('ori2' + str(i) + '_' + filename[:-8], rotated)
					cv2.waitKey(10)
					
					cv2.imshow('rota2' + str(i) + '_' + str(Rotation_Angle) + filename[:-8], rotated)
					cv2.waitKey()
				if save_file:
					filename = save_path + name + '_' + str(i) + '_rota2_' + str(Rotation_Angle) + ImageType
					print 'filename', filename
					cv2.imwrite(filename, im)
				
				# im = cv2.resize(im,(settings.w_resize,settings.h_resize), interpolation=cv2.INTER_LINEAR)
				# print 'received im for rotation h,w', im.shape[0], im.shape[1]
				rotated = imutils.rotate(im, angle=Rotation_Angle + 15)
				images, labels, files = add_to_images_list(rotated, label, filename, images, labels, files)
				if show:
					cv2.imshow('ori2' + str(i) + '_' + filename[:-8], rotated)
					cv2.waitKey(10)
					
					cv2.imshow('rota2' + str(i) + '_' + str(Rotation_Angle) + filename[:-8], rotated)
					cv2.waitKey()
				if save_file:
					filename = save_path + name + '_' + str(i) + '_rota2_' + str(Rotation_Angle) + ImageType
					print 'filename', filename
					cv2.imwrite(filename, im)
			
			if Clockwise == 1 and Rotation_Angle <> 0:
				# Clockwise
				rotated_tmp = cv2.resize(im, (settings.w_resize + 40, settings.h_resize + 20), interpolation=cv2.INTER_LINEAR)
				rotated_tmp = imutils.rotate(rotated_tmp, angle=Rotation_Angle * -1)
				rotated = rotated_tmp[10:settings.h_resize + 10, 20:settings.w_resize + 20]
				images, labels, files = add_to_images_list(rotated, label, filename, images, labels, files)
				# rotated = imutils.resize(rotated, width=settings.w_resize, height=settings.h_resize)
				images, labels, files = add_to_images_list(rotated, label, filename, images, labels, files)
				if show:
					cv2.imshow('c_ori1' + str(i) + '_' + filename[:-8], rotated)
					cv2.waitKey(10)
					
					cv2.imshow('c_rota1' + str(i) + '_' + str(Rotation_Angle) + filename[:-8], rotated)
					cv2.waitKey()
				if save_file:
					filename = save_path + name + '_' + str(i) + '_c_rota1_' + str(Rotation_Angle) + ImageType
					print 'filename', filename
					cv2.imwrite(filename, im)
			
			return images, labels, files
		
		if do_rotat and index in rnd_rotat:
			images, labels, files = add_rotation(im_base, Rotation_Angle, label, filename, images, labels, files, index,
			                                     save_path,
			                                     name, show=show, save_file=False)
			
		
		
		def add_flip(im, label, filename, images, labels, files, i=0, save_path='', name='', flip_Type=0, show=False, save_file=False):
					
			#for flipType in xrange(-1, 0): #can use (-1,2) for three types of flipping
			flipped = cv2.flip(im, flip_Type)
			images, labels, files = add_to_images_list(flipped, label, filename, images, labels, files)
			if show:
				cv2.imshow('flip' + str(i) + str(flipType + 1), flipped)
				cv2.waitKey(10)
			if save_file:
				filename = save_path + name + '_' + str(i) + '_flip' + str(flipType + 1) + ImageType
				print 'filename', filename
				cv2.imwrite(filename, im)
			return images, labels, files
		
		def add_dark(im, label, filename, images, labels, files, i=0, save_path='', name='', show=False, save_file=False):
			img_copy = im
			img_copy = cv2.resize(img_copy, (184, 184))
			dark_img = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)
			dark_img = Image.fromarray(dark_img)  # Image.fromarray(im1misc)
			rnd_darkness = 0.01 * randint(29, 50)
			dark_img = dark_img.point(lambda p: p * rnd_darkness)
			dark_img = cv2.cvtColor(np.array(dark_img), cv2.COLOR_RGB2GRAY) #RGB2BGR: red remain red for PIL
			
			images, labels, files = add_to_images_list(dark_img, label, filename, images, labels, files)
			if show:
				cv2.imshow('flip' + str(i) + str(rnd_darkness), dark_img)
				cv2.waitKey(10)
			if save_file:
				filename = save_path + name + '_' + str(i) + '_flip' + str(rnd_darkness) + ImageType
				print 'filename', filename
				cv2.imwrite(filename, im)
			return images, labels, files
		
		if do_darken and index in rnd_darken: #use color input, not gray
			images, labels, files = add_dark(im, label, filename, images, labels, files, index, save_path, name,
			                                 show=show,
			                                 save_file=False)
		
		# if 'full' not in filename and Flip == 1:
		if do_flip and index in rnd_flip0:
			images, labels, files = add_flip(im_base, label, filename, images, labels, files, index, save_path, name,0,
			                                 show=show,save_file=False)
		if do_flip and index in rnd_flip1:
			images, labels, files = add_flip(im_base, label, filename, images, labels, files, index, save_path, name,1,
			                                 show=show,save_file=False)
		if do_flip and index in rnd_flip2:
					images, labels, files = add_flip(im_base, label, filename, images, labels, files, index, save_path, name,2,
					                                 show=show,save_file=False)
		### add noise begin ##############################################################
		if noise_level <> 0:
			img_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
			
			# img = img.astype(np.float32)
			img_noised = img_gray + np.random.rand(settings.w_resize, settings.h_resize) * noise_level
			img_noised = (img_noised / np.max(img_noised)) * 255
		
		### add noise end    ##############################################################
		
		def do_augment_data(im_ori, label, filename, images, labels, files, h, w, show=False, save_file=False):
			# print 'augment data level 2'
			name = os.path.basename(filename)[:-len(ImageType)]
			save_path = settings.data
			# im = cv2.imread(filename)
			im_proportions = []
			ims_resize = []
			
			# first cut different proportion from whole image
			def cutCVimg(im, ori_h, ori_w, ratio, im_proportions):
				for i in xrange(2):
					w_new = int(ori_w * ratio * 0.9)  # simulate different detection area sizes
					h_new = int(ori_h * ratio * 0.9)
					
					x = randint(1, int(ori_w * 0.1))
					y = randint(1, int(ori_h * 0.1))
					# print 'x,y,w_new,h_new',x,y,w_new,h_new
					
					im = im[y:y + h_new, x:x + w_new]  # y1:y2,x1:x2
					# resize them to seg output size hxw (simulate)
					im = cv2.resize(np.uint8(im), (320, 320))
					###im = np.float32(im.reshape(320, 320))
					im_proportions.append(im)
				return im_proportions
			
			# create patches
			# im_ori = im
			for r in xrange(7, 9):  # stands for proportion 0.7 and 0.8 of original image
				im_proportions = cutCVimg(im_ori, im_ori.shape[0], im_ori.shape[1], r * 0.12,
				                          im_proportions)  # [0]h,[1]w for rectangular use 0.12
				if show:
					for im in im_proportions:
						cv2.imshow('proportion' + str(r), im)
						cv2.waitKey(10)
			
			# second, add to transform_to_one_size
			for im, i in zip(im_proportions, xrange(len(im_proportions))):
				# im = cv2.resize(np.uint8(im), (h, w))
				# im = imutils.resize(im, width=settings.w_resize)
				im_base = transform_to_one_size(im)
				
				images, labels, files = add_to_images_list(im_base, label, filename, images, labels, files)
				
				if show:
					cv2.imshow('resize_' + str(i), im)
					cv2.waitKey(10)
				if save_file:
					cv2.imwrite(save_path + name + '_' + str(i) + ImageType, im)
				
				# third, add rotation and add to images list
				images, labels, files = add_rotation(im_base, Rotation_Angle, label, filename, images, labels, files, i,
				                                     save_path, name, show=show, save_file=False)
				
				# next, add all flipping and add to images list
				images, labels, files = add_flip(im_base, label, filename, images, labels, files, i, save_path, name, show=show,
				                                 save_file=False)
				'''
				if show:
					cv2.imshow('flip' + str(i) + str(flipType + 1), flipped)
					cv2.waitKey()
				if save_file:
					filename = save_path + name + '_' + str(i) + '_flip' + str(flipType + 1) + ImageType
					print 'filename', filename
					cv2.imwrite(filename, im)
				'''
			
			return images, labels, files
		
		if (
				'full' in filename or 'duo' in filename) and augment_crop:  # hinten/', 'links/', 'oben/', 'rechts/', 'unten/', 'vorn/
			# if augment_crop:  # hinten/', 'links/', 'oben/', 'rechts/', 'unten/', 'vorn/
			# use im_gray as input
			images, labels, files = do_augment_data(im_gray, label, filename, images, labels, files, 320, 320, show=False,
			                                        save_file=False)
		
		'''
		if index > int(0.3*len(lines)) and index < int(0.4 * len(lines)):
			############ add online data begin
			# Rotation_Angle = randint(15, 170)
			# noise_level = 0.01 * randint(1, 2)
			### Rotation start ##############################################################
			if Anti_clockwise == 1 and Rotation_Angle <> 0:
				rotated = imutils.rotate(im, angle=Rotation_Angle+3)
				images.append(rotated)
				labels.append(label)
				files.append(filename)

		if index > int(0.5*len(lines)) and index < int(0.6 * len(lines)):
			############ add online data begin
			# Rotation_Angle = randint(15, 170)
			# noise_level = 0.01 * randint(1, 2)
			### Rotation start ##############################################################
			if Anti_clockwise == 1 and Rotation_Angle <> 0:
				rotated = imutils.rotate(im, angle=Rotation_Angle+23)
				images.append(rotated)
				labels.append(label)
				files.append(filename)

		'''
	
	images_np = np.asarray(images)
	labels_np = np.asarray(labels)
	
	return (images_np, labels_np, files)


# prepare_list(LABEL_LIST, LABEL_PATH)
# read_images_online(LABEL_LIST, random_read
# =True, Anti_clockwise=1, Clockwise=0, Rotation_Angle=5, Flip=1, noise_level=0,augment_crop=True)




# import data
def import_data(add_online=False, augment_crop=False):
	elapsed_time = time.time() - start_time
	print 'Elapsed time:', "{:.2f}".format(elapsed_time), 's'
	
	# print "Start training, loading images"
	digits = datasets.load_digits(n_class=n_classes)
	
	if add_online:
		carimages, cartargets, f = read_images_online(LABEL_LIST, random_read
		=True, Anti_clockwise=1, Clockwise=0, Rotation_Angle=5, Flip=True, noise_level=0, augment_crop=augment_crop)
	
	else:
		carimages, cartargets, f = read_images(LABEL_LIST, random_read=True)
	
	total_images = len(carimages)
	
	# tmp=Image.fromarray(carimages[0],'L')
	# tmp.show()
	
	carimages = carimages / 255 - 0.5
	
	if DEBUG == 1:
		# You havent yet changed the rest, becareful about sizes and etc.
		print ' Shape of Labels', cartargets.shape  # hy check if their length is same
	
	digits.images = carimages.reshape((len(carimages), -1))
	
	if DEBUG == 1:
		print "Shape of data set after reshape: ", digits.images.shape  # hy
	
	digits.images = np.expand_dims(np.array(digits.images), 2).astype(np.float32)
	
	if DEBUG == 1:
		print "Shape of data set after expansion: ", digits.images.shape  # hy
	
	digits.target = np.array(cartargets).astype(np.int32)
	digits.target = dense_to_one_hot(digits.target, num_classes=n_classes)
	
	if DEBUG == 1:
		print '\n'
		print "5.print target"
		# print digits.target
		
		elapsed_time = time.time() - start_time
		print 'Total elapsed time2:', "{:.2f}".format(elapsed_time), 's'
	
	return [total_images, digits, carimages, cartargets, f]


# return [total_images, digits, carimages, cartargets, f, val2_digits, val2_images, val2_targets, val2_f]


# test
# images_np, labels_np, files = read_images_online(filelist='FileList_TEST1_sing.txt',random_read=True,Anti_clockwise=0,Clockwise=0,Rotation_Angle=0,Flip_X=1,Flip_Y=0,noise_level=0,step=0)
# print 'len of image', len(images_np)

############################################################################################################
# hy: initialize crop frame (interest of area in demo window)
# At the moment, this window has to be adjusted to focus our object.
# Different area shown in focus region leads to different test  result.
############################################################################################################
def set_video_window(TestFace, scale=1):
	VIDEO_FILE = ''
	crop_x1 = 0
	crop_y1 = 0
	area_step_size = 0
	video_label = 1
	if scale == 1:
		if TestFace == 'full':
			# Video file for Demo
			# VIDEO_FILE = '../Test_Videos/dark.avi'
			# VIDEO_FILE = '../tmp/vlc-10h05m41s_bg_holder.avi'
			VIDEO_FILE = '../Test_Images/Test_Videos/TestVideo1.mp4'
			VIDEO_FILE = '../Test_Images/MA/MA_videos/MOV_0045.mp4' #42
			# These settings are for TestVideo1.avi
			crop_x1 = 0  # 550
			crop_y1 = 0  # 300 780
			area_step_size = 1080  # 640
			video_label = 3
		if TestFace == 'hinten':
			VIDEO_FILE = '../Test_Videos/TestVideoHinten.avi'
			# These settings are for TestVideoHinten.avi
			crop_x1 = 680
			crop_y1 = 850
			area_step_size = 210
			video_label = 0
		
		if TestFace == 'links':
			VIDEO_FILE = '../Test_Videos/TestVideoLinks.avi'
			crop_x1 = 560
			crop_y1 = 660
			area_step_size = 400
			video_label = 1
		
		if TestFace == 'oben':
			VIDEO_FILE = '../Test_Videos/TestVideoOben.avi'
			crop_x1 = 660
			crop_y1 = 460
			area_step_size = 400
			video_label = 2
		
		if TestFace == 'rechts':
			VIDEO_FILE = '../Test_Videos/TestVideoRechts.avi'
			# These settings are for TestVideoRechts.avi.
			crop_x1 = 550
			crop_y1 = 600
			area_step_size = 450
			video_label = 3
		
		if TestFace == 'unten':
			VIDEO_FILE = '../Test_Videos/TestVideoUnten.avi'
			# These settings are for TestVideoUnten.avi
			crop_x1 = 860
			crop_y1 = 600
			area_step_size = 250
			video_label = 4
		
		if TestFace == 'vorn':
			VIDEO_FILE = '../Test_Videos/TestVideoVorn.avi'
			# Following are settings for the video TestVideoVorn.avi
			crop_x1 = 680
			crop_y1 = 790
			area_step_size = 390  # hy: if we do not need the test window to move around in Demo, then it is just the width
			video_label = 5
	
	if scale == 2:
		# version middle size 2
		if TestFace == 'hinten':
			VIDEO_FILE = '../Test_Videos/TestVideoHinten.avi'
			# These settings are for TestVideoHinten.avi,
			crop_x1 = 580
			crop_y1 = 750
			area_step_size = 510
			video_label = 0
		
		if TestFace == 'links':
			VIDEO_FILE = '../Test_Videos/TestVideoLinks.avi'
			# These settings are for TestVideoLinks.avi,
			crop_x1 = 360
			crop_y1 = 460
			area_step_size = 880
			video_label = 1
		
		if TestFace == 'oben':
			VIDEO_FILE = '../Test_Videos/TestVideoOben.avi'
			crop_x1 = 660
			crop_y1 = 460
			area_step_size = 500
			video_label = 2
		
		if TestFace == 'rechts':
			VIDEO_FILE = '../Test_Videos/TestVideoRechts.avi'
			# These settings are for TestVideoRechts.avi,
			crop_x1 = 550
			crop_y1 = 600
			area_step_size = 620
			video_label = 3
		
		if TestFace == 'unten':
			VIDEO_FILE = '../Test_Videos/TestVideoUnten.avi'
			crop_x1 = 860
			crop_y1 = 600
			area_step_size = 470
			video_label = 4
		
		if TestFace == 'vorn':
			VIDEO_FILE = '../Test_Videos/TestVideoVorn.avi'
			# Following are settings for the video TestVideoVorn.avi
			crop_x1 = 520
			crop_y1 = 590
			area_step_size = 750  # if we do not need the test window to move around in Demo, then it is just the width
			video_label = 5
	
	if scale == 3:
		# version middle size 3
		if TestFace == 'hinten':
			VIDEO_FILE = '../Test_Videos/TestVideoHinten.avi'
			
			crop_x1 = 550
			crop_y1 = 780
			area_step_size = 410
			video_label = 0
		
		if TestFace == 'links':
			VIDEO_FILE = '../Test_Videos/TestVideoLinks.avi'
			# These settings are for TestVideoLinks.avi,
			crop_x1 = 260
			crop_y1 = 560
			area_step_size = 480
			video_label = 1
		
		if TestFace == 'oben':
			VIDEO_FILE = '../Test_Videos/TestVideoOben.avi'
			crop_x1 = 700
			crop_y1 = 360
			area_step_size = 600
			video_label = 2
		
		if TestFace == 'rechts':
			VIDEO_FILE = '../Test_Videos/TestVideoRechts.avi'
			# These settings are for TestVideoRechts.avi,
			crop_x1 = 650
			crop_y1 = 800
			area_step_size = 320
			video_label = 3
		
		if TestFace == 'unten':
			VIDEO_FILE = '../Test_Videos/TestVideoUnten.avi'
			crop_x1 = 860
			crop_y1 = 600
			area_step_size = 570
			video_label = 4
		
		if TestFace == 'vorn':
			VIDEO_FILE = '../Test_Videos/TestVideoVorn.avi'
			# Following are settings for the video TestVideoVorn.avi
			crop_x1 = 260
			crop_y1 = 450
			area_step_size = 420  # hy: if we do not need the test window to move around in Demo, then it is just the width
			video_label = 5
	
	# print 'test face and scale:', TestFace, ', ', scale
	return [VIDEO_FILE, crop_x1, crop_y1, area_step_size, video_label]


def get_ground_truth_label(index, default=False):
	target = 0
	if default:
		target = 0
	elif index < 165:
		target = 1
	elif index > 165 and index < 300:
		target = 5
	elif index > 300 and index < 654:
		target = 3
	elif index > 654 and index < 850:
		target = 0
	elif index > 850 and index < 1100:
		target = 1
	elif index > 1100 and index < 1289:
		target = 5
	return target

def get_ground_truth_label_im(label_text, default=False):
	target = 0
	if 'hinten' in label_text:
		target = 0
	if 'links' in label_text:
		target = 1
	if 'oben' in label_text:
		target = 2
	if 'rechts' in label_text:
		target = 3
	if 'unten' in label_text:
		target = 4
	if 'vorn' in label_text:
		target = 5
	return target



def print_label_title():
	print settings.LABEL_names


def print_label_title_conf():
	print settings.LABEL_names


def convert_result(RES):  # 0 hinten, 1 links, 2 oben, 3 rechts, 4 unten, 5 vorn,
	if RES == 0 or RES == 7:
		label_str = 'vorn'
		label_num = 5
	
	if RES == 1 or RES == 3 or RES == 8 or RES == 10:  # 8:rechts/links  12:rechts/links
		label_str = 'rechts'
		label_num = 3
	
	if RES == 2 or RES == 11:
		label_str = 'oben'
		label_num = 2
	
	if RES == 4 or RES == 5 or RES == 6:
		label_str = 'links'
		label_num = 1
	
	if RES == 11:
		label_str = 'unten'
		label_num = 4
	
	if RES == 9 or RES == 10:
		label_str = 'hinten'
		label_num = 0
	return label_str, label_num


def SAVE_Images(filename, filepath):
	OUTPUT_PATH = filepath
	cmd = 'cp ' + filename + ' ' + OUTPUT_PATH
	os.system(cmd)


def SAVE_CorrectClassified_Img(img, save=False):
	if save:
		imgNum = len([name for name in os.listdir(settings.CorrectClassified) if
		              os.path.isfile(os.path.join(settings.CorrectClassified, name))])
		img_name = img
		if imgNum < settings.maxNumSaveFiles:  # hy: to avoid full disk error!
			SAVE_Images(img_name, settings.CorrectClassified)
		else:
			print 'CorrectClassified Folder is full !!!'


def SAVE_CorrectClassified_frame(name_str, img, save=False):
	if save:
		imgNum = len([name for name in os.listdir(settings.CorrectClassified) if
		              os.path.isfile(os.path.join(settings.CorrectClassified, name))])
		img_name = name_str
		# print 'num of files', misNum
		if imgNum < settings.maxNumSaveFiles:  # hy: to avoid full disk error!
			cv2.imwrite(img_name, img)
		else:
			print 'CorrectClassified Folder is full !!!'


def SAVE_Misclassified_Img(img, save=False):
	if save == 1:
		imgNum = len([name for name in os.listdir(settings.Misclassified) if
		              os.path.isfile(os.path.join(settings.Misclassified, name))])
		img_name = img
		if imgNum < settings.maxNumSaveFiles:  # hy: to avoid full disk error!
			SAVE_Images(img_name, settings.Misclassified)
		else:
			print 'Misclassified Folder is full !!!'


def SAVE_Misclassified_frame(name_str, img, save=False):
	if save == 1:
		imgNum = len([name for name in os.listdir(settings.Misclassified) if
		              os.path.isfile(os.path.join(settings.Misclassified, name))])
		img_name = name_str
		# print 'num of files', misNum
		if imgNum < settings.maxNumSaveFiles:  # hy: to avoid full disk error!
			cv2.imwrite(img_name, img)
		else:
			print 'Misclassified Folder is full !!!'


def track_roi(VIDEO_FILE):
	video = cv2.VideoCapture(VIDEO_FILE)  # hy: changed from cv2.VideoCapture()
	# cv2.waitKey(10)
	
	video.set(1, 2)  # hy: changed from 1,2000 which was for wheelchair test video,
	# hy: propID=1 means 0-based index of the frame to be decoded/captured next
	
	if not video.isOpened():
		print "cannot find or open video file"
		exit(-1)
	
	# Read the first frame of the video
	ret, frame = video.read()
	
	# Set the ROI (Region of Interest). Actually, this is a
	# rectangle of the building that we're tracking
	c, r, w, h = 900, 650, 400, 400
	track_window = (c, r, w, h)
	
	# Create mask and normalized histogram
	roi = frame[r:r + h, c:c + w]
	hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
	
	mask = cv2.inRange(hsv_roi, np.array((0., 30., 32.)), np.array((180., 255., 255.)))
	
	roi_hist = cv2.calcHist([hsv_roi], [0], mask, [180], [0, 180])
	
	cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)
	
	term_cond = (
		cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 80, 1)  # hy: TERM_CRITERIA_EPS - terminate iteration condition
	
	while True:
		ret, frame = video.read()
		if ret:
			hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
			dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)
			ret, track_window = cv2.meanShift(dst, track_window, term_cond)
			
			x, y, w, h = track_window
			
			# hy: draw rectangle as tracked window area
			cv2.rectangle(frame, (x, y), (x + w, y + h), 255, 2)
			cv2.putText(frame, 'Tracked', (x - 25, y - 10), cv2.FONT_HERSHEY_SIMPLEX,
			            1, (255, 255, 255), 2, cv2.CV_AA)
			
			cv2.imshow('Tracking', frame)
			if cv2.waitKey(1) & 0xFF == ord('q'):
				break
		else:
			print 'no frame received'
			break
	
	return [track_window]


# hy: input- CNN variable conv and file list; output- learned feature map
def get_feature_map(conv_feature, f, layer):
	save_file = 0
	conv_feature_2D_batch = []
	# batch_xs, batch_ys = digits.images[1:total_images - 1], digits.target[1:total_images - 1]
	## Save Tensor to Files  ##########################################################
	# conv1_feature = sess.run(conv1, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1})
	np.set_printoptions(threshold=np.nan)  # hy
	num_of_ori_imgs, th, tw, num_of_slices = conv_feature.shape
	print 'num of image,h,w,num of slices', num_of_ori_imgs, 'x', th, 'x', tw, 'x', num_of_slices
	
	# num_of_ori_imgs = len(conv_feature) #hy:debug
	# print 'length feat', num_of_ori_imgs #hy:debug
	
	for im_index in xrange(num_of_ori_imgs):
		fname = f[im_index]
		fname = os.path.splitext(fname)[0]
		from os.path import basename
		base_name = basename(fname)
		# print fname, '--', base_name #hy for debug
		print 'image path name', f[im_index]
		for slice_dim in xrange(num_of_slices):
			for slice_block in xrange(num_of_ori_imgs):
				# outfile.write('# Block ' + str(slice_block) + '\n') #hy: debug
				# print '\nnew block ', str(slice_block), 'of hxw: 4x4 *** image ', str(im_index), f[im_index] #hy: debug
				
				for slice_th in xrange(th):
					for slice_tw in xrange(tw):
						# hy:convert feature to 2D
						conv_feature_2D = conv_feature[slice_block, :, :, slice_dim]
						
						if save_file == 1:
							# hy:create txt files
							with file('fm_h' + str(settings.h_resize) + 'w' + str(settings.w_resize) + '_' + str(
											im_index) + '-' + base_name + '-' + layer + '-' + str(slice_dim) + '.png',
							          'w') as outfile:  # hy: one txt contains one slice 42x42
								np.savetxt(outfile, conv_feature_2D, fmt='%-2.6f')
								outfile.write('\n')
							
							# hy: debug #
							# outfile.write('# Array shape: {0}\n'.format(conv_feature.shape))
							# outfile.write(f[im_index - 1] + '\n')
							# outfile.write('row ' + str(slice_th) + ' col ' + str(slice_tw) + ' in block ' + str(
							# slice_block) + ' image ' + str(im_index) + '\n')
							# print '\nrow '+ str(slice_th) + ' col '+ str(slice_tw) + ' in block '+ str(slice_block)+' image ' + str(im_index)
			conv_feature_2D_batch.append(conv_feature_2D)
	
	print 'feature map saved'  # hy: save feature maps
	return conv_feature_2D_batch


# classifier_model: model path + name
def load_classifier_model(sess, f_path, classifier_model):
	# hy: load saved model with values
	ckpt = tf.train.get_checkpoint_state(checkpoint_dir=f_path)  # "../backupModel/"
	saver = tf.train.import_meta_graph(classifier_model)  # (eva)
	#
	ckpt.model_checkpoint_path = classifier_model[:-5]
	if ckpt and ckpt.model_checkpoint_path:
		print "Evaluation with images, model", ckpt.model_checkpoint_path
		saver = tf.train.Saver()
		saver.restore(sess, ckpt.model_checkpoint_path)
	else:
		print 'not found model'
		print 'I-Test with Images starting ...'  # print 'Test with images starting ...', ckpt.model_checkpoint_path
	
	return sess, saver


def EVALUATE_IMAGE_SLICES(img, f, index, sess, cartargets, num_class, SAVE_CorrectClassified=False,
                          SAVE_Misclassified=False):  # hy todo change dimension to fit tensorflow
	n_classes = num_class
	confMat1_TEST = np.zeros((n_classes, n_classes), dtype=np.float)
	confMat2_TEST = np.zeros((2, 2), dtype=np.float)
	confMat3 = np.zeros((1, n_classes), dtype=np.float)
	count_labels = np.zeros((1, n_classes), dtype=np.float)
	class_probability = np.zeros((1, n_classes), dtype=np.float)
	
	img_s = img
	i = index
	test_labels = np.zeros((1, n_classes))  # Making a dummy label tp avoid errors as initial predict
	
	# Doing something very stupid here, fix it!
	test_image = img_s.reshape((-1, img_s.size))
	
	test_image = np.expand_dims(np.array(test_image), 2).astype(np.float32)
	test_image = test_image / 255 - 0.5  # TODO here is tricky, double check with respect to the formats
	
	batch_xs1, batch_ys1 = test_image, test_labels
	
	output = sess.run("pred:0", feed_dict={"x:0": batch_xs1, "y:0": batch_ys1, "keep_prob:0": 1.})
	
	# print("Output for external=",output)
	# print output
	output = convert_to_confidence(output)  #
	np.set_printoptions(precision=3)
	
	RES = np.argmax(output)
	
	label_target = int(cartargets[i])
	
	print '\nTestImage', i + 1, ':', f[i]
	
	# print 'Image name', carimages
	print 'Target:', LABELS[label_target][:-1], ';  predict:', LABELS[RES][:-1]  # hy
	# print 'Target:', label_target, ';  predict:', RES  # hy
	
	count_labels[:, label_target] = count_labels[:, label_target] + 1
	
	label = label_target
	predict = int(RES)
	# hy: INFO - print label, predict
	# print 'labels_onehot:', labels_onehot[i, :], '  label=', label
	# print 'score:', scores[i, :]
	# print 'predict:', predict
	# if label == predict:
	confMat1_TEST[label, predict] = confMat1_TEST[label, predict] + 1
	
	if int(RES) == label_target:
		label2_TEST = 0
		pred2_TEST = 0
		confMat3[:, int(RES)] = confMat3[:, int(RES)] + 1
		SAVE_CorrectClassified_Img(f[i], SAVE_CorrectClassified)
	
	else:
		label2_TEST = 1
		pred2_TEST = 1
		SAVE_Misclassified_Img(f[i], SAVE_Misclassified)
	
	# print 'Count classified'
	# tools.print_label_title()
	# print confMat1_TEST
	
	confMat2_TEST[label2_TEST, pred2_TEST] = confMat2_TEST[label2_TEST, pred2_TEST] + 1
	tp = confMat2_TEST[0, 0]
	tn = confMat2_TEST[1, 1]
	print '\nCount correctly classified'
	print_label_title()
	print confMat3
	
	# print 'Total labels'
	# print count_labels
	
	# print 'Proportion of correctly classified'
	# if count_labels[:, pos] > 0:
	# for pos in range(0, 6, 1):
	#  class_probability[:, pos] = confMat3[:, pos] / count_labels[:, pos]
	# print class_probability
	
	# print '\nRank list of predicted results'
	sorted_vec, prob_all = rank_index(output[0], label_target, result_for_table=result_for_table)
	
	# return (confMat1_TEST, confMat2_TEST, confMat3, count_labels, class_probability,sorted_vec,output)
	return (sorted_vec, output)


def EVALUATE_IMAGES_VAGUE(sess, n_classes, img_list, SAVE_CorrectClassified=False, SAVE_Misclassified=False):
	LABEL_LIST_TEST = img_list
	# Testing
	cartargets, f = read_test_images(LABEL_LIST_TEST)
	# print 'cartargets label', cartargets
	TEST_length = 20
	# TEST_length = len(cartargets)
	
	# carimages = carimages / 255 - 0.5  #TODO here is tricky, double check wit respect to the formats
	# digits.images = carimages.reshape((len(carimages), -1))
	
	
	"""
  print '\n'
  print "4.print shape of database: ", digits.images.shape  # hy
  digits.images = np.expand_dims(np.array(digits.images), 2).astype(np.float32)
  print "4.1.print shape of database after expansion: ", digits.images.shape  # hy

  digits.target = np.array(cartargets).astype(np.int32)
  digits.target = dense_to_one_hot(digits.target)
  print '\n'
  print "5.print target"
  print digits.target
  """
	
	confMat_m1_TEST = np.zeros((n_classes, n_classes), dtype=np.float)
	confMat_m2_TEST = np.zeros((2, 2), dtype=np.float)
	confMat_m3 = np.zeros((1, n_classes), dtype=np.float)
	count_labels_m = np.zeros((1, n_classes), dtype=np.float)
	class_probability_m = np.zeros((1, n_classes), dtype=np.float)
	
	patch_size = 42  # 227
	for i in range(0, TEST_length, 1):
		# hy:extra Debug
		# im = carimages[i]
		# im = frame_crop_resize_gray  # Lazy
		
		
		'''
    #hy: option to use numpy.ndarray, but it cannot use attribute 'crop' of Image (integer) object
    img = cv2.imread(f[i])
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img = imutils.resize(img, width=patch_size, height=patch_size)
    h_b, w_b = img.shape
    print 'h_b', h_b, ', w_b', w_b
    '''
		
		print 'processing main test image', f[i]
		
		# hy: use integer image: Image, resize
		img = Image.open(f[i]).convert('LA')  # convert to gray
		h_b, w_b = img.size
		# print 'read test image ok', h_b, ', ', w_b
		img = img.resize((patch_size * 2, patch_size * 2), Image.BICUBIC)  # hy:use bicubic
		# h_b, w_b = img.size
		# print 'h_b', h_b, ', w_b', w_b
		
		test_lables = np.zeros((1, n_classes))  # Making a dummy label tp avoid errors as initial predict
		test_image = img
		test_image_label = cartargets[i]
		# Doing something very stupid here, fix it!
		# test_image = im.reshape((-1, im.size))
		
		
		# test_image = np.expand_dims(np.array(test_image), 2).astype(np.float32)
		# test_image = test_image / 255 - 0.5  # TODO here is tricky, double check with respect to the formats
		
		slices_rec = create_test_slices(test_image, patch_size, test_image_label)
		print 'slices with path received', slices_rec
		slices_len = len(slices_rec)
		
		out_sum = np.zeros((1, n_classes), dtype=np.float)
		out_box = np.zeros((1, n_classes), dtype=np.float)
		
		# batch_xs, batch_ys = im, cartargets
		
		# output_im = sess.run(pred, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.})
		
		for j in range(0, slices_len, 1):
			print '\nprocessing slice', j, slices_rec[j]
			# hy read and resize integer object
			# im_s = Image.open(slices_rec[j]) #numpy.ndarray does not have attribute 'crop'
			# im_s = im_s.resize((settings.h_resize, settings.w_resize), Image.BICUBIC)  # hy:use bicubic, resize func reuqires integer object
			# im_s = im_s.convert('LA') #hy convert to gray
			
			# hy read and resize continuous number object
			im_s = cv2.imread(slices_rec[j])  # result is not integer
			im_s = cv2.cvtColor(im_s, cv2.COLOR_BGR2GRAY)
			im_s = imutils.resize(im_s, width=settings.h_resize, height=settings.w_resize)
			
			# hy conver to integer object required for tensor
			im_s = np.asarray(im_s, np.float32)
			
			CONF = 0.20
			
			(sorted_vec, outputsub) = EVALUATE_IMAGE_SLICES(im_s, f, i, sess, cartargets)
			print 'slice', j, 'result', sorted_vec
			print 'Image slice', slices_rec[j]
			outbox = outputsub
			out_sum = out_sum + outputsub[0]
		
		# print '\ntp, tn, total number of test images:', tp, ', ', tn, ', ', TEST_length
		# print confMat2_TEST
		print '\nTEST general count:'
		
		print out_sum
		print out_sum / slices_len
		outbox[0] = out_sum / slices_len
		
		output_im, prob_all = rank_index(outbox[0], test_image_label)
		print 'target', test_image_label
		print 'output final prediction', output_im[-1]
		
		RES = int(output_im[-1])
		print 'test_image_label', test_image_label
		
		label = test_image_label
		predict = int(RES)
		
		confMat_m1_TEST[label, predict] = confMat_m1_TEST[label, predict] + 1
		
		count_labels_m[:, test_image_label] = count_labels_m[:, test_image_label] + 1
		
		if int(RES) == int(test_image_label):
			label2_TEST = 0
			pred2_TEST = 0
			
			confMat_m3[:, int(RES)] = confMat_m3[:, int(RES)] + 1
			SAVE_CorrectClassified_Img(f[i], SAVE_CorrectClassified)
		
		
		else:
			label2_TEST = 1
			pred2_TEST = 1
			SAVE_Misclassified_Img(f[i], SAVE_Misclassified)
		
		# print 'Count classified'
		# print_label_title()
		# print confMat1_TEST
		
		confMat_m2_TEST[label2_TEST, pred2_TEST] = confMat_m2_TEST[label2_TEST, pred2_TEST] + 1
		tp = confMat_m2_TEST[0, 0]
		tn = confMat_m2_TEST[1, 1]
		
		print 'Count classified m1 - confusion matrix'
		print_label_title()
		print confMat_m1_TEST
		
		print '\nCount correctly classified -m3'
		print_label_title()
		print confMat_m3
		
		print 'tp,np -m2'
		print confMat_m2_TEST
		print 'Total labels'
		print count_labels_m
		
		print 'Proportion of correctly classified for detailed analysis'  # ok
		if count_labels_m[:, pos] > 0:
			for pos in range(0, n_classes, 1):
				class_probability_m[:, pos] = confMat_m3[:, pos] / count_labels_m[:, pos]
			print class_probability_m
		
		print 'TEST overall acc:', "{:.3f}".format(tp / TEST_length)


def rank_index(vector, target, result_for_table):
	tmpLen = len(vector)
	sorted_vec = sorted(range(tmpLen), key=vector.__getitem__)
	prob_all = []
	for index in range(0, tmpLen):
		predict = sorted_vec[tmpLen - 1 - index]
		if predict == target:
			tmpStr = '<-Target\t, Probability:'
			prob_all.append(vector[predict])
		else:
			tmpStr = '\t\t\t, Probability:'
			prob_all.append(vector[predict])
		if result_for_table == 0:
			print index + 1, ') :', LABELS[predict], tmpStr, vector[predict]
	return sorted_vec, prob_all


def confusion_matrix(labels_onehot, scores, normalized=True):
	n_samples, n_class = scores.shape
	print 'n_samples for validation:', n_samples
	conf_matrix = np.zeros((n_class, n_class), dtype=np.float32)
	conf_matrix_2 = np.zeros((2, 2), dtype=np.float32)
	
	for i in range(0, n_samples):
		label = np.argmax(labels_onehot[i, :])
		predict = np.argmax(scores[i, :])
		# hy: INFO - print label, predict
		# print 'labels_onehot:', labels_onehot[i, :], '  label=', label
		# print 'score:', scores[i, :]
		# print 'predict:', predict
		conf_matrix[label, predict] = conf_matrix[label, predict] + 1
		
		# Mapping labels
		'''
    if label == 0 or label == 2:
      label2 = 0
    else:
      label2 = 1

    if predict == 0 or predict == 2:
      predict2 = 0
    else:
      predict2 = 1
    '''
		
		#################################################################################################################
		# hy: adapt to lego classes
		# hy: use it count corrected predict
		
		
		# print label2, predict2
		if label == predict:  # hy: true positive
			# hy: conf_matrix_2 true positive index 0,0
			label2 = 0
			predict2 = 0
		
		
		
		else:
			# hy: conf_matrix_2 true positive index 1,1
			label2 = 1
			predict2 = 1
		
		#################################################################################################################
		
		conf_matrix_2[label2, predict2] = conf_matrix_2[label2, predict2] + 1.0
	
	# hy: confusion matrix
	# [  tp      fn]
	# [  fp      tn]
	# tp: count label=predict / total
	# tn: label!=predict
	# fp: 1-tp
	# fn: 1-tn
	
	if normalized:
		for i in range(0, n_class):
			conf_matrix[i, :] = conf_matrix[i, :] / np.sum(conf_matrix[i, :])
	
	return conf_matrix, conf_matrix_2


# def dense_to_one_hot(labels_dense, num_classes=n_classes):
def dense_to_one_hot(labels_dense, num_classes=0):
	"""Convert class labels from scalars to one-hot vectors."""
	num_labels = labels_dense.shape[0]  # num_labels is the same as num of images
	index_offset = np.arange(num_labels) * num_classes
	labels_one_hot = np.zeros((num_labels, num_classes))
	# each label is written as one vector:eg. class 0 of total 6 classes is [1,0,0,0,0,0]
	labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1
	if DEBUG == 1:
		print 'one_hot_vector:', labels_one_hot[0]
	return labels_one_hot


# Implementing softmax function on the DL output scores, adopted only for 2 classes
# hy: for final output layer using softmax classification
def convert_to_confidence(scores):
	h, w = scores.shape
	output = np.zeros((h, w), dtype=np.float32)
	sum = np.zeros((h, 1), dtype=np.float32)
	# if sum != 0:
	for i in range(0, w):
		sum[:, 0] += np.exp(scores[:, i])
	# print 'sum i =', sum[:, 0]
	for i in range(0, w):
		# print 'sum out =', sum[:, 0]
		output[:, i] = np.exp(scores[:, i]) / sum[:, 0]
	# class0=math.exp(scores[0,0])/(math.exp(scores[0,1])+math.exp(scores[0,0]))
	#    class1=math.exp(scores[0,1])/(math.exp(scores[0,1])+math.exp(scores[0,0]))
	#  output=[class0, class1]
	# else:
	#  print 'sum is 0'
	return output


# Adds noise to gray level images, nomalizes the image again
def add_noise(img, noise_level):
	img = img.astype(np.float32)
	h = img.shape[0]
	w = img.shape[1]
	img_noised = img + np.random.rand(h, w) * noise_level
	img_noised = (img_noised / np.max(img_noised)) * 255
	# img_noised=img_noised.astype(np.uint8)
	return img_noised

import re
def REMOVE_online_Data(step):
	# print 'removing data'
	for i in xrange(len(LABELS)):
		# cmd = 'rm -r ' + data + folder_list[i] + '/*rotated*.*'  # hy: remove recursively
		# os.system(cmd)
		dir = settings.data + settings.LABELS[i]
		# dir = dir[:-1]
		for f in os.listdir(dir):
			if re.search('/*_st*.*', f) is not None:
				os.remove(os.path.join(dir, f))

def calc_mean_stdev(images):
	mean = np.mean(images)
	print 'mean', mean
	stdev = np.std(images)
	print 'stdev', stdev
	return mean, stdev

def reduce_mean_stdev(images,print_val=False):
	mean = np.mean(images)
	stdev = np.std(images)
	if print_val:
		print 'mean %d,stdev %d', (mean, stdev)
	
	images = images - mean
	
	images_reduced_mean = images / stdev
	
	return images_reduced_mean

############  for seg-net     ######################
def import_data_segnet_2c_v1_not_read_file_names(data_path, file_img, file_mask, h, w, maxNum, file_num=1,
                                                 do_Flipping=False):
	depth = 1
	ch = 1
	print 'load data', data_path, file_img, file_mask, h, w, maxNum, do_Flipping
	images = np.zeros((maxNum * 4, ch, h, w))
	masks = np.zeros((maxNum * 4, ch, h, w))
	
	data_counter = 0
	for i in range(1, maxNum + 1):
		# file_num = 5
		fmask = data_path + file_mask % file_num  #
		# print i, 'of ',maxNum,'join path and current mask file name:',fmask
		
		fimg = data_path + file_img % file_num
		print '\n', i, 'of ', maxNum, 'join path and current img file name:', fimg
		
		mask = cv2.imread(fmask, 0)
		
		print 'read image'
		img = cv2.imread(fimg, 0)
		
		if mask is None or img is None:
			continue
		
		mask = cv2.resize(mask, (h, w))
		img = cv2.resize(img, (h, w))
		
		data_counter += 1
		# debug
		# cv2.imshow("img_window",img)
		# cv2.waitKey(100)
		
		mask = mask.reshape(h, w)
		img = np.float32(img.reshape(h, w))
		# debug
		# print '1-min/max:%f %f, mean: %f, std: %f of loaded image' % (np.min(img),np.max(img), np.mean(img), np.std(img))
		
		mask = mask / 255.0
		img = img / 255.0
		# debug
		# print '2-min/max:%f %f, mean: %f, std: %f of loaded image' % (np.min(img),np.max(img), np.mean(img),np.std(img))
		
		
		if do_Flipping:
			for fl in range(-1, 2):
				flipped_img = cv2.flip(img, fl)
				flipped_mask = cv2.flip(mask, fl)
				
				images[data_counter, :, :, :] = flipped_img
				masks[data_counter, :, :, :] = np.float32(flipped_mask > 0)
				data_counter += 1
		
		images[i, :, :, :] = img
		masks[i, :, :, :] = np.float32(mask > 0)
		
		if i % 100 == 0:
			print 'i=', i
	print 'total', data_counter, 'images and', data_counter, 'masks are loaded'
	# return images, masks
	return images[0:data_counter, :, :, :], masks[0:data_counter, :, :, :]

def import_data_k_segnet(im_path,label_path, file_imgs, file_masks, h, w, maxNum, MUL=False,
						  do_Flipping=False,do_gblur=False,do_darken=False):
	from scipy import ndimage as nd
	import scipy.misc as misc

	INPUT_CH = 1
	if MUL:
		INPUT_CH = 3 #3
		print 'loading data with input channel:', INPUT_CH
		
	rnd_flip, rnd_gblur, rnd_darken = [], [], []
	if do_Flipping:
		rnd_flip = random.sample(xrange(maxNum - 1), maxNum - 1)
	if do_gblur:
		rnd_gblur = random.sample(xrange(maxNum - 1), maxNum - 2)
	if do_darken:
		rnd_darken = random.sample(xrange(maxNum - 1), maxNum - 1)  # 80
	
	maxNum = 3*len(rnd_flip) + len(rnd_gblur) + len(rnd_darken) + len(file_imgs)+4
	#todo: check len of total input images

	d = 0 if INPUT_CH == 1 else -1

	print 'maxNum :', maxNum

	# out: images pixel value divided by 255, so they have value between 0 and 1,
	# #mask is composed of 0s and 1s, for two classes
	images = np.zeros((maxNum, INPUT_CH, h, w))
	masks = np.zeros((maxNum, 1, h, w))

	print 'load data', im_path, h, w, maxNum, do_Flipping
	#images = np.zeros((maxNum * 4, ch, h, w))
	#masks = np.zeros((maxNum * 4, ch, h, w))

	data_counter = 0
	no_raw_files = len(file_imgs)
	for i, img, m in zip(range(1, no_raw_files + 1), file_imgs, file_masks):
		# fimg = im
		fimg = im_path + img
		print '\n#', i, 'of', no_raw_files, 'img file name:', fimg

		fmask = label_path + m  #
		# print i, 'of ',maxNum,'join path and current mask file name:',fmask
		print '\n#', i, 'of', len(file_imgs), 'mask file name:', fmask

		print 'show image'
		img = cv2.imread(fimg, d)  # d >0: 3-channel, =0: 1-channel, <0:no change
		mask = cv2.imread(fmask, 0)  #always greyscale

		if mask is None or img is None:
			continue

		img = cv2.resize(img, (h, w))
		mask = cv2.resize(mask, (h, w))

		
		# debug
		# cv2.imshow("img_window",img)
		# cv2.waitKey(100)

		img = np.float32(img.reshape(INPUT_CH, h, w))
		mask = mask.reshape(1, h, w)

		img = img / 255.0
		mask = mask / 255.0

		if do_Flipping and i in rnd_flip:
			img_copy = img.copy()
			mask_copy = mask.copy()
			for fl in range(-1, 2):
				flipped_img = cv2.flip(img_copy, fl)
				flipped_mask = cv2.flip(mask_copy, fl)

				images[data_counter, :, :, :] = flipped_img

				if MUL:
					masks[data_counter, :, :, :] = np.float32(flipped_mask)  #no need to expand dim
					#np.expand_dims(np.array(mask_copy), 2).astype(np.float32)
				else:
					masks[data_counter, :, :, :] = np.float32(flipped_mask > 0)
				data_counter += 1

		if do_gblur and i in rnd_gblur:
			img_copy = img.copy()
			mask_copy = mask.copy()

			rnd_blurriness = 0.01 * randint(150, 280)

			gblur_img = nd.gaussian_filter(img_copy, sigma=rnd_blurriness)
			images[data_counter, :, :, :] = gblur_img

			if MUL:
				masks[data_counter, :, :, :] = np.float32(mask_copy) ##no need to expand dim
			else:
				masks[data_counter, :, :, :] = np.float32(mask_copy > 0)
			#masks[data_counter, :, :, :] = np.expand_dims(np.array(mask_copy > threshold), 2).astype(
			#	np.uint32)

			data_counter += 1

		if do_darken and i in rnd_darken: # and i in rnd_darken:
			img_copy = cv2.imread(fimg)
			img_copy = cv2.resize(img_copy, (h, w))

			mask_copy = mask.copy()

			dark_img = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)
			dark_img = Image.fromarray(dark_img)  # Image.fromarray(im1misc)
			rnd_darkness = 0.01*randint(29,150)
			dark_img = dark_img.point(lambda p: p*rnd_darkness)
			dark_img = cv2.cvtColor(np.array(dark_img), cv2.COLOR_RGB2BGR)

			cv2.imwrite('../tmp_k1.png',dark_img)
			if INPUT_CH == 1:
				dark_img = cv2.imread('../tmp_k1.png',0)
			else:
				dark_img = cv2.imread('../tmp_k1.png')
				
			cmd = 'rm ../tmp_k1.png'
			os.system(cmd)

			#dark_img = cv2.resize(dark_img, (h, w))
			dark_img = np.float32(dark_img.reshape(INPUT_CH, h, w))
			dark_img = dark_img / 255.0 #if added the image does not become dark

			images[data_counter, :, :, :] = dark_img

			#masks_np[data_counter, :, :, :] = np.expand_dims(np.array(mask_copy > threshold), 2).astype(
			#	np.float32)
			if MUL:
				masks[data_counter, :, :, :] = np.float32(mask_copy) #no need to expand dim
			else:
				masks[data_counter, :, :, :] = np.float32(mask_copy>0)

			data_counter += 1


		images[data_counter, :, :, :] = img
		if MUL:
			masks[data_counter, :, :, :] = np.float32(mask>0) # no need to expand dim
		else:
			masks[data_counter, :, :, :] = np.float32(mask > 0)
		
		data_counter += 1

	print 'total', data_counter, 'images and', data_counter, 'masks are loaded'
	# return images, masks
	return images[0:data_counter, :, :, :], masks[0:data_counter, :, :, :]

def import_data_k_resnet(im_path,label_path, file_imgs, file_masks, h, w, maxNum, MUL=False,
						  do_Flipping=False,do_gblur=False,do_darken=False):
	from scipy import ndimage as nd
	import scipy.misc as misc

	INPUT_CH = 3

	d = 0 if INPUT_CH == 1 else -1

	maxNum_factor = 1

	rnd_flip = random.sample(xrange(maxNum - 1), maxNum - 1)
	rnd_gblur = random.sample(xrange(maxNum - 1), int(maxNum*0.9))
	rnd_darken = random.sample(xrange(maxNum - 1), int(maxNum*0.3))
	maxNum = len(rnd_flip) * 3 + len(rnd_gblur) + len(rnd_darken) + len(file_imgs)


	print 'maxNum factor:', maxNum_factor

	# out: images pixel value divided by 255, so they have value between 0 and 1,
	# #mask is composed of 0s and 1s, for two classes
	images = np.zeros((maxNum, INPUT_CH, h, w))
	masks = np.zeros((maxNum, 1, h, w))

	print 'load data', im_path, h, w, maxNum, do_Flipping
	#images = np.zeros((maxNum * 4, ch, h, w))
	#masks = np.zeros((maxNum * 4, ch, h, w))

	data_counter = 0
	for i, img, m in zip(range(1, maxNum + 1), file_imgs, file_masks):
		# fimg = im
		fimg = im_path + img
		print '\n####', i, 'of ', maxNum, 'img file name:', fimg

		fmask = label_path + m  #
		# print i, 'of ',maxNum,'join path and current mask file name:',fmask
		print '\n####', i, 'of ', maxNum, 'mask file name:', fmask

		print 'show image'
		img = cv2.imread(fimg, d)  # d >0: 3-channel, =0: 1-channel, <0:no change
		mask = cv2.imread(fmask, 0)  #always greyscale

		if mask is None or img is None:
			continue

		img = cv2.resize(img, (h, w))
		mask = cv2.resize(mask, (h, w))

		data_counter += 1
		# debug
		# cv2.imshow("img_window",img)
		# cv2.waitKey(100)

		img = np.float32(img.reshape(INPUT_CH, h, w))
		mask = mask.reshape(1, h, w)

		img = img / 255.0
		mask = mask / 255.0

		if do_Flipping and i in rnd_flip:
			img_copy = img.copy()
			mask_copy = mask.copy()
			for fl in range(-1, 2):
				flipped_img = cv2.flip(img_copy, fl)
				flipped_mask = cv2.flip(mask_copy, fl)

				images[data_counter, :, :, :] = flipped_img

				if MUL:
					masks[data_counter, :, :, :] = np.float32(flipped_mask)
				else:
					masks[data_counter, :, :, :] = np.float32(flipped_mask > 0)
				data_counter += 1

		if do_gblur and i in rnd_gblur:
			img_copy = img.copy()
			mask_copy = mask.copy()

			rnd_blurriness = 0.01 * randint(150, 280)
			gblur_img = nd.gaussian_filter(img_copy, sigma=rnd_blurriness)

			images[data_counter, :, :, :] = gblur_img

			if MUL:
				masks[data_counter, :, :, :] = np.float32(mask_copy)
			else:
				masks[data_counter, :, :, :] = np.float32(mask_copy > 0)
			#masks[data_counter, :, :, :] = np.expand_dims(np.array(mask_copy > threshold), 2).astype(
			#	np.uint32)

			data_counter += 1

		if do_darken and i in rnd_darken:

			img_copy = misc.imread(fimg)
			mask_copy = mask.copy()

			#dark_img = cv2.cvtColor(img_copy,cv2.COLOR_BGR2RGB)
			#dark_img = cv2.cvtColor(np.array(dark_img),cv2.COLOR_RGB2BGR)

			dark_img_pil = Image.fromarray(img_copy)  #Image.fromarray(im1misc)
			rnd_darkness = 0.01*randint(29,150)
			dark_img_p = dark_img_pil.point(lambda p: p*rnd_darkness)
			dark_img_p.save('../tmp.png')
			dark_img = misc.imread('../tmp.png')
			#print 'before 11:', dark_img
			cmd = 'rm ../tmp.png'
			os.system(cmd)

			dark_img = misc.imresize(dark_img, [h, w], interp='nearest')
			dark_img = np.float32(dark_img.reshape(h, w, INPUT_CH))
			dark_img = dark_img / 255.0 #if added the image does not become dark
			#misc.imshow(dark_img)

			images[data_counter, :, :, :] = dark_img

			#masks_np[data_counter, :, :, :] = np.expand_dims(np.array(mask_copy > threshold), 2).astype(
			#	np.float32)
			if MUL:
				masks[data_counter, :, :, :] = np.expand_dims(np.array(mask_copy), 2).astype(
					np.float32)
			else:
				masks[data_counter, :, :, :] = np.expand_dims(np.array(mask_copy>0), 2).astype(
					np.float32)

			data_counter += 1


		images[data_counter, :, :, :] = img
		if MUL:
			masks[data_counter, :, :, :] = np.expand_dims(np.array(mask), 2).astype(
					np.float32)
			#masks[data_counter, :, :, :] = np.float32(mask)
		else:
			#masks[data_counter, :, :, :] = np.expand_dims(np.array(mask>0), 2).astype(
			#		np.float32)
			masks[data_counter, :, :, :] = np.float32(mask > 0)

	print 'total', data_counter, 'images and', data_counter, 'masks are loaded'
	# return images, masks
	return images[0:data_counter, :, :, :], masks[0:data_counter, :, :, :]



def import_data_seg_k_2c_rgb(im_path,label_path, file_imgs, file_masks, h, w, maxNum, do_Flipping=False):
	'''
	use gray images as input, all values of images and masks are set to 0 to 1 float
	:param im_path:
	:param label_path:
	:param file_imgs:
	:param file_masks:
	:param h:
	:param w:
	:param maxNum:
	:param do_Flipping:
	:return:
	'''
	ch = 3  # 1

	print 'load data', im_path, h, w, maxNum, do_Flipping
	if do_Flipping:
		maxNum = maxNum * 4

	images = np.zeros((maxNum, ch, h, w))
	masks = np.zeros((maxNum, ch, h, w))

	data_counter = 0
	for i, img, m in zip(range(1, maxNum + 1), file_imgs, file_masks):
		# fimg = im
		fimg = im_path + img
		print '\n####', i, 'of file ', len(file_imgs), 'img file name:', fimg

		fmask = label_path + m  #
		print '\n####', i, 'of file ', len(file_imgs), 'mask file name:', fmask

		print 'show image'
		img = cv2.imread(fimg, -1)
		mask = cv2.imread(fmask, 0)  # d >0: 3-channel, =0: 1-channel, <0:no change

		if mask is None or img is None:
			continue

		mask = cv2.resize(mask, (h, w))
		img = cv2.resize(img, (h, w))

		data_counter += 1
		# debug
		# cv2.imshow("img_window",img)
		# cv2.waitKey(100)

		mask = mask.reshape(1, h, w)
		img = np.float32(img.reshape(ch, h, w))

		mask = mask / 255.0
		img = img / 255.0

		if do_Flipping:
			for fl in range(-1, 2):
				flipped_img = cv2.flip(img, fl)
				flipped_mask = cv2.flip(mask, fl)

				images[data_counter, :, :, :] = flipped_img
				masks[data_counter, :, :, :] = np.float32(flipped_mask)
				data_counter += 1

		images[i, :, :, :] = img
		masks[i, :, :, :] = np.float32(mask)

		if i % 100 == 0:
			print 'i=', i
	print 'total', data_counter, 'images and', data_counter, 'masks are loaded'
	# return images, masks
	return images[0:data_counter, :, :, :], masks[0:data_counter, :, :, :]

def import_data_seg_2c_v2_rotation(data_path, file_imgs, file_masks, h, w, maxNum, do_Flipping=False):
	ch = 1  # 1
	d = 0 if ch == 1 else -1
	print 'load data', data_path, h, w, maxNum, do_Flipping
	images = np.zeros((maxNum * 5, ch, h, w))  # th:ch, h, w for keras
	masks = np.zeros((maxNum * 5, ch, h, w))
	
	data_counter = 0
	for i, img, m in zip(range(1, maxNum + 1), file_imgs, file_masks):
		# fimg = im
		fimg = data_path + 'images/' + img
		print '\n####', i, 'of ', maxNum, 'img file name:', fimg
		
		fmask = data_path + 'labels/' + m  #
		print '\n####', i, 'of ', maxNum, 'mask file name:', fmask
		
		# print 'show image'
		img = cv2.imread(fimg, d)
		mask = cv2.imread(fmask, d)  # d >0: 3-channel, =0: 1-channel, <0:no change
		
		do_rotation = False
		if do_rotation:
			rot_img = imutils.rotate(img, angle=5)
			rot_mask = imutils.rotate(mask, angle=5)
			
			rot_img = cv2.resize(rot_img, (h, w))
			rot_mask = cv2.resize(rot_mask, (h, w))
			
			rot_img = np.float32(rot_img.reshape(h, w, ch))
			rot_mask = rot_mask.reshape(h, w, ch)
			
			rot_img = rot_img / 255.0
			rot_mask = rot_mask / 255.0
			
			images[data_counter, :, :, :] = rot_img
			masks[data_counter, :, :, :] = np.float32(rot_mask > 0)
			data_counter += 1
		
		if mask is None or img is None:
			continue
		
		img = cv2.resize(img, (h, w))
		mask = cv2.resize(mask, (h, w))
		
		# debug
		# cv2.imshow("img_window",img)
		# cv2.waitKey(100)
		
		img = np.float32(img.reshape(ch, h, w))  # th (keras):ch, h, w
		mask = mask.reshape(ch, h, w)
		
		img = img / 255.0
		mask = mask / 255.0
		
		if do_Flipping:
			for fl in range(-1, 2):
				flipped_img = cv2.flip(img, fl)
				flipped_mask = cv2.flip(mask, fl)
				
				images[data_counter, :, :, :] = flipped_img
				masks[data_counter, :, :, :] = np.float32(flipped_mask > 0)
				data_counter += 1
		
		images[data_counter, :, :, :] = img
		masks[data_counter, :, :, :] = np.float32(mask > 0)
		
		data_counter += 1
		if i % 100 == 0:
			print 'i=', i
	print 'total', data_counter, 'images and', data_counter, 'masks are loaded'
	# return images, masks
	return images[0:data_counter, :, :, :], masks[0:data_counter, :, :, :]
# return images[0:data_counter, :, :, :], masks[0:data_counter, :, :, :]


# output list of pixel values
def import_data_seg_2c_tf_v2(data_path, file_imgs, file_masks, h, w, maxNum, do_Flipping=False):
	# args
	# out: images pixel value divided by 255, so they have value between 0 and 1,
	# #mask is composed of 0s and 1s, for two classes
	
	ch = 1  # 1
	d = 0 if ch == 1 else -1
	print 'load data', data_path, h, w, maxNum, do_Flipping
	images, masks = [], []
	data_counter = 0
	for i, img, m in zip(range(1, maxNum + 1), file_imgs, file_masks):
		fimg = data_path + 'images/' + img
		# print '\n####', i, 'of ', maxNum, 'img file name:', fimg
		
		fmask = data_path + 'labels/' + m  #
		# print '\n####', i, 'of ', maxNum, 'mask file name:', fmask
		
		img = cv2.imread(fimg, d)
		mask = cv2.imread(fmask, d)  # d >0: 3-channel, =0: 1-channel, <0:no change
		
		# debug
		# cv2.imshow('mask',mask)
		# cv2.waitKey()
		
		do_rotation = False
		if do_rotation:
			rot_img = imutils.rotate(img, angle=5)
			rot_mask = imutils.rotate(mask, angle=5)
			
			rot_img = cv2.resize(rot_img, (h, w))
			rot_mask = cv2.resize(rot_mask, (h, w))
			
			rot_img = np.float32(rot_img.reshape(ch, h, w))
			rot_mask = rot_mask.reshape(ch, h, w)
			
			# rot_img = rot_img / 255.0
			# rot_mask = rot_mask / 255.0
			
			images[data_counter, :, :, :] = rot_img
			masks[data_counter, :, :, :] = np.float32(rot_mask > 0)
			data_counter += 1
		
		if mask is None or img is None:
			continue
		
		# debug
		# cv2.imshow("img_window",img)
		# cv2.waitKey(100)
		
		img = cv2.resize(img, (h, w))
		mask = cv2.resize(mask, (h, w))
		# print 'mask resize size:', mask.size, ', mask\n', mask
		
		# img = np.asarray(np.float32(img.reshape(ch, h, w)))
		# mask = np.asarray(mask.reshape(ch, h, w))
		# print 'mask as array size:', mask.size, ', mask\n', mask
		
		img = img / 255.0
		mask = mask / 255.0
		
		if do_Flipping:
			for fl in range(-1, 2):
				flipped_img = cv2.flip(img, fl)
				flipped_mask = cv2.flip(mask, fl)
				
				images.append(flipped_img)
				masks.append(np.float32(flipped_mask > 0))
				data_counter += 1
		
		images.append(img)
		
		# masks.append(np.int32(mask))
		# mask = np.asarray(mask)
		# print 'mask i', mask[100]
		# print 'mask size:',mask.size, ', mask shape:', mask.shape
		
		# print masks[10]
		# masks.append(np.float32(mask > 0)) #for other cases
		mask = mask.astype(np.float)
		masks.append(mask > 0)  # for other cases
		# masks.append(np.int32(mask > 0)) # use int at input for tf bin
		# cv2.imshow('mask',mask)
		# cv2.waitKey()
		# masks.append(np.float32(mask>0))
		
		data_counter += 1
		if i % 100 == 0:
			print 'i=', i
	
	images_np = np.asarray(images)
	
	masks_np = np.asarray(masks)
	print 'y type1:', type(masks_np), type(masks_np[0]), type(mask)
	# debug print 'masks:',masks[data_counter-1]
	print 'total', data_counter, 'images and', data_counter, 'masks are loaded,flipping', do_Flipping
	return images_np, masks_np

# only two types of flipping available, using misc
def import_data_seg_tf_2c_onlygray_int(im_path, label_path, file_imgs, file_masks, h, w, maxNum, MUL=False,
                                      do_Flipping=False):
	import scipy.misc as misc
	# args
	
	INPUT_CH = 3  # ori3
	# out: images pixel value divided by 255, so they have value between 0 and 1,
	# #mask is composed of 0s and 1s, for two classes
	if do_Flipping:
		maxNum = 3 * maxNum
	
	images_np = np.zeros((maxNum, h, w, INPUT_CH))
	masks_np = np.zeros((maxNum, h, w, 1))
	
	print 'load data', im_path, h, w, maxNum, do_Flipping
	data_counter = 0
	for i, img, m in zip(range(1, maxNum + 1), file_imgs, file_masks):
		fimg = im_path + img
		# print '\n####', i, 'of ', maxNum, 'img file name:', fimg
		
		fmask = label_path + m  #
		# print '\n####', i, 'of ', maxNum, 'mask file name:', fmask
		img_g = misc.imread(fimg, 'I')  #
		img_g = np.array([img_g for i in range(3)])
		
		# mask = misc.imread(fmask, 'I')  # read as signed int32
		mask = misc.imread(fmask)  # read original form, 1-channel (but must check previously whether all files are 1-channel)
		dim_of_mask = np.ndim(mask)
		#print 'dim of mask:', dim_of_mask, ', shape:', mask.shape
		if dim_of_mask > 2:
			mask = misc.imread(fmask, 'I')
		
		
		if mask is None or img_g is None:
			continue
		
		img_g = misc.imresize(img_g, [h, w], interp='nearest')
		img_g = np.float32(img_g.reshape(h, w, INPUT_CH))
		
		mask = misc.imresize(mask, [h, w], interp='nearest')
		#print '#####  ',fmask,',mask resized shape:', mask.shape
		
		# print 'mask resize size:', mask.size, ', mask\n', mask
		img_g = img_g / 255.0  # make all values between 0 - 255 and as int
		mask = mask / 255.0  # make all values between 0 - 255 and as int
		
		if do_Flipping:
			img_g_copy = img_g.copy()
			mask_copy = mask.copy()
			
			for fl in range(0, 2):
				flipped_img_g = np.flip(img_g_copy, fl)
				flipped_mask = np.flip(mask_copy, fl)
				# misc.imshow(flipped_img)
				
				images_np[data_counter, :, :, :] = flipped_img_g
				
				if MUL:
					masks_np[data_counter, :, :, :] = np.array(flipped_mask).astype(np.uint32)
					#masks_np[data_counter, :, :, :] = np.expand_dims(np.array(flipped_mask), 2).astype(np.uint32)
					#.astype(np.float32)
					
				else:
					#masks_np[data_counter, :, :, :] = np.array(flipped_mask > 0).astype(np.uint32)
					masks_np[data_counter, :, :, :] = np.expand_dims(np.array(flipped_mask > 0), 2).astype(np.uint32)
				
				data_counter += 1
		
		# print 'img shape:', img.shape #old: (320, 320, 3)
		
		images_np[data_counter, :, :, :] = img_g
		# masks_np[data_counter, :, :, :] = np.float32(mask > 0)
		if MUL:
			masks_np[data_counter, :, :, :] = np.expand_dims(np.array(mask), 2).astype(np.uint32)
		else:
			masks_np[data_counter, :, :, :] = np.expand_dims(np.array(mask > 0), 2).astype(np.uint32)
		
		display_mask = False
		if display_mask and data_counter < 10:
			misc.imshow(masks_np[data_counter, :, :, :].reshape((h, w)))
		
		data_counter += 1
	
	# debug print 'masks:',masks[data_counter-1]
	print 'total', data_counter, 'images and', data_counter, 'masks are loaded,flipping', do_Flipping
	print 'mask max,min:', np.max(masks_np[0]), ', ', np.min(masks_np[0])
	if display_mask:
		for i in xrange(30):
			print masks_np[0][i][i][0],
			print '\n'
	return images_np, masks_np


# only two types of flipping available, using misc
def import_data_seg_tf_3c_int(im_path, label_path, file_imgs, file_masks, h, w, maxNum, MUL=False,
                                        do_Flipping=False):
	import scipy.misc as misc
	# args
	
	INPUT_CH = 3  # ori3
	# out: images pixel value divided by 255, so they have value between 0 and 1,
	# #mask is composed of 0s and 1s, for two classes
	if do_Flipping:
		maxNum = 3 * maxNum
	
	images_np = np.zeros((maxNum, h, w, INPUT_CH))
	masks_np = np.zeros((maxNum, h, w, 1))
	
	print 'load data', im_path, h, w, maxNum, do_Flipping
	data_counter = 0
	for i, img, m in zip(range(1, maxNum + 1), file_imgs, file_masks):
		fimg = im_path + img
		# print '\n####', i, 'of ', maxNum, 'img file name:', fimg
		
		fmask = label_path + m  #
		# print '\n####', i, 'of ', maxNum, 'mask file name:', fmask
		img = misc.imread(fimg)  #
		#img_g = misc.imread(fimg, 'I')  #
		#img_g = np.array([img_g for i in range(3)])
		
		# mask = misc.imread(fmask, 'I')  # read as signed int32
		mask = misc.imread(fmask,mode='RGB')  # read original form, 1-channel (but must check previously whether all files are 1-channel)
		dim_of_mask = np.ndim(mask)
		# print 'dim of mask:', dim_of_mask, ', shape:', mask.shape
		
		if mask is None or img is None:
			continue
		
		img = misc.imresize(img, [h, w], interp='nearest')
		img = np.float32(img.reshape(h, w, INPUT_CH))
		#img_g = misc.imresize(img_g, [h, w], interp='nearest')
		#img_g = np.float32(img_g.reshape(h, w, INPUT_CH))
		
		mask = misc.imresize(mask, [h, w], interp='nearest')
		# misc.imshow(mask)
		# print '#####  ',fmask,',mask resized shape:', mask.shape
		
		# print 'mask resize size:', mask.size, ', mask\n', mask
		# img_g = img_g / 255.0  # make all values between 0 - 255 and as int
		# mask = mask / 255.0  # make all values between 0 - 255 and as int
		
		if do_Flipping:
			img_copy = img.copy() #must use copy
			mask_copy = mask.copy()
				
			for fl in range(0, 2):
				flipped_img = np.flip(img_copy, fl)
				flipped_mask = np.flip(mask_copy, fl)
				# misc.imshow(flipped_img)
				
				# gt_image[i,j,k] == 1
				# masks_np[data_counter, :, :, :] = np.expand_dims(np.array(flipped_mask)).astype(np.uint32)
				# masks_np[data_counter, :, :, :] = np.expand_dims(np.array(flipped_mask), 2).astype(np.uint32)
				if data_counter > 1 and data_counter < 6:
					n, diff_v = count_diff_pixel_values(flipped_mask[:, :, 0], h, w)
					print 'num of diff0:', n, diff_v
					n, diff_v = count_diff_pixel_values(flipped_mask[:, :, 1], h, w)
					print 'num of diff1:', n, diff_v
					n, diff_v = count_diff_pixel_values(flipped_mask[:, :, 2], h, w)
					print 'num of diff2:', n, diff_v
				
				flipped_mask[flipped_mask < 160] = 0
				flipped_mask[flipped_mask == 160] = 1
				flipped_mask[flipped_mask == 200] = 2
				
				images_np[data_counter, :, :, :] = flipped_img
				masks_np[data_counter, :, :, 0] = np.array(flipped_mask[:, :, 0]).astype(np.uint32)
				
				data_counter += 1
		
		# print 'img shape:', img.shape #old: (320, 320, 3)
		
		images_np[data_counter, :, :, :] = img
		# masks_np[data_counter, :, :, :] = np.float32(mask > 0)
		mask[mask < 160] = 0
		mask[mask == 160] = 1
		mask[mask == 200] = 2
		mask[mask == 255] = 2
		
		masks_np[data_counter, :, :, 0] = np.array(mask[:, :, 0]).astype(np.uint32)
		
		display_mask = False
		if display_mask and data_counter < 10:
			misc.imshow(masks_np[data_counter, :, :, 2].reshape((h, w)))
		
		data_counter += 1
	
	# debug print 'masks:',masks[data_counter-1]
	print 'total', data_counter, 'images and', data_counter, 'masks are loaded,flipping', do_Flipping
	print 'mask max,min:', np.max(masks_np[0]), ', ', np.min(masks_np[0])
	if display_mask:
		for i in xrange(30):
			print masks_np[0][i][i][0],
			print '\n'
	
	return images_np, masks_np


# only two types of flipping available, using misc
def import_data_seg_tf_3c_onlygray_int(im_path, label_path, file_imgs, file_masks, h, w, maxNum, MUL=False,
									do_Flipping=False):
	import scipy.misc as misc
	# args

	INPUT_CH = 3  # ori3
	NUM_OF_CLASSESS = 3 #0:bg, 1:fg side 2:fg oben
	# out: images pixel value divided by 255, so they have value between 0 and 1,
	# #mask is composed of 0s and 1s, for two classes
	if do_Flipping:
		maxNum = 3 * maxNum

	images_np = np.zeros((maxNum, h, w, INPUT_CH))
	masks_np = np.zeros((maxNum, h, w, 1))

	print 'load data', im_path, h, w, maxNum, do_Flipping
	data_counter = 0
	for i, img, m in zip(range(1, maxNum + 1), file_imgs, file_masks):
		fimg = im_path + img
		# print '\n####', i, 'of ', maxNum, 'img file name:', fimg

		fmask = label_path + m  #
		# print '\n####', i, 'of ', maxNum, 'mask file name:', fmask
		img_g = misc.imread(fimg, 'I')  #
		img_g = np.array([img_g for i in range(3)])

		# mask = misc.imread(fmask, 'I')  # read as signed int32
		mask = misc.imread(fmask,mode='RGB')  # read original form, 1-channel (but must check previously whether all files are 1-channel)
		dim_of_mask = np.ndim(mask)
		# print 'dim of mask:', dim_of_mask, ', shape:', mask.shape
		
		if mask is None or img_g is None:
			continue

		img_g = misc.imresize(img_g, [h, w], interp='nearest')
		img_g = np.float32(img_g.reshape(h, w, INPUT_CH))

		mask = misc.imresize(mask, [h, w], interp='nearest')
		#misc.imshow(mask)
		# print '#####  ',fmask,',mask resized shape:', mask.shape

		# print 'mask resize size:', mask.size, ', mask\n', mask
		#img_g = img_g / 255.0  # make all values between 0 - 255 and as int
		#mask = mask / 255.0  # make all values between 0 - 255 and as int

		if do_Flipping:
			img_g_copy = img_g.copy()
			mask_copy = mask.copy()
			
			for fl in range(0, 2):
				flipped_img_g = np.flip(img_g_copy, fl)
				flipped_mask = np.flip(mask_copy, fl)
				# misc.imshow(flipped_img)

				images_np[data_counter, :, :, :] = flipped_img_g
				#gt_image[i,j,k] == 1
				#masks_np[data_counter, :, :, :] = np.expand_dims(np.array(flipped_mask)).astype(np.uint32)
				#masks_np[data_counter, :, :, :] = np.expand_dims(np.array(flipped_mask), 2).astype(np.uint32)
				if data_counter > 1 and data_counter < 6:
					n, diff_v = count_diff_pixel_values(flipped_mask[:,:,0], h, w)
					print 'num of diff0:', n,diff_v
					n, diff_v = count_diff_pixel_values(flipped_mask[:,:,1], h, w)
					print 'num of diff1:', n,diff_v
					n, diff_v = count_diff_pixel_values(flipped_mask[:,:,2], h, w)
					print 'num of diff2:', n,diff_v
					
				flipped_mask [flipped_mask <160] = 0
				flipped_mask [flipped_mask == 160] = 1
				flipped_mask [flipped_mask == 200] = 2
				
					
				masks_np[data_counter, :, :, 0] = np.array(flipped_mask[:,:,0]).astype(np.uint32)
				
				data_counter += 1

		# print 'img shape:', img.shape #old: (320, 320, 3)

		images_np[data_counter, :, :, :] = img_g
		# masks_np[data_counter, :, :, :] = np.float32(mask > 0)
		mask[mask < 160] = 0
		mask[mask == 160] = 1
		mask[mask == 200] = 2
		
		masks_np[data_counter, :, :, 0] = np.array(mask[:,:,0]).astype(np.uint32)

		display_mask = False
		if display_mask and data_counter < 10:
			misc.imshow(masks_np[data_counter, :, :, 2].reshape((h, w)))
		
		data_counter += 1

	# debug print 'masks:',masks[data_counter-1]
	print 'total', data_counter, 'images and', data_counter, 'masks are loaded,flipping', do_Flipping
	print 'mask max,min:', np.max(masks_np[0]), ', ', np.min(masks_np[0])
	if display_mask:
		for i in xrange(30):
			print masks_np[0][i][i][0],
			print '\n'
			
	
	return images_np, masks_np


# only two types of flipping available, using misc, only mul case + gray
def import_data_seg_2c_tf_rgb_int(im_path, label_path, file_imgs, file_masks, h, w, maxNum, MUL=False, ch=3,
									  do_Flipping=False,do_gblur=False):
	import scipy.misc as misc
	from scipy import ndimage as nd
	# args

	INPUT_CH = 3  # ori3
	maxNum_factor = 1
	INPUT_CH = 3  # ori3
	if do_Flipping:
		maxNum_factor = 3
	if do_gblur:
		maxNum_factor = maxNum_factor + 1

	print 'maxNum factor:', maxNum_factor

	# out: images pixel value divided by 255, so they have value between 0 and 1,
	# #mask is composed of 0s and 1s, for two classes
	images_np = np.zeros((maxNum*maxNum_factor , h, w, INPUT_CH))
	masks_np = np.zeros((maxNum*maxNum_factor, h, w, 1))

	print 'load data, incl. flipping', im_path, h, w, maxNum, do_Flipping
	data_counter = 0
	for i, img, m in zip(range(1, maxNum + 1), file_imgs, file_masks):
		fimg = im_path + img

		fmask = label_path + m  #

		img = misc.imread(fimg)  # ori 3  #np.flip(self._transform(filename), 0)

		mask = misc.imread(fmask)  # changed, removed 'I' as all mask files must be saved to 1-channel
		dim = len(mask.shape)
		if dim == 3:
			mask = misc.imread(fmask, 'I')

		if mask is None or img is None:
			continue

		img = misc.imresize(img, [h, w], interp='nearest')
		img = np.float32(img.reshape(h, w, INPUT_CH))

		mask = misc.imresize(mask, [h, w], interp='nearest')  # change

		# print 'mask resize size:', mask.size, ', mask\n', mask
		# img = img / 255.0  # make all values between 0 - 255 and as int
		# img_g = img_g / 255.0  # make all values between 0 - 255 and as int
		# for mask not dividing to 1
		# mask = mask / 255.0  # make all values between 0 - 255 and as int

		if do_Flipping:
			img_copy = img.copy()
			mask_copy = mask.copy()

			for fl in range(0, 2):
				flipped_img = np.flip(img_copy, fl)
				flipped_mask = np.flip(mask_copy, fl)
				# misc.imshow(flipped_img)

				images_np[data_counter, :, :, :] = flipped_img

				threshold = 160 #160 for pub_red_mul
				masks_np[data_counter, :, :, :] = np.expand_dims(np.array(flipped_mask > threshold), 2).astype(
					np.uint32)

				data_counter += 1
		if do_gblur:
			img_copy = img.copy()
			mask_copy = mask.copy()

			gblur_img = nd.gaussian_filter(img_copy, sigma=3)
			images_np[data_counter, :, :, :] = gblur_img

			threshold = 0
			masks_np[data_counter, :, :, :] = np.expand_dims(np.array(mask_copy > threshold), 2).astype(
				np.uint32)

			data_counter += 1

		# print 'img shape:', img.shape #old: (320, 320, 3)

		images_np[data_counter, :, :, :] = img
		masks_np[data_counter, :, :, :] = np.expand_dims(np.array(mask > threshold), 2).astype(np.uint32)

		display_mask = False
		if display_mask and data_counter < 3:
			misc.imshow(masks_np[data_counter, :, :, :].reshape((h, w)))

		data_counter += 1

	# debug print 'masks:',masks[data_counter-1]
	print 'total', data_counter, 'images and', data_counter, 'masks are loaded,flipping', do_Flipping
	print 'mask max,min:', np.max(masks_np[0]), ', ', np.min(masks_np[0])
	if display_mask:
		for i in xrange(30):
			print masks_np[0][i][i][0],
		print '\n'
	return images_np, masks_np


# only two types of flipping available, using misc, only mul case + gray
def import_data_seg_tf_rgb_rnd(im_path, label_path, file_imgs, file_masks, h, w, maxNum, MUL=False,
									  do_Flipping=False,do_gblur=False,do_darken=False):
	import scipy.misc as misc
	from scipy import ndimage as nd
	# args

	INPUT_CH = 3  # ori3
	threshold = 0

	rnd_flip = random.sample(xrange(maxNum - 1), maxNum - 1)
	rnd_gblur = random.sample(xrange(maxNum - 1), int(maxNum *0.3))
	rnd_darken = random.sample(xrange(maxNum - 1), int(maxNum *0.3)) #80
	maxNum = len(rnd_flip)*2 + len(rnd_gblur) + len(rnd_darken) + len(file_imgs)

	# out: images pixel value divided by 255, so they have value between 0 and 1,
	# #mask is composed of 0s and 1s, for two classes
	images_np = np.zeros((maxNum , h, w, INPUT_CH))
	masks_np = np.zeros((maxNum, h, w, 1))

	print 'load data, incl. flipping', im_path, h, w, maxNum, do_Flipping
	data_counter = 0
	for i, img, m in zip(range(1, len(file_imgs) + 1), file_imgs, file_masks):
		fimg = im_path + img

		fmask = label_path + m  #

		img = misc.imread(fimg)  # ori 3  #np.flip(self._transform(filename), 0)

		mask = misc.imread(fmask)  # changed, removed 'I' as all mask files must be saved to 1-channel
		dim = len(mask.shape)
		if dim == 3:
			mask = misc.imread(fmask, 'I')

		if mask is None or img is None:
			continue

		img = misc.imresize(img, [h, w], interp='nearest')
		img = np.float32(img.reshape(h, w, INPUT_CH))

		mask = misc.imresize(mask, [h, w], interp='nearest')  # change

		# print 'mask resize size:', mask.size, ', mask\n', mask
		img = img / 255.0 #
		# for mask not dividing to 1
		mask = mask / 255.0

		if do_Flipping and i in rnd_flip:
			img_copy = img.copy()
			mask_copy = mask.copy()

			for fl in range(0, 2):
				flipped_img = np.flip(img_copy, fl)
				flipped_mask = np.flip(mask_copy, fl)
				# misc.imshow(flipped_img)

				images_np[data_counter, :, :, :] = flipped_img

				if MUL:
					masks_np[data_counter, :, :, :] = np.expand_dims(np.array(flipped_mask), 2).astype(
					np.float32)
				else:
					threshold = 0 #0 #mul_data use 159
					masks_np[data_counter, :, :, :] = np.expand_dims(np.array(flipped_mask > threshold), 2).astype(
						np.float32)

				data_counter += 1

		if do_gblur and i in rnd_gblur:
			img_copy = img.copy()
			mask_copy = mask.copy()
			rnd_blurriness = 0.01 * randint(150, 280)

			gblur_img = nd.gaussian_filter(img_copy, sigma=rnd_blurriness)
			images_np[data_counter, :, :, :] = gblur_img

			if MUL:
				masks_np[data_counter, :, :, :] = np.expand_dims(np.array(mask_copy), 2).astype(
				np.float32)
			else:
				masks_np[data_counter, :, :, :] = np.expand_dims(np.array(mask_copy > threshold), 2).astype(
				np.float32)

			data_counter += 1

		if do_darken and i in rnd_darken:
			img_copy = misc.imread(fimg)
			mask_copy = mask.copy()

			#dark_img = cv2.cvtColor(img_copy,cv2.COLOR_BGR2RGB)
			#dark_img = cv2.cvtColor(np.array(dark_img),cv2.COLOR_RGB2BGR)

			dark_img_pil = Image.fromarray(img_copy)  #Image.fromarray(im1misc)
			rnd_darkness = 0.01*randint(20,50) #29,150
			dark_img_p = dark_img_pil.point(lambda p: p*rnd_darkness)
			dark_img_p.save('../tmp.png')
			dark_img = misc.imread('../tmp.png')
			#print 'before 11:', dark_img
			cmd = 'rm ../tmp.png'
			os.system(cmd)

			dark_img = misc.imresize(dark_img, [h, w], interp='nearest')
			dark_img = np.float32(dark_img.reshape(h, w, INPUT_CH))
			dark_img = dark_img / 255.0 #if added the image does not become dark
			#misc.imshow(dark_img)

			images_np[data_counter, :, :, :] = dark_img


			if MUL:
				masks_np[data_counter, :, :, :] = np.expand_dims(np.array(mask_copy), 2).astype(
				np.float32)
			else:
				masks_np[data_counter, :, :, :] = np.expand_dims(np.array(mask_copy > threshold), 2).astype(
				np.float32)

			data_counter += 1


		# print 'img shape:', img.shape #old: (320, 320, 3)
		images_np[data_counter, :, :, :] = img
		if MUL:
			masks_np[data_counter, :, :, :] = np.expand_dims(np.array(mask), 2).astype(np.float32)
		else:
			masks_np[data_counter, :, :, :] = np.expand_dims(np.array(mask > threshold), 2).astype(np.float32)

		display_mask = False
		if display_mask and data_counter < 3:
			misc.imshow(masks_np[data_counter, :, :, :].reshape((h, w)))

		data_counter += 1

	# debug print 'masks:',masks[data_counter-1]
	print 'total', data_counter, 'images and', data_counter, 'masks are loaded,flipping', do_Flipping
	print 'mask max,min:', np.max(masks_np[0]), ', ', np.min(masks_np[0])
	if display_mask:
		for i in xrange(30):
			print masks_np[0][i][i][0],
		print '\n'
	return images_np, masks_np


def import_data_seg_2c_tf_rgb_rnd_v2(im_path, label_path, file_imgs, file_masks, h, w, maxNum, ch=3,
									  do_Flipping=False,do_gblur=False,do_darken=False):
	import scipy.misc as misc
	from scipy import ndimage as nd
	import random
	# args
	threshold = 0  # 159
	INPUT_CH = 3  # ori3

	print 'load data, incl. flipping', im_path, h, w, maxNum, do_Flipping
	images, masks = [], []
	data_counter = 0
	rnd_flip = random.sample(xrange(maxNum-1), maxNum-1)
	rnd_gblur = random.sample(xrange(maxNum-1), maxNum-6)
	rnd_darken = random.sample(xrange(maxNum-1), maxNum-3)
	maxNum = len(rnd_flip)*2 + len(rnd_gblur) + len(rnd_darken) + len(file_imgs)

	for i, img, m in zip(range(1, len(file_imgs) + 1), file_imgs, file_masks):
		fimg = im_path + img
		# print '\n####', i, 'of ', maxNum, 'img file name:', fimg
		fmask = label_path + m  #
		# print '\n####', i, 'of ', maxNum, 'mask file name:', fmask

		img = misc.imread(fimg)  # ori 3  #np.flip(self._transform(filename), 0)
		mask = misc.imread(fmask)  # changed, removed 'I' as all mask files must be saved to 1-channel
		dim = len(mask.shape)
		if dim == 3:
			mask = misc.imread(fmask, 'I')

		if mask is None or img is None:
			continue

		img = misc.imresize(img, [h, w], interp='nearest')
		img = np.float32(img.reshape(h, w, INPUT_CH))

		mask = misc.imresize(mask, [h, w], interp='nearest')  # change

		# print 'mask resize size:', mask.size, ', mask\n', mask
		img = img / 255.0
		# for mask not dividing to 1
		mask = mask / 255.0


		if do_Flipping and i in rnd_flip:
			img_copy = img.copy()
			mask_copy = mask.copy()

			for fl in range(0, 2):
				flipped_img = np.flip(img_copy, fl)
				flipped_mask = np.flip(mask_copy, fl)
				# misc.imshow(flipped_img)

				images.append(flipped_img)
				masks.append(np.expand_dims(np.array(flipped_mask > threshold), 2).astype(
					np.float32))
				data_counter += 1


		if do_gblur and i in rnd_gblur:
			img_copy = img.copy()
			mask_copy = mask.copy()

			gblur_img = nd.gaussian_filter(img_copy, sigma=3)

			images.append(gblur_img)
			masks.append(np.expand_dims(np.array(mask_copy > threshold), 2).astype(
				np.float32))

			data_counter += 1

		if do_darken and i in rnd_darken:
		#if do_darken:
			img_copy = misc.imread(fimg)
			mask_copy = mask.copy()

			#dark_img = cv2.cvtColor(img_copy,cv2.COLOR_BGR2RGB)
			#dark_img = cv2.cvtColor(np.array(dark_img),cv2.COLOR_RGB2BGR)

			dark_img_pil = Image.fromarray(img_copy)  #Image.fromarray(im1misc)
			dark_img_p = dark_img_pil.point(lambda p: p*0.29)
			dark_img_p.save('tmp.png')
			dark_img = misc.imread('tmp.png')
			#print 'before 11:', dark_img

			dark_img = misc.imresize(dark_img, [h, w], interp='nearest')
			dark_img = np.float32(dark_img.reshape(h, w, INPUT_CH))

			dark_img = dark_img / 255.0 #if added the image does not become dark
			#misc.imshow(dark_img)

			images.append(dark_img)
			#print 'before 22:', images[-1]

			masks.append(np.expand_dims(np.array(mask_copy > threshold), 2).astype(
				np.float32))

			data_counter += 1


		images.append(img)
		masks.append(np.expand_dims(np.array(mask > threshold), 2).astype(np.float32))  # for other cases

		data_counter += 1

	print 'data_counter:', data_counter
	images_np = np.asarray(images)
	masks_np = np.asarray(masks)
	#totalNum=len(images)
	#print 'max len:', maxNum
	#images_np = np.zeros((maxNum, h, w, INPUT_CH))
	#masks_np = np.zeros((maxNum, h, w, 1))
	#for np_i in xrange(maxNum):
	#	images_np[np_i,:,:,:] = images[np_i]
	#	masks_np[np_i,:,:,:] = masks[np_i]

	#print 'y type1:', type(masks_np), type(masks_np[0]), type(mask)
	# debug print 'masks:',masks[data_counter-1]

	display_mask = False
	if display_mask and data_counter < 3:
		misc.imshow(masks_np[data_counter, :, :, :].reshape((h, w)))


	print 'total', data_counter, 'images and', data_counter, 'masks are loaded,flipping', do_Flipping
	print 'mask max,min:', np.max(masks_np[0]), ', ', np.min(masks_np[0])
	if display_mask:
		for i in xrange(30):
			print masks_np[0][i][i][0],
		print '\n'
	return images_np, masks_np


def import_data_seg_mul_tf_rgb(im_path, label_path, file_imgs, file_masks, h, w, maxNum, ch=3,
									  do_Flipping=False,do_gblur=False):
	import scipy.misc as misc
	from scipy import ndimage as nd
	# args

	maxNum_factor = 1
	INPUT_CH = 3  # ori3
	if do_Flipping:
		maxNum_factor = 3
	if do_gblur:
		maxNum_factor = maxNum_factor + 1

	print 'maxNum factor:', maxNum_factor
	# out: images pixel value divided by 255, so they have value between 0 and 1,
	# #mask is composed of 0s and 1s, for two classes
	images_np = np.zeros((maxNum*maxNum_factor , h, w, INPUT_CH))
	masks_np = np.zeros((maxNum*maxNum_factor, h, w, 1))

	print 'load data, incl. flipping', im_path, h, w, maxNum, do_Flipping
	data_counter = 0
	for i, img, m in zip(range(1, maxNum + 1), file_imgs, file_masks):
		fimg = im_path + img

		fmask = label_path + m  #

		img = misc.imread(fimg)  # ori 3  #np.flip(self._transform(filename), 0)

		mask = misc.imread(fmask)  # changed, removed 'I' as all mask files must be saved to 1-channel
		dim = len(mask.shape)
		if dim == 3:
			mask = misc.imread(fmask, 'I')

		if mask is None or img is None:
			continue

		img = misc.imresize(img, [h, w], interp='nearest')
		img = np.float32(img.reshape(h, w, INPUT_CH))

		mask = misc.imresize(mask, [h, w], interp='nearest')  # change

		# print 'mask resize size:', mask.size, ', mask\n', mask
		img = img / 255.0
		# for mask not dividing to 1
		mask = mask / 255.0

		if do_Flipping:
			img_copy = img.copy()
			mask_copy = mask.copy()

			for fl in range(0, 2):
				flipped_img = np.flip(img_copy, fl)
				flipped_mask = np.flip(mask_copy, fl)
				# misc.imshow(flipped_img)

				images_np[data_counter, :, :, :] = flipped_img

				masks_np[data_counter, :, :, :] = np.expand_dims(np.array(flipped_mask), 2).astype(
					np.float32)

				data_counter += 1

		if do_gblur:
			img_copy = img.copy()
			mask_copy = mask.copy()

			gblur_img = nd.gaussian_filter(img_copy, sigma=3)
			images_np[data_counter, :, :, :] = gblur_img

			masks_np[data_counter, :, :, :] = np.expand_dims(np.array(mask_copy), 2).astype(
				np.float32)

			data_counter += 1

		# print 'img shape:', img.shape #old: (320, 320, 3)

		images_np[data_counter, :, :, :] = img
		masks_np[data_counter, :, :, :] = np.expand_dims(np.array(mask), 2).astype(np.float32)

		display_mask = False
		if display_mask and data_counter < 3:
			misc.imshow(masks_np[data_counter, :, :, :].reshape((h, w)))

		data_counter += 1

	# debug print 'masks:',masks[data_counter-1]
	print 'total', data_counter, 'images and', data_counter, 'masks are loaded,flipping', do_Flipping
	print 'mask max,min:', np.max(masks_np[0]), ', ', np.min(masks_np[0])
	if display_mask:
		for i in xrange(30):
			print masks_np[0][i][i][0],
		print '\n'
	return images_np, masks_np


# only two types of flipping available, using misc, only mul case + gray
def import_data_segnet_2c_tf_rgb_gray(im_path, label_path, file_imgs, file_masks, h, w, maxNum, MUL=False,ch=3, do_Flipping=False):
	import scipy.misc as misc
	# args
	
	INPUT_CH = 3  # ori3
	if do_Flipping:
		maxNum = maxNum * 3
		
	# out: images pixel value divided by 255, so they have value between 0 and 1,
	# #mask is composed of 0s and 1s, for two classes
	images_np = np.zeros((maxNum*2, h, w, INPUT_CH))
	masks_np = np.zeros((maxNum*2, h, w, 1))
	
	print 'load data', im_path, h, w, maxNum, do_Flipping
	data_counter = 0
	for i, img, m in zip(range(1, maxNum + 1), file_imgs, file_masks):
		fimg = im_path + img
		
		fmask = label_path + m  #
		
		img = misc.imread(fimg)  # ori 3  #np.flip(self._transform(filename), 0)
		img_g = misc.imread(fimg,'I')  # ori 3  #np.flip(self._transform(filename), 0)
		img_g = np.array([img_g for i in range(3)])


		mask = misc.imread(fmask) #changed, removed 'I' as all mask files must be saved to 1-channel
		dim = len(mask.shape)
		if dim == 3:
			mask = misc.imread(fmask,'I')

		if mask is None or img is None:
			continue
		
		img = misc.imresize(img, [h, w], interp='nearest')
		img = np.float32(img.reshape(h, w, INPUT_CH))
		
		img_g = misc.imresize(img_g, [h, w], interp='nearest')
		img_g = np.float32(img_g.reshape(h, w, INPUT_CH))
		
		mask = misc.imresize(mask, [h, w], interp='nearest') #change
		
		# print 'mask resize size:', mask.size, ', mask\n', mask
		#img = img / 255.0  # make all values between 0 - 255 and as int
		#img_g = img_g / 255.0  # make all values between 0 - 255 and as int
		# for mask not dividing to 1
		#mask = mask / 255.0  # make all values between 0 - 255 and as int

		if do_Flipping:
			img_copy = img.copy()
			img_g_copy = img_g.copy()
			mask_copy = mask.copy()
			
			for fl in range(0, 2):
				flipped_img = np.flip(img_copy, fl)
				flipped_img_g = np.flip(img_g_copy, fl)
				flipped_mask = np.flip(mask_copy, fl)
				# misc.imshow(flipped_img)
				
				images_np[data_counter, :, :, :] = flipped_img
				images_np[data_counter+1, :, :, :] = flipped_img_g

				threshold= 199
				masks_np[data_counter, :, :, :] = np.expand_dims(np.array(flipped_mask>threshold), 2).astype(np.float32)
				masks_np[data_counter+1, :, :, :] = np.expand_dims(np.array(flipped_mask>threshold), 2).astype(np.float32)
				
				data_counter += 2
		
		# print 'img shape:', img.shape #old: (320, 320, 3)
		
		images_np[data_counter, :, :, :] = img
		images_np[data_counter+1, :, :, :] = img_g
		masks_np[data_counter, :, :, :] = np.expand_dims(np.array(mask>threshold), 2).astype(np.float32)
		masks_np[data_counter+1, :, :, :] = np.expand_dims(np.array(mask>threshold), 2).astype(np.float32)
		
		display_mask = False
		if display_mask and data_counter < 3:
			misc.imshow(masks_np[data_counter, :, :, :].reshape((h, w)))
		
		data_counter += 2
	
	# debug print 'masks:',masks[data_counter-1]
	print 'total', data_counter, 'images and', data_counter, 'masks are loaded,flipping', do_Flipping
	print 'mask max,min:', np.max(masks_np[0]), ', ', np.min(masks_np[0])
	if display_mask:
		for i in xrange(30):
			print masks_np[0][i][i][0],
		print '\n'
	return images_np, masks_np

def import_data_segnet_2c_tf_misc_cv2_gray(im_path, label_path, file_imgs, file_masks, h, w, maxNum, MUL=False,ch=3, do_Flipping=False):
	# args
	import scipy.misc as misc
	INPUT_CH = 3  # ori3
	# out: images pixel value divided by 255, so they have value between 0 and 1,
	# #mask is composed of 0s and 1s, for two classes
	if do_Flipping:
		maxNum = maxNum*3
	
	images_np = np.zeros((maxNum, h, w, INPUT_CH))
	images_np_view = np.zeros((maxNum, h, w, 3))
	masks_np = np.zeros((maxNum, h, w, 1))
	
	print 'load data (incl.flip)', im_path, h, w, maxNum, do_Flipping
	data_counter = 0
	for i, img, m in zip(range(1, maxNum + 1), file_imgs, file_masks):
		fimg = im_path + img
		fmask = label_path + m  #
		
		img_view = cv2.resize(cv2.imread(fimg, -1),(h,w))
		img = misc.imresize(misc.imread(fimg), [h,w], interp='nearest')  # ori 3  #np.flip(self._transform(filename), 0)
		#img = misc.imread(fimg,'I')  # ori 3  #np.flip(self._transform(filename), 0)
		#img = np.array([img for i in range(3)])
		img = misc.imresize(img, [h,w], interp='nearest')  # ori 3  #np.flip(self._transform(filename), 0)
		
		#mask = misc.imresize(misc.imread(fmask, 'I'), [h,w], interp='nearest')  # read as signed int32
		mask = misc.imresize(misc.imread(fmask, 'I'), [h,w], interp='nearest')  # read as signed int32
		
		if mask is None or img is None:
			continue
		
		# print 'mask resize size:', mask.size, ', mask\n', mask
		img      = np.float32(img.reshape(h, w, INPUT_CH))
		img_view = np.float32(img_view.reshape(h, w, 3))
		mask = np.asarray(mask.reshape(h, w))
	
		
		# img = np.asarray(np.float32(img.reshape(ch, h, w)))
		# mask = np.asarray(mask.reshape(ch, h, w))
		# print 'mask as array size:', mask.size, ', mask\n', mask
		
		img = img / 255.0
		mask = mask / 255.0
		
		if do_Flipping:
			img_copy = img.copy()
			img_view_copy = img_view.copy()
			mask_copy = mask.copy()
			
			for fl in range(0, 2):
				flipped_img = np.flip(img_copy, fl)
				flipped_img_view = np.flip(img_view_copy, fl)
				flipped_mask = np.flip(mask_copy, fl)
				# print 'flipped img shape:', flipped_img.shape
				
				images_np[data_counter, :, :, :] = flipped_img
				images_np_view[data_counter, :, :, :] = flipped_img_view
				# masks_np[data_counter, :, :, :] = np.float32(flipped_mask > 0)
				masks_np[data_counter, :, :, :] = np.expand_dims(np.array(flipped_mask>0), 2).astype(np.float32)
				
				data_counter += 1
		
		
		images_np[data_counter, :, :, :] = img
		images_np_view[data_counter, :, :, :] = img_view
		# masks_np[data_counter, :, :, :] = np.float32(mask > 0)
		if not MUL:
			#for binary
			masks_np[data_counter, :, :, :] = np.expand_dims(np.array(mask>0), 2).astype(np.float32)
		else:
			#for mul class masks
			masks_np[data_counter, :, :, :] = np.expand_dims(np.array(mask), 2).astype(np.float32)
			
		# print 'y type1:', type(masks_np), type(mask)
		# cv2.imshow('mask',mask)
		# cv2.waitKey()
		
		data_counter += 1
	
	# debug print 'masks:',masks[data_counter-1]
	print 'total', data_counter, 'images and', data_counter, 'masks are loaded,flipping', do_Flipping
	return images_np, masks_np, images_np_view

def convert_img_for_tf(images_np, masks_np, h, w, train_mode=True, n_classes=1):
	digits = datasets.load_digits(n_class=h * w)
	total_images = len(images_np)
	
	digits.images = images_np.reshape((len(images_np), -1))
	digits.target = masks_np.reshape((len(masks_np), -1)).astype(np.float32)
	
	DEBUG = 0
	if DEBUG == 1:
		print "Convert for tf \nshape of data set after reshape: ", digits.images.shape  # hy
	
	digits.images = np.expand_dims(np.array(digits.images), 2).astype(np.float32)
	# digits.images = digits.images.reshape(-1,h*w,1) #doing reshape here does not apply to tensorflow
	# Cannot feed value of shape (102400, 1) for Tensor u'x:0', which has shape '(?, 102400, 1)'
	
	if DEBUG == 1:
		print "Shape of data set after expansion: ", digits.images.shape  # hy
	
	# convert to one_hot
	# masks_np = np.array(masks_np).astype(np.int32)
	# print 'mask array label:', masks_np
	# digits.target = dense_to_one_hot(masks_np, num_classes=2)
	# print 'one hot label:', digits.targets
	
	use_one_hot = False
	mask_list = []
	counter_1s = 0
	if use_one_hot:
		print 'target shape:', masks_np.shape  # len(masks_np)
		for n in xrange(total_images):  #
			for i in xrange(320):
				for j in xrange(320):
					if masks_np[n][i][j] == 0:
						mask_list.append(np.int32([1, 0]))
					else:
						mask_list.append(np.int32([0, 1]))
		
		print 'mask_one_hot size (nxhxw):', len(mask_list)
		mask_list = np.asarray(mask_list)
		print 'mask_one_hot:', mask_list
		digits.target = mask_list.astype(np.float32).reshape(len(masks_np), -1)
	
	elif train_mode:
		print 'target shape:', masks_np.shape  # len(masks_np)
		for n in xrange(total_images):  #
			for i in xrange(h):
				for j in xrange(w):
					if masks_np[n][i][j] > 0:
						mask_list.append(1)  # (1)
						counter_1s += 1
					elif masks_np[n][i][j] == 0:
						mask_list.append(0)
					else:
						mask_list.append(0)
		
		print 'mask_list size (nxhxw):', len(mask_list), ', contain 1s:', counter_1s
		mask_list = np.asarray(mask_list)
		# digits.target = mask_list.astype(np.int32).reshape(len(masks_np), -1) # for sparse softmax
		digits.target = mask_list.astype(np.float32).reshape(len(masks_np), -1)  # for sparse softmax
	
	else:
		# digits.target = masks_np.astype(np.float32).reshape(len(masks_np),-1)
		digits.target = np.array(np.array(digits.target))
	
	if DEBUG == 1:
		print 'label_convert_tf:\n', digits.targets[0][120:300]
	
	if DEBUG == 1:
		print 'target: len of masks_np:', len(masks_np), ', shape of masks_np:', masks_np.shape
		print 'target: len of digits.target:', len(digits.targets), ', shape of digits.target:', digits.targets.shape
	
	# Convert the boolean values into floats -- so that
	# computations in cross-entropy loss is correct
	# bit_mask_class = tf.to_float(class_labels_tensor)
	# bit_mask_background = tf.to_float(background_labels_tensor)
	
	# combined_mask = tf.concat(concat_dim=2, values=[bit_mask_class,
	#                                                bit_mask_background])
	# reshape input so that it becomes suitable for
	# tf.softmax_cross_entropy_with_logits with [batch_size, num_classes]
	# digits.target = tf.reshape(tensor=combined_mask, shape=(-1, 2))
	
	if DEBUG == 1:
		print '\n'
		print "print targets"
		print digits.targets
		
		elapsed_time = time.time() - start_time
		print 'Total elapsed time2:', "{:.2f}".format(elapsed_time), 's'
	
	return [total_images, digits]

def add_colorOverlay(img_grayscale, mask):
	colorOverlay = cv2.cvtColor(img_grayscale, cv2.COLOR_GRAY2RGB)
	colorOverlay[:, :, 2] = mask
	return colorOverlay

def calc_dice_simi(seg, gt, img_name, k=1):
	# segmentation
	# seg = np.zeros((100,100), dtype='int')
	# seg[30:70, 30:70] = k
	
	# ground truth
	# gt = np.zeros((100,100), dtype='int')
	# gt[30:70, 40:80] = k
	
	dice = np.sum(seg[gt == k]) * 2.0 / (np.sum(seg) + np.sum(gt))
	
	#print img_name,', dice similarity score: {}'.format(dice)
	return dice

############  for seg-net end ######################

def get_precision(session, im):
	sess = session
	im = np.asarray(im, np.float32)
	
	CONF = 0.20
	
	test_image = im
	
	test_lables = np.zeros((1, n_classes))  # Making a dummy label tp avoid errors as initial predict
	
	# Doing something very stupid here, fix it!
	test_image = im.reshape((-1, im.size))
	
	# print test_image
	# print sess.run(test_image)
	
	test_image = np.expand_dims(np.array(test_image), 2).astype(np.float32)
	test_image = test_image / 255 - 0.5  # TODO here is tricky, double check wit respect to the formats
	
	# hy: evaluate
	batch_xs, batch_ys = test_image, test_lables
	
	# output = sess.run("Accuracy:0", feed_dict={"x:0": batch_xs, "y:0": batch_ys, "keep_prob:0": 1.})
	output = sess.run("pred:0", feed_dict={"x:0": batch_xs, "y:0": batch_ys, "keep_prob:0": 1.})
	
	# print("Output for external=",output)
	output = convert_to_confidence(output)  #
	
	return output

def create_bin_tf_data():
	from PIL import Image
	import numpy as np
	
	data_dir = '../Data/data_3_segnet/mul_class/'
	data_dir_im = '../Data/data_3_segnet/mul_class/table2/images/'
	
	im = Image.open(data_dir_im + os.listdir(data_dir_im)[0])
	im = (np.array(im))
	
	r = im[:, :, 0].flatten()
	g = im[:, :, 1].flatten()
	b = im[:, :, 2].flatten()
	label = [1]
	
	out = np.array(list(label) + list(r) + list(g) + list(b), np.uint8)
	out.tofile(data_dir + "data_batch_1.bin")
	
	eval_data = False
	if not eval_data:
		# filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i) for i in xrange(1, 1)] #(1,6)
		filenames = [os.path.join(data_dir, 'data_batch_1.bin')]  # for i in xrange(1, 1)] #(1,6)
	
	# edit this line of code to fit the name of the bin file. Or, just distribute your images into 6 bin files evenly.
	print filenames[0]

# create_bin_tf_data()

def create_seg_pixel_data(img, mask):
	img = np.array(img)
	mask = np.array(mask)
	# print 'img:', img
	# create im, label pair
	print 'len:', len(img), ', shape:', img.shape
	print img[0]
	cv2.imshow('0', img[0])
	
	# data_dir_im = '../Data/data_3_segnet/mul_class/table2/images/'
	# data_dir_m = '../Data/data_3_segnet/mul_class/table2/labels/'
	# im = cv2.imread(data_dir_im+os.listdir(data_dir_im)[0],0)
	# mask = cv2.imread(data_dir_m+os.listdir(data_dir_m)[0],0)
	# create_seg_pixel_data(im,mask)

def count_diff_pixel_values(picture, h, w):
	ds = []
	for row in xrange(h):
		for col in xrange(w):
			if picture[row][col] not in ds:
				ds.append(picture[row][col])
	return len(ds), ds


def internet_on(url):
	import urllib
	try:
		urllib.urlopen(url)
		url_ok = True
	except (IOError):
		url_ok = False
	return url_ok

def save_tb_imgs(save_path):
	import urllib
	#http://127.0.1.1:6006/data/individualImage?index=0&tag=c_ori_rgb%2Fimage%2F0&run=train&ts=1496095020.999715
	url_p1, url_p4 = 'http://127.0.1.1:6006/data/individualImage?index=', '%2Fimage%2F0&run=train&ts=*'

	#url_p1, url_p4 = 'http://127.0.1.1:6006/data/individualImage?index=', '%2Fimage%2F0&run=train&ts=*'
	save_name = save_path + '_pred.png'
	valid_url = False
	i = 0
	while not valid_url and i < 4:
		i = 0
		url_img = url_p1 + str(i) + '&tag=b_pred' + url_p4
		valid_url = internet_on(url_img)
		if not valid_url:
			i += 1
		
	#print 'url_img:', url_img

	urllib.urlretrieve(url_img, save_name)

	url_img = url_p1 + str(i) + '&tag=c_conv19' + url_p4
	save_name = save_path + '_conv19.png'

	print 'url_img:', url_img
	urllib.urlretrieve(url_img, save_name)
	
	url_img = url_p1 + str(i) + '&tag=c_ori_rgb' + url_p4
	save_name = save_path + '_ori.png'
	urllib.urlretrieve(url_img, save_name)
	
	print 'tb im saved', save_path

#also suitable for mul class
def valiate_dice_value(h,w):
	data_path = '../Test_Images/MA/test_represent/takenout/'  # main_path

	ref_mask = cv2.resize(cv2.imread(data_path + 'cad_real_m_001.jpg'), (320, 320))
	pred = cv2.resize(cv2.imread(data_path + '/82000res_cad_real_im_001_test.png'), (320, 320))
	print 'ref,pred size:', ref_mask.shape, ',', pred.shape

	# cv2.imshow('ref', ref_mask)
	# cv2.imshow('pred', pred)
	# cv2.waitKey()

	dice = calc_dice_simi(pred / 255, ref_mask / 255, k=1)
	print 'dice:', dice

###########################################################################################
#similarity
import cv2
import cv
import numpy as np
import time
import numpy
import imutils
from PIL import Image
import os
import settings

settings.set_global()


def calc_histogram(img1, img2, color, bins, h):
	for ch, col in enumerate(color):
		hist_item1 = cv2.calcHist([img1], [ch], None, [256], [0, 255])
		hist_item2 = cv2.calcHist([img2], [ch], None, [256], [0, 255])
		cv2.normalize(hist_item1, hist_item1, 0, 255, cv2.NORM_MINMAX)
		cv2.normalize(hist_item2, hist_item2, 0, 255, cv2.NORM_MINMAX)
		sc = cv2.compareHist(hist_item1, hist_item2, cv.CV_COMP_CORREL)
		# printsc
		hist = np.int32(np.around(hist_item1))
		pts = np.column_stack((bins, hist))
		cv2.polylines(h, [pts], False, col)
	return sc


# hy: calc similarity of each of images in group one to any of images in group two
# get potential strong samples
def calc_similarity(dirs1, path1, dirs2, path2, thresh, incl_neg_simi):
	tmp_ = []
	corr_ = []
	
	for item1 in dirs1:
		for item2 in dirs2:
			
			img1 = cv2.imread(path1 + item1)
			img1 = cv2.cvtColor(img1, cv.CV_BGR2HSV)
			img2 = cv2.imread(path2 + item2)
			img2 = cv2.cvtColor(img2, cv.CV_BGR2HSV)
			
			bins = np.arange(256).reshape(256, 1)
			color = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]
			h = np.zeros((300, 256, 3))
			# print '\ncompare correlation cad vs cam:',item1,'vs',item2
			corr = calc_histogram(img1, img2, color, bins, h)
			corr_.append(corr)
			if incl_neg_simi == 1:
				if corr > float(thresh) or corr < -float(thresh):
					# cmd = 'cp ' + path1+item1 + ' ./tmp/resized/' + name + '/'
					# print cmd
					# os.system(cmd)
					tmp_.append(item1)
				#print 'similar images:', item1, 'vs', item2, ', confidence:', corr
			else:
				if corr > float(thresh):
					# cmd = 'cp ' + path1+item1 + ' ./tmp/resized/' + name + '/'
					# print cmd
					# os.system(cmd)
					tmp_.append(item1)
				#print 'similar images:', item1, 'vs', item2, ', confidence:', corr
	tmp_1 = list(set(tmp_))
	count = len(tmp_1)
	
	return count, tmp_1, corr_, min(corr_), max(corr_)


def calc_similarity_low(dirs1, path1, dirs2, path2, thresh, incl_neg_simi):
	tmp_ = []
	corr_ = []
	
	for item1 in dirs1:
		for item2 in dirs2:
			
			img1 = cv2.imread(path1 + item1)
			img1 = cv2.cvtColor(img1, cv.CV_BGR2HSV)
			img2 = cv2.imread(path2 + item2)
			img2 = cv2.cvtColor(img2, cv.CV_BGR2HSV)
			
			bins = np.arange(256).reshape(256, 1)
			color = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]
			h = np.zeros((300, 256, 3))
			# print '\ncompare correlation cad vs cam:',item1,'vs',item2
			corr = calc_histogram(img1, img2, color, bins, h)
			corr_.append(corr)
			if incl_neg_simi == 1:
				if corr < float(thresh) or corr > -float(thresh):
					# cmd = 'cp ' + path1+item1 + ' ./tmp/resized/' + name + '/'
					# print cmd
					# os.system(cmd)
					tmp_.append(item1)
				# print 'similar images:', item1, 'vs', item2, ', confidence:', corr
			else:
				if corr < float(thresh):
					# cmd = 'cp ' + path1+item1 + ' ./tmp/resized/' + name + '/'
					# print cmd
					# os.system(cmd)
					tmp_.append(item1)
				# print 'similar images:', item1, 'vs', item2, ', confidence:', corr
	tmp_1 = list(set(tmp_))
	count = len(tmp_1)
	
	return count, tmp_1, corr_, min(corr_), max(corr_)


def split_samples(tmpA, tmpB):
	strong_disturb_to_other_ = []
	strong_pos_ = []
	for i in xrange(len(tmpA)):
		if tmpA[i] in tmpB:
			strong_disturb_to_other_.append(tmpA[i])
		
		if tmpA[i] not in tmpB:
			strong_pos_.append(tmpA[i])
	strong_disturb_to_other = list(set(strong_disturb_to_other_))
	strong_pos = list(set(strong_pos_))
	print '\ntotal number of strong disturb to others (remove)', len(strong_disturb_to_other)
	print 'total number of strong positive samples (keep)', len(strong_pos)
	return strong_pos, strong_disturb_to_other


def compare_images_cv():
	##############################################################
	##############################################################
	input_folder_name = 'unten'
	test_image_path = '../Test_Images/testpkg7_2/'
	path1 = '../Data/top_data/training/' + input_folder_name + '/'  # input
	path3 = test_image_path + input_folder_name + '/'  # hy: target
	# path3 = './Test_Images/' + input_folder_name[5:] + '/'  # target
	
	# disturbances: the rest classes, other than input class
	path2_1 = test_image_path + 'v/'
	path2_2 = test_image_path + 'r/'
	path2_3 = test_image_path + 'h/'
	path2_4 = test_image_path + 'l/'
	path2_5 = test_image_path + 'o/'
	
	dirs1 = [s for s in os.listdir(path1) if 'cad' in s]
	# dirs1_ = os.listdir(path1)
	# dirs1 = dirs1_[2001:len(dirs1_)-1]
	# dirs1 = dirs1_[0:100]
	
	dirs3 = os.listdir(path3)
	dirs2_1 = os.listdir(path2_1)
	dirs2_2 = os.listdir(path2_2)
	dirs2_3 = os.listdir(path2_3)
	dirs2_4 = os.listdir(path2_4)
	dirs2_5 = os.listdir(path2_5)
	thresh13 = 0.01
	
	count, cmp13, corr, corr_min, corr_max = calc_similarity(dirs1, path1, dirs3, path3, thresh13, 1)
	print 'min', corr_min, 'max', corr_max, 'total similar images, 1 vs target:', count
	
	cmp_dict = dict(zip(cmp13,corr))
	import operator
	cmp13_sorted = sorted(cmp_dict.items(), key=operator.itemgetter(1))
	print 'top similar'
	for item in cmp13_sorted:
		print item
	print '\n'
	thresh13 = corr_max - 0.1
	thresh12 = thresh13
	
	count, cmp13, corr, corr_min, corr_max = calc_similarity(dirs1, path1, dirs3, path3, thresh13, 1)
	print 'min', corr_min, 'max', corr_max, 'total similar images, 1 vs target:', count
	
	if count > 0:
		# '''
		count, cmp12_1, corr, corr_min, corr_max = calc_similarity(dirs1, path1, dirs2_1, path2_1, thresh12, 1)
		print 'min', corr_min, 'max', corr_max, 'total similar images, 1 vs 2_1:', count
		
		count, cmp12_2, corr, corr_min, corr_max = calc_similarity(dirs1, path1, dirs2_2, path2_2, thresh12, 1)
		print 'min', corr_min, 'max', corr_max, 'total similar images, 1 vs 2_2:', count
		
		count, cmp12_3, corr, corr_min, corr_max = calc_similarity(dirs1, path1, dirs2_3, path2_3, thresh12, 1)
		print 'min', corr_min, 'max', corr_max, 'total similar images, 1 vs 2_3:', count
		
		count, cmp12_4, corr, corr_min, corr_max = calc_similarity(dirs1, path1, dirs2_4, path2_4, thresh12, 1)
		print 'min', corr_min, 'max', corr_max, 'total similar images, 1 vs 2_4:', count
		
		count, cmp12_5, corr, corr_min, corr_max = calc_similarity(dirs1, path1, dirs2_5, path2_5, thresh12, 1)
		print 'min', corr_min, 'max', corr_max, 'total similar images, 1 vs 2_5:', count
		tmpA = cmp13  # hy: potential good samples
		
		strong, disturb = split_samples(tmpA, cmp12_1)
		strong, disturb = split_samples(strong, cmp12_2)
		strong, disturb = split_samples(strong, cmp12_3)
		strong, disturb = split_samples(strong, cmp12_4)
		strong, disturb = split_samples(strong, cmp12_5)
		
		print 'final strong samples', len(strong)
		for item in strong:
			print item
		dest_path = './Data/strong/'
		save_file = False
		if save_file:
			for item1 in strong:
				# print item1
				cmd = 'cp ' + path1 + item1 + ' ' + dest_path
				os.system(cmd)
			print 'total images found:', len(os.listdir(dest_path))
		
		################################ get weak neg #####
		strong, disturb = split_samples(tmpA, cmp12_1)
		strong, disturb = split_samples(disturb, cmp12_2)
		strong, disturb = split_samples(disturb, cmp12_3)
		strong, disturb = split_samples(disturb, cmp12_4)
		strong, disturb = split_samples(disturb, cmp12_5)
		
		print 'final strong disturb to other classes:', len(disturb)
		print disturb
		dest_path = './Data/disturb/'
		if save_file:
			for item_weak in disturb:
				cmd = 'cp ' + path1 + item_weak + ' ' + dest_path
				os.system(cmd)
			print 'total images found:', len(os.listdir(dest_path))
	# '''
	else:
		print 'no samples filtered'


compare_images_cv()


def get_weak_positive():
	##############################################################
	input_folder_name = 'weak_pos_tmp'
	path1 = './Data/' + input_folder_name + '/'  # hy: input
	path3 = './Test_Images/testpkg3_white_200x200/' + 'hinten' + '/'  # hy: target
	
	dirs1 = os.listdir(path1)
	# dirs1_ = os.listdir(path1)
	# dirs1 = dirs1_[2001:len(dirs1_)-1]
	# dirs1 = dirs1_[0:100]
	
	dirs3 = os.listdir(path3)
	thresh13 = 0
	
	count, cmp13, corr_min, corr_max = calc_similarity(dirs1, path1, dirs3, path3, thresh13, 1)
	print 'min', corr_min, 'max', corr_max, 'total similar images, 1 vs target:', count
	
	thresh13 = corr_min + 0.01
	thresh12 = thresh13
	
	count, cmp13, corr_min, corr_max = calc_similarity_low(dirs1, path1, dirs3, path3, thresh13, 0)
	print 'min', corr_min, 'max', corr_max, 'total weak similar images, 1 vs target:less than', thresh13, count
	
	if count > 0:
		tmpA = cmp13  # hy: potential good samples
		dest_path = './Data/weak_pos/'
		for item1 in tmpA:
			# print item1
			cmd = 'mv ' + path1 + item1 + ' ' + dest_path
			os.system(cmd)
		print 'total weak positive images (remove):', len(os.listdir(dest_path))
	
	else:
		print 'no samples filtered'


#get_weak_positive()


# import numpy
# from PIL import Image
# import cv2

def similarness(image1, image2):
	"""
Return the correlation distance be1tween the histograms. This is 'normalized' so that
1 is a perfect match while -1 is a complete mismatch and 0 is no match.
"""
	# Open and resize images to 200x200
	i1 = Image.open(image1).resize((200, 200))
	i2 = Image.open(image2).resize((200, 200))
	
	# Get histogram and seperate into RGB channels
	i1hist = numpy.array(i1.histogram()).astype('float32')
	i1r, i1b, i1g = i1hist[0:256], i1hist[256:256 * 2], i1hist[256 * 2:]
	# Re bin the histogram from 256 bins to 48 for each channel
	i1rh = numpy.array([sum(i1r[i * 16:16 * (i + 1)]) for i in range(16)]).astype('float32')
	i1bh = numpy.array([sum(i1b[i * 16:16 * (i + 1)]) for i in range(16)]).astype('float32')
	i1gh = numpy.array([sum(i1g[i * 16:16 * (i + 1)]) for i in range(16)]).astype('float32')
	# Combine all the channels back into one array
	i1histbin = numpy.ravel([i1rh, i1bh, i1gh]).astype('float32')
	
	# Same steps for the second image
	i2hist = numpy.array(i2.histogram()).astype('float32')
	i2r, i2b, i2g = i2hist[0:256], i2hist[256:256 * 2], i2hist[256 * 2:]
	i2rh = numpy.array([sum(i2r[i * 16:16 * (i + 1)]) for i in range(16)]).astype('float32')
	i2bh = numpy.array([sum(i2b[i * 16:16 * (i + 1)]) for i in range(16)]).astype('float32')
	i2gh = numpy.array([sum(i2g[i * 16:16 * (i + 1)]) for i in range(16)]).astype('float32')
	i2histbin = numpy.ravel([i2rh, i2bh, i2gh]).astype('float32')
	
	return cv2.compareHist(i1histbin, i2histbin, 0)

